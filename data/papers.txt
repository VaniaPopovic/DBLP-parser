index0!@#@!1998!@#@!Static and Dynamic Metrics for Effective Object Clustering!@#@!Proceedings of the Fifth Asia Pacific Software Engineering Conference!@#@!null
index1!@#@!2003!@#@!Who participates and why?: an analysis of citizens on the internet and the mass public!@#@!Social Science Computer Review!@#@!Scholars continue to find that political participation, especially beyond voting, is in limited supply in the United States. However, the rise of the Internet provides possibilities to mitigate such circumstances. Some scholars suggest that the Internet disconnects citizens from public life, while other studies note that it provides a venue for further participation in public life. The question remains as to whether the Internet mobilizes or demobilizes citizens. The article explores this question using Survey2000, a comprehensive, Internet-based, social scientific survey conducted in 1998 by scholars at Northwestern University in conjunction with the National Geographic Society. A positive relationship is found between engagement on the Internet and civic and political participation. However, the article also finds that the Internet appears to exacerbate the socioeconomic bias already exhibited by civic and political participation prior to the rise of the Internet.
index2!@#@!2002!@#@!Call for papers!@#@!Sys Admin!@#@!null
index3!@#@!2002!@#@!Universal parametrization in constructing smoothly-connected B-spline surfaces!@#@!Computer Aided Geometric Design!@#@!In this paper, we explore the feasibility of universal parametrization in generating B-spline surfaces, which was proposed recently in the literature (Lim, 1999). We present an interesting property of the new parametrization that it guarantees G0 continuity on B-spline surfaces when several independently constructed patches are put together without imposing any constraints. Also, a simple blending method of patchwork is proposed to construct Cn-1 surfaces, where overlapping control nets are utilized. It takes into account the semi-localness property of universal parametrization. It effectively helps us construct very natural looking B-spline surfaces while keeping the deviation from given data points very low. Experimental results are shown with several sets of surface data points.
index4!@#@!2003!@#@!Data Allocation and Load Balancing for Heterogeneous Cluster Storage Systems!@#@!Proceedings of the 3st International Symposium on Cluster Computing and the Grid!@#@!Distributed filesystems are a typical solution in networked environments as clusters and grids. Parallel filesystems are a typical solution in order to reach high performance I/O distributed environment, but those filesystemshave some limitations in heterogeneous storage systems.Usually in distributed systems, load balancing is used asa solution to improve the performance, but typically the distribution is made between peer-to-peer computational resources and from the processor point of view. In heterogeneous systems, like heterogeneous clusters of workstations,the existing solutions do not work so well. However, the utilization of those systems is more extended every day, havingan extreme example in the grid environment. In this paperwe bring attention to those aspects of heterogeneous distributed data systems presenting a parallel file system thattake into account heterogeneity of storage nodes, the dynamic addition of new storage nodes, and an algorithm togroup requests in heterogeneous systems.
index5!@#@!2003!@#@!Employment opinion: reversal of fortune!@#@!IEEE Spectrum!@#@!No question times are tough for many working engineers. But is the current job market really worse than previous ones? IEEE Spectrum's senior associate eitor Jean Kumagai spoke with Stephen R. Barley, a professor of management science and engineering and codirector of the Center for Work, Technology and Organization at Stanford University (California), to get his thoughts on what's going on in the engineering workplace. [A longer version of this interview is on the Spectrum Web site http://www.spectrum.ieee.org.]
index6!@#@!1999!@#@!From Coordination of Workflow and Group Activities to Composition and Management of Virtual Enterprises!@#@!Proceedings of the 1999 International Symposium on Database Applications in Non-Traditional Environments!@#@!The objective of the Collaboration Management Infrastructure (CMI) project at MCC is the development of technologies that support a wide class of advanced applications requiring synchronous and asynchronous coordination of activities executed by human and software agents. CMI integrates a number of technologies having their origin in workflow and process management, groupware, and document management and provides additional solutions to the problems of dynamic process modification at run time, customizable awareness of the process status, and integration of external services. We describe the Collaboration Management Model and describe briefly its implementation using a collection of commercial tools augmented with new components providing the advanced functionality. We also describe briefly further extension to the model needed to provide support for a new class of applications implementing the concept of a virtual enterprise.
index7!@#@!1995!@#@!Modes of Comprehension: Mode Analysis of Arrays and Array Comprehensions!@#@!Proceedings of the 7th International Symposium on Programming Languages: Implementations, Logics and Programs!@#@!null
index8!@#@!2002!@#@!Thesis: clustering and instance based learning in first order logic!@#@!AI Communications!@#@!Instance based learning and clustering are popular methods in propositional machine learning. Both methods use a notion of similarity between objects. This dissertation investigates these methods in a relational setting. First, a number of new metrics are proposed. Next, these metrics are used to upgrade clustering and instance based learning to first order logic.
index9!@#@!2002!@#@!Estimating internal memory fragmentation for Java programs!@#@!Journal of Systems and Software!@#@!Dynamic memory management has been an important part of a large class of computer programs and with the recent popularity of object oriented programming languages, more specifically Java, high performance dynamic memory management algorithms continue to be of great importance. In this paper, an analysis of Java programs, provided by the SPECjvm98 benchmark suite, and their behavior, as this relates to fragmentation, is performed. Based on this analysis, a new model is proposed which allows the estimation of the total internal fragmentation that Java systems will incur prior to the programs execution. The proposed model can also accommodate any variation of segregated lists implementation. A comparison with a previously introduced fragmentation model is performed as well as a comparison with actual fragmentation values that were extracted from SPECjvm98. Finally the idea of a test-bed application that will use the proposed model to provide to programmers/developers the ability to know, prior to a programs execution, the fragmentation and memory utilization of their programs, is also introduced. With this application at hand developers as well as designers of applications could better assess the stability, efficiency as well reliability of their applications at compile time.
index10!@#@!1998!@#@!ILI: An Adaptive Infrastructure for Dynamic Interactive Distributed Applications!@#@!Proceedings of the International Conference on Configurable Distributed Systems!@#@!null
index11!@#@!1999!@#@!Resynchronization Properties of Arithmetic Coding!@#@!Proceedings of the Conference on Data Compression!@#@!In this paper we consider the problem of resynchronizing simple arithmetic codes. This research lays the groundwork for future analysis of arithmetic codes with high- order context models. In order for the decoder to achieve full resynchronization, the unknown, initial b bits of the code stream must be determined exactly. When the source is approximately i.i.d., the search complexity associated with choosing the correct sequence is at least O (2 b= 2). Therefore, when b is 100 or more, the time complexity required to achieve full resynchronization is prohibitively high.
index12!@#@!1998!@#@!Unification and Consistency Verification of Object-Oriented Analysis Models!@#@!Proceedings of the Fifth Asia Pacific Software Engineering Conference!@#@!null
index13!@#@!2003!@#@!One- and multistep discretizations of index 2 differential algebraic systems and their use in optimization!@#@!Journal of Computational and Applied Mathematics!@#@!An approach to solve constrained minimization problems is to integrate a corresponding index 2 differential algebraic equation (DAE). Here, corresponding means that the ω-limit sets of the DAE dynamics are local solutions of the minimization problem. In order to obtain an efficient optimization code, we analyze the behavior of certain Runge-Kutta and linear multistep discretizations applied to these DAEs. It is shown that the discrete dynamics reproduces the geometric properties and the long-time behavior of the continuous system correctly. Finally, we compare the DAE approach with a classical SQP-method.
index14!@#@!2003!@#@!Surface Science Spectra: A Hybrid Journal-Database!@#@!Computing in Science and Engineering!@#@!The Surface Science Spectra journal is a spectral database built on efforts made for other kinds of spectroscopies and attends to the surface science community's special needs.
index15!@#@!1998!@#@!An Efficient, Objective Technique for Selecting An All-Star Team!@#@!Interfaces!@#@!Up to 1995, all-star selection in the Ontario-Quebec Intercollegiate Football Conference was accomplished with a head coaches' meeting that took up most of the Sunday before the conference semifinal play-off games. There were two difficulties with this system. First, coaches involved in the play-off games the next Saturday lost a day of game planning. Second, there were assistant coaches who felt this "horse-trading" session was not very objective. The implementation of a Borda voting scheme solves both these problems.
index16!@#@!2002!@#@!Throughput Enhanced Wireless in Local Loop (TWiLL) - The Architecture, Protocols and Pricing Schemes!@#@!Proceedings of the 27th Annual IEEE Conference on Local Computer Networks!@#@!Traditionally, voice communication over the local loophas been provided by wired systems. However in the recentpast there has been an increased interest in the useof radio access technologies in local loops. Such systemswhich are now popular for their ease and low cost of installationand maintenance are called Wireless in LocalLoop (WLL) systems. Subscribers' demands for greatercapacity have grown over the years especially with the adventof the Internet. Unlike WLL, wired local loops haveresponded to these increasing demands through the useof digital technologies such as ISDN and xDSL. Multi-hopcommunication has already been studied extensivelyin Ad hoc network environments and has begun makingforays into cellular systems as well. Multi-hop communicationhas been proven as one of the best ways to enhancethroughput in a wireless network. In this paper, westudy the issues involved in multi-hop communication in awireless local loop system and propose a novel WLL architecturecalled Throughput enhanced Wireless in LocalLoop (TWiLL). Through a realistic simulation model weshow the tremendous performance improvement achievedby TWiLL over WLL. We also propose pricing schemeswhich could be applied in such a multi-hop environment.
index17!@#@!1993!@#@!HW/SW Co-Design with PRAMs Using CoDES!@#@!Proceedings of the 11th IFIP WG10.2 International Conference sponsored by IFIP WG10.2 and in cooperation with IEEE COMPSOC on Computer Hardware Description Languages and their Applications!@#@!null
index18!@#@!2003!@#@!Non-separable detachments of graphs!@#@!Journal of Combinatorial Theory Series B!@#@!Let G = (V, E) be a graph and r : V → Z+. An r-detachment of G is a graph H obtained by 'splitting' each vertex v ∈ V into r(v) vertices, called the pieces of v in H. Every edge uv ∈ E corresponds to an edge of H connecting some piece of u to some piece of v. An r-degree specification for G is a function f on V, such that, for each vertex v ∈ V, f(v) is a partition of d(v) into r(v) positive integers. An f-detachment of G is an r-detachment H in which the degrees in H of the pieces of each v ∈ V are given by f(v). Crispin Nash-Williams [3] obtained necessary and sufficient conditions for a graph to have a k-edge-connected r-detachment or f-detachment. We solve a problem posed by Nash-Williams in [2] by obtaining analogous results for non-separable detachments of graphs.
index19!@#@!1998!@#@!On Objective Measures of Rule Surprisingness!@#@!Proceedings of the Second European Symposium on Principles of Data Mining and Knowledge Discovery!@#@!null
index20!@#@!1998!@#@!Attentive Face Detection and Recognition!@#@!Mustererkennung 1998, 20. DAGM-Symposium!@#@!null
index21!@#@!2002!@#@!Scientific papers: from web sites to e-communities: The internet and mental health service users: An empowerment process?!@#@!Technology and Health Care!@#@!null
index22!@#@!2002!@#@!Interoperable Thin Client Separation from GUI Applications!@#@!Proceedings of the 6th European Conference on Software Maintenance and Reengineering!@#@!This paper describes the concept of GUI application reengineering with a purpose to detach visualization part into separate lightweight client process runnable on different platforms in distributed environment. Only thin presentation layer of primary application is rewritten and whole application business logic remains intact. Original GUI platform becomes a server platform communicating with remote client locally or through the network.Theoretical and practical materials on GUI-application reengineering technologies along with techniques and methods applied in a series of projects are analyzed and generalized. Covered application class is defined. Reengineering process decomposition on distinct stages is made. Some considerations are expressed about bottleneck finding where cut line between thin client and middle tier should be drawn. Several implementation issues are considered including a choice of optimal toolkit for the thin client, distributed event cycle organization, deadlock elimination question, index-based architecture of distributed call routing and some performance aspects. Some performance measurements made in real environment are given for evaluation of the approach effectiveness.
index23!@#@!1984!@#@!The Forms Pattern Language!@#@!Proceedings of the First International Conference on Data Engineering!@#@!null
index24!@#@!2002!@#@!An efficient and evolutionary hierarchical modeling and simulation approach!@#@!Systems Analysis Modelling Simulation!@#@!Modeling and simulation have taken a preponderant place in the analysis and design of complex systems. The general environment we present in this paper provides a set of tools intended to make easier the creation and the simulation of evolving models. The originality of the approach is layed on the one hand in the combination of a hierarchical modeling and a discrete event simulation formalism, and on the other hand the implementation of object-oriented concepts during the realization phase. After a description of the existing works directly related to our approach, we introduce the basic modeling concepts and the defined object-oriented simulation architecture. Then, we propose a concrete application concerning the analysis of one complex natural system "the hydrologic behavior of the catchment basin". This study ends with the presentation of results obtained from a set of real data.
index25!@#@!2002!@#@!Simplification of surface parametrizations!@#@!Proceedings of the 2002 international symposium on Symbolic and algebraic computation!@#@!Given a rational parametrization of an algebraic surface, we try to reduce the degree by a suitable reparametrization. We give an algorithm that produces a parametrization with a degree that is at most twice the minimal degree. The problem is closely related to the simplification of linear systems of plane curves by Cremona transformations.
index26!@#@!2000!@#@!Use of Shape Models to Search Digitized Spine X-rays!@#@!CBMS!@#@!We are building a biomedical information resource consisting of digitized x-ray images and associated textual data from national health surveys. This resource, the Web-based Medical Information Retrieval System, or WebMIRS, is currently in beta test. In a future WebMIRS system, we plan to have not only text and raw image data, but quantitative anatomical feature information derived from the images and capability to retrieve images based on image characteristics, either alone or in conjunction with text descriptions associated with the images. Our archive consists of data collected in the second and third National Health and Nutrition Examination Surveys (NHANES), conducted by the National Center for Health Statistics. For the NHANES II survey, the records contain information for approximately 20,000 participants. Each record contains about two thousand data points, including demographic information, answers to health questionnaires, anthropometric information, and the results of a physician's examination. In addition, approximately 10,000 cervical spines and 7,000 lumbar spine x-rays were collected. WebMIRS makes the text and images retrievable. Only raw images are returned; no quantitative or descriptive information about the images is stored in the database. We are conducting research into the problem of automatically or semi-automatically segmenting spine vertebrae in these images and determining vertebral boundaries with enough accuracy to be useful in classifying the vertebrae into categories of interest to researchers in osteoarthritis.
index27!@#@!2001!@#@!PicoDBMS: Validation and Experience!@#@!Very Large Data Bases!@#@!null
index28!@#@!1997!@#@!Distributed Object Oriented Databases: An Allocation Method!@#@!Proceedings of the 8th  International Conference on Database and Expert Systems Applications!@#@!null
index29!@#@!1999!@#@!External Referees!@#@!Proceedings of the Sixth International Conference on Database Systems for Advanced Applications!@#@!null
index30!@#@!1995!@#@!Neural-network-based Model Predictive Control: A Case Study!@#@!Proceedings of the 2nd New Zealand Two-Stream International Conference on Artificial Neural Networks and Expert Systems!@#@!This paper presents a specific example of model predictive control (MPC) of an Ultra-High Temperature (UHT) milk treatment plan using a Artificial Neural Network (ANN) as the model. Single-network and composite-network models were trained on plant data with the composite-network model performing better. Simulations of a MPC scheme using the composite-network model as a prediction model show that the scheme does not perform as well as a PI controller. Some pitfalls and possible improvements are noted.
index31!@#@!2003!@#@!The intrinsic dimensionality of graphs!@#@!Annual ACM Symposium on Theory of Computing!@#@!We resolve the following conjecture raised by Levin together with Linial, London, and Rabinovich [16]. Let Z∞d be the infinite graph whose vertex set is Zd and which has an edge (u,v) whenever ||u-v||∞ = 1. Let dim(G) be the smallest d such that G occurs as a (not necessarily induced) subgraph of Z∞d. The growth rate of G, denoted ρG, is the minimum ρ such that every ball of radius r > 1 in G contains at most rρ vertices. By simple volume arguments, dim(G) = Ω(ρG). Levin conjectured that this lower bound is tight, i.e., that dim(G) = O(ρG) for every graph G.Previously, it was not known whether dim(G) could be upper bounded by any function of ρG, even in the special case of trees. We show that a weaker form of Levin's conjecture holds by proving that, for every graph G, dim(G) = O(ρG log ρG). We disprove, however, the specific bound of the conjecture and show that our upper bound is tight by exhibiting graphs for which dim(G) =Ω(ρG log ρG). For families of graphs which exclude a fixed minor, we salvage the strong form, showing that dim(G) = O(ρG). This holds also for graphs without long induced simple cycles. Our results extend to a variant of the conjecture for finite-dimensional Euclidean spaces due to Linial[15].
index32!@#@!1999!@#@!Unsupervised Segmentation of Color Images Based on k -means Clustering in the Chromaticity Plane!@#@!Proceedings of the IEEE Workshop on Content-Based Access of Image and Video Libraries!@#@!In this work, we present an original technique for unsupervised segmentation of color images which is based on an extension, for an use in the u1v1 chromaticity diagram, of the well-known k -means algorithm, widely adopted in cluster analysis. We suggest exploiting the separability of color information which, represented in a suitable 3D space, may be "projected" onto a 2D chromatic subspace and onto a 1D luminance subspace. One can first compute the chromaticity coordinates ( u1v1) of colors and find representative clusters in such a 2D space, by using a 2D k means algorithm, and then associate these clusters with appropriate luminance values, by using a 1D k means algorithm, a simple dimensionally reduced version of the previous one. Experimental evidence of the effectiveness of our technique is reported.
index33!@#@!1992!@#@!Eine Online-Subpixelinterpolation f&uuml;r CCD-gest&uuml;tzte Triangulationsme&szlig;systeme nach dem Lichtschnittverfahren!@#@!Mustererkennung 1992, 14. DAGM-Symposium!@#@!null
index34!@#@!2003!@#@!Total recall: in-place viewing of captured whiteboard annotations!@#@!CHI '03 extended abstracts on Human factors in computing systems!@#@!Total Recall introduces a new way to view captured whiteboard annotations. To digitize drawings we used a modified commercial system. However, instead of displaying the annotations on a separate computer screen, Total Recall shows the annotations at the place on the board where they were actually made. The user holds a hand-held computer to the board and moves it to reveal the desirable portion of the captured annotations. By using ultra-sonic positioning and optimized graphics, we achieve a high frame-rate (30 fps), allowing for very smooth panning and interaction. We argue that this way of viewing captured whiteboard annotations is more natural and intuitive than current desktop-based systems.
index35!@#@!1998!@#@!Reengineering the Dutch Flower Auctions: a Framework for Analyzing Exchange Organizations!@#@!Information Systems Research!@#@!This paper specifies a generalizable model of exchange processes and develops a processs takeholder analysis framework to evaluate alternative market designs. This framework is applied to analyze a number of information technology initiatives in the Dutch flower markets. The Dutch flower auctions are the world's leading centers for trading cut flowers and potted plants. We undertake a cross-case analysis and apply our framework to analyse successes and failures in the introduction of new IT-based trading mechanisms in these markets. Based on our study, we develop a number of testable propositions on: the separation of physical and informational processes in trading, the responses of stakeholders to changes in available information due to IT initiatives, and economic and incentive conditions required for adoption of new trading processes. Finally, our detailed cases illustrate the institutional and incentive constraints, and complexities encountered in the introduction of new electronic markets.
index36!@#@!1999!@#@!Setting Parameters by Example!@#@!Proceedings of the 40th Annual Symposium on Foundations of Computer Science!@#@!We introduce a class of "inverse parametric optimization" problems, in which one is given both a parametric optimization problem and a desired optimal solution; the task is to determine parameter values that lead to the given solution. We describe algorithms for solving such problems for minimum spanning trees, shortest paths, and other "optimal sub-graph" problems, and discuss applications in multicast routing, vehicle path planning, resource allocation, and board game programming.
index37!@#@!1997!@#@!Making internal processes external for constructive collaboration!@#@!CT!@#@!Information technology has the potential to promote joint creation of new ideas. It has become widely recognized that the workings of human cognitive processes heavily rely on physical externalisation of the interaction of those processes with outside environments, including other people in those environments. Such externalization takes various forms, from conversation, written texts, sketches and memos to simple physical "records" of actions taken in the world. For example, the mere location of a tool recently used can be interpreted, for instance, as a sign of the progress of the work. Externalized records are useful because they serve as sharable and concretely manipulable objects for constructive collaboration. Recently developed information technology can help people keep better records of such externalizations, reflect upon them for making changes and restore them when necessary. Altogether, these records and operations feed into constructive collaboration. The author gives examples of collaborative externalization of cognitive processes and show how they lead to deeper levels of understanding and creation of new ideas.
index38!@#@!1996!@#@!A statistical process for surface tracking!@#@!Proceedings of the 6th International Workshop on Discrete Geometry for Computer Imagery!@#@!null
index39!@#@!1997!@#@!A CMOS Low Voltage, High Gain Op-Amp!@#@!Proceedings of the 1997 European conference on Design and Test!@#@!A CMOS, self biasing, single supply op-amp is presented. It is designed with regulated cascode transistors for gain enhancement and a common mode feedback technique for bias stabilisation of complementary regulated cascodes. It enables supply voltage lowering to about 2|Vt|+2|Vds,sat| with the maintain of high gain operation. At Vdd=1.8 V, the measured DC gain of the op-amp is 115 dB, whit a unity gain frequency of 8.6 MHz for a capacitive load of 20 pF.
index40!@#@!1994!@#@!Visualizing abstract events!@#@!Proceedings of the 1994 conference of the Centre for Advanced Studies on Collaborative research!@#@!Because of the complexity of distributed applications, understanding their behaviour is a challenging task. The top-down use of suitable abstraction hierarchies is frequently proposed to manage this complexity. One commonly used abstraction is to group primitive events into abstract events. This paper presents a graphical representation for convex abstract events. This representation can easily be included in the process-time diagrams frequently used to depict the behaviour of distributed applications. Such visualizations, in turn, are helpful during the construction, debugging, and monitoring distributed applications as well as in trying to understand old "legacy" code in a program-understanding task. We added such a graphical representation to a prototype distributed debugger. Some examples of the resulting abstract visualization of the execution behaviour are given. These abstract visualizations are essential to minimize the complexity of the understanding process, and support top-down behaviour analyses.
index41!@#@!1992!@#@!A Performance Analysis of S++: A MAC Protocol for High Speed Networks!@#@!Proceedings of the IFIP WG6.1/WG6.4 Third International Workshop on Protocols for High-Speed Networks III!@#@!null
index42!@#@!1996!@#@!Perceived Risks and Management Actions: Differences in End-User Application Development Across Functional Groups!@#@!Proceedings of the 29th Hawaii International Conference on System Sciences Volume 2: Decision Support and Knowledge-Based Systems!@#@!Essentially unaddressed in prior end-user computing (EUC) research is an important context factor: the functional department of the end-user. Just as individual employees vary in their EUC tool and management support needs, we propose that not all functional departments in the same firm will use EUC tools for the same tasks, perceive the same EUC risks, and have the same management control needs. This article reports on an exploratory study designed to investigate potential differences across functional groups in the same organization for three factors: application tasks, policies to minimize risk, and perceived EUC benefits. Based on the data collected from semi-structured interviews and questionnaires from IS and IC Management, Functional Managers, and end-users, significant differences across functional groups can exist. This suggests that the workgroup is an important contextual factor that should be taken into account in future EUC research. A research model is provided based on the results of this exploratory study.
index43!@#@!2001!@#@!Visual simulation of smoke and fire!@#@!Proceedings of the Eurographic workshop on Computer animation and simulation!@#@!null
index44!@#@!2002!@#@!Online teaching: say goodby to chat!@#@!Journal of Computing Sciences in Colleges!@#@!Online teaching must be structured where students are on a specific timeline and feel they are in a "classroom" learning environment. This philosophy has evolved into meaning that online teaching requires a high interaction with students using e-mail and chat. This paper describes an online study in introductory statistics which used computer tutorial supplements and computer graded quizzes (over 25 quizzes) with immediate feedback to monitor the progress of students. This type of learning environment is modeled after certification programs conducted by corporations such as Microsoft and Novell. These programs are not limited by a large number of participants nor are they labor intense. Benefits from this study will include how to teach large online classes in a more efficient yet less time consuming manner.
index45!@#@!2003!@#@!The design and implementation of a parallel array operator for the arbitrary remapping of data!@#@!ACM SIGPLAN Notices!@#@!Gather and scatter are data redistribution functions of long-standing importance to high performance computing. In this paper, we present a highly-general array operator with powerful gather and scatter capabilities unmatched by other array languages. We discuss an efficient parallel implementation, introducing three new optimizations---schedule compression, dead array reuse, and direct communication---that reduce the costs associated with the operator's wide applicability. In our implementation of this operator in ZPL, we demonstrate performance comparable to the hand-coded Fortran + MPI versions of the NAS FT and CG benchmarks.
index46!@#@!1997!@#@!Two Loop Detection Mechanisms: A Comparision!@#@!Proceedings of the International Conference on Automated Reasoning with Analytic Tableaux and Related Methods!@#@!null
index47!@#@!2002!@#@!On Project-Specific Languages and Their Application in Reengineering!@#@!Proceedings of the 6th European Conference on Software Maintenance and Reengineering!@#@!We propose an approach for tuning reengineering tools to particular projects. This approach is based on the informal knowledge of the system, consisting of specific usages of the programming language. We illustrate this process with examples from an industrial project on PL/I to Java conversion.
index48!@#@!2003!@#@!The role of Jacobi polynomials in the theory of Hermite and Laguerre 2D polynomials!@#@!Journal of Computational and Applied Mathematics!@#@!Using an alternative definition of usual Hermite polynomials, two problems in the theory of general Hermite and Laguerre 2D polynomials can be separated with advantage for the further treatment: the introduction of a general 2D matrix in the linear transformation of powers of the components of a 2D vector and the generation of Hermite (or Laguerre) polynomials by applying an integral operator to these powers. The Jacobi polynomials appear in the finite-dimensional irreducible representations of the two-dimensional general linear group GL(2, C).
index49!@#@!2003!@#@!Energy trading: opening up energy trading!@#@!IEEE Spectrum!@#@!On 3 October 2001, Enron Corp.'s chief executive officer Ken Lay was in his element, chairing a day-and-a-half, invitation-only conference on national energy policy at a swanky hotel just outside Washington, D.C. It was wall-to-wall policy types, just the sort of gathering in which the Ph.D. economist reveled.
index50!@#@!1999!@#@!Closed user groups in Internet service centres!@#@!Proceedings of the IFIP WG 6.1 International Working Conference on Distributed Applications and Interoperable Systems II!@#@!null
index51!@#@!1995!@#@!Pseudo-exhaustive word-oriented DRAM testing!@#@!Proceedings of the 1995 European conference on Design and Test!@#@!This paper presents a new methodology for RAM testing based on the PS(n,k) q-ary fault model (q=2/sup w/) which includes most classical fault models for SRAMs and DRAMs. According to this fault model, the contents of any w-bit memory word of a memory with n words, or ability to change this contents, is influenced by the contents of any other k-1 words of the memory. The proposed methodology uses a pseudo-exhaustive technique based on Reed-Solomon codes, which can be efficiently applied to a word-oriented RAMs, assuming small values of k. The methodology ensures the detection of any number of disjoint (not linked) k-coupling faults, whereby the involved k words may be located anywhere in the memory; i.e., no assumptions have to be made on the physical topology of the cells in the memory cell array because of the systematic structure of the proposed tests, they are well suited for BIST implementations.
index52!@#@!1999!@#@!Message from the Symposium Chairpersons!@#@!Proceedings of the 14th International Symposium on Defect and Fault-Tolerance in VLSI Systems!@#@!null
index53!@#@!1996!@#@!Web intelligent query-disconnected Web browsing using cooperative techniques!@#@!Proceedings of the First IFCIS International Conference on Cooperative Information Systems!@#@!Mobile computers operate in constantly changing network environments. It is possible for a mobile computer to become temporarily "disconnected" from a network when it changes base stations or goes out of range of a base station. A mobile host may also "doze off" to preserve battery power. If, at the time it "goes down", a mobile computer is involved in a transaction process with another computer (mobile or static), it should be able to tolerate the "fault" of temporary disconnection. The work focuses on disconnected Web browsing from a mobile host. The current model of Web browsing is inherently sequential, and wasteful of bandwidth. The paper investigates an efficient model for browsing and presents a preliminary implementation.
index54!@#@!2002!@#@!Developing object-oriented enterprise quality frameworks using proto-frameworks!@#@!Software&mdash;Practice &amp; Experience!@#@!In this article, we present an approach to architecture-driven design of object-oriented frameworks based on the notion of object-oriented materialization of architectural styles. This approach leads us to the development of the proto-framework concept, which is a new denomination for an object-oriented framework that provides the essential basis to build other frameworks that adopt an underlying architectural design derived from non-object-oriented styles. In this context, we describe the approach to framework design, the design of a particular proto-framework called Bubble, and a real example of its application to the design of an enterprise framework.
index55!@#@!1995!@#@!Efficient algorithms for analyzing and synthesizing fault-tolerant datapaths!@#@!Proceedings of the IEEE International Workshop on Defect and Fault Tolerance in VLSI Systems!@#@!We address optimization problems arising in the synthesis of application specific integrated circuits (ASICs) that recover from transient faults via a rollback and retry approach. In this approach, each segment of a computation is duplicated and the results are compared using comparators. If the compared values are unequal, the computation is rolled back to the beginning of the segment (rollback point) and retried. Previous work in this area has generally been of an experimental nature focusing on heuristic approaches. We examine these problems from an algorithmic perspective. Several comparison and rollback strategies for reducing hardware costs and the delay caused by a transient fault have been previously proposed. For various combinations of these comparison and rollback strategies, we present efficient algorithms to analyze a given design to determine the maximum delay that can be caused by a transient fault of a given duration. These algorithms are based on formal characterizations of when a transient fault can cause a maximum delay for each combination of comparison and rollback strategies. We have also developed an efficient algorithm for designing fault-tolerant datapaths under hardware and delay constraints.
index56!@#@!2002!@#@!Fast and Guaranteed C Compilation onto the PACT-XPP" Reconfigurable Computing Platform!@#@!Proceedings of the 10th Annual IEEE Symposium on Field-Programmable Custom Computing Machines!@#@!null
index57!@#@!2002!@#@!Radon concentration in the atmosphere as an indicator of the height of the mixing layer in the region of mining activity!@#@!Development and application of computer techniques to environmental studies!@#@!The main objective of this work was examination whether measurement of polonium 218Po concentration in the atmosphere could be useful to evaluate the height of the mixing layer as an alternative method in relation to the theoretical or remote sensing methods. Data analysis based on study of variation of chosen meteorological parameters and its comparison with changes of the radon emanation power. The Fourier-, Wavelet- and Regression analysis were used for this aim. Finally one has been ascertained that meteorological conditions indirectly influenced the radon emanation power however its consequences had an essential meaning. On the other hand the relationship between the daily variation of the mixing height and polonium 218Po concentration in the atmosphere at the ground level was determined. As a result one has been stated that the polonium concentration could be an indicator of the mixing layer.
index58!@#@!2000!@#@!A Mixed Similarity Measure in Near-Linear Computational Complexity for Distance-Based Methods!@#@!Proceedings of the 4th European Conference on Principles of Data Mining and Knowledge Discovery!@#@!null
index59!@#@!2002!@#@!The stability problem for fuzzy bidirectional associative memories!@#@!Fuzzy Sets and Systems!@#@!The fuzzy bidirectional associative memories (FBAMs) are studied in this paper. It is shown that any FBAM based on the S-T composition is globally stable if both S and T are triangular norms or triangular conorms. When T is an upper semicontinuous triangular norm, some necessary and sufficient conditions are established in such a way that the FBAMs based on the max-T composition are globally stable, and the stable states and the equilibria of the FBAMs were studied. When T is a continuous triangular norm, it is proved that the sequence of reverberation states of the learning FBAM is nonincreasing.
index60!@#@!2000!@#@!Heuristics for Balancing Turbine Fans!@#@!Operations Research!@#@!We develop heuristics for a problem that models the static balancing of turbine fans: load point masses at regularly spaced positions on the periphery of a circle so that the residual unbalance about the center--which corresponds to the axis of rotation of the fan--is as small as possible. We give worst-case guarantees for our heuristics in terms of residual unbalance. For the case of an even number of blades, we show that one of our heuristics provides the same worst-case guarantee (with respect to the ideal of perfect balance) as does total enumeration. Furthermore, computational tests show that our heuristics are orders of magnitude faster and not far from optimum on average.
index61!@#@!2003!@#@!Blow-up solutions for a class of nonlinear parabolic equations with Dirichlet boundary conditions!@#@!Nonlinear Analysis: Theory, Methods &amp; Applications!@#@!In the present paper, the blow up of smooth local solutions for a class of nonlinear parabolic equations u,t = ∇(a(u)∇u) + f(x, u, q, t) (q = |∇u|2) with Dirichlet boundary conditions are studied. By constructing an auxiliary function and using Hopf's maximum principles on it, the sufficient conditions for blow-up solutions are obtained and the upper bound of "blow-up time" is given under some suitable assumptions on a, f and initial date. The obtained results are applied to some examples in which a and f are exponential functions.
index62!@#@!2003!@#@!Welcome 2003 CCSC: mid-south conference!@#@!Journal of Computing Sciences in Colleges!@#@!null
index63!@#@!2001!@#@!Extending MSC for Reactive Systems!@#@!HCC!@#@!Message Sequence Chart(MSC) is a visual language thatillustrates the scenarios of system operations, offering user-friendly,easy to understand behavior descriptions. Furthermore,high-level MSC(HMSC) provides compositionmechanisms to deal with complexity of the system. However,for the MSC to be used to describe complex reactivesystems, there should be ways to deal with the reactive behaviorsthat require the system to respond immediately. Inthis paper, we propose extensions of MSC to describe complexreactive behaviors in a systematic way. We define theformal semantics of the extended features based on processalgebra as well as the visual and textual syntax. The extensionsallow structured, systematic and succinct descriptionof complex reactive behaviors.
index64!@#@!1999!@#@!Co-Evolving Demes of Non-Uniform Cellular Automata for Synchronisation!@#@!Proceedings of the 1st NASA/DOD workshop on Evolvable Hardware!@#@!Emergent computation refers to systems in which global information processing appears as a result of the interactions among many components, each of which may be a system that exhibits an ability for emergent computation at a different level of self-organisation. In this paper, we employ a modification of cellular programming to evolve cellular machines for synchronisation. This allows global computation to occur by many local interactions among computational demes of interacting cells. The computational machine, derived from the non-uniform cellular automata model, consists of a grid of cells which are co-evolved in isolated demes. We describe experiments which show that demes can be co-evolved to perform non-trivial computation. We also analyse the mechanisms of computation within the different synchronising demes. Our results not only show that the co-evolution of demes is possible, but that they can attain high computational performance through co-operative action.
index65!@#@!2002!@#@!Benchmarking!@#@!IT measurement: practical advice from experts!@#@!null
index66!@#@!2002!@#@!Merging multiple data streams on common keys over high performance networks!@#@!Proceedings of the 2002 ACM/IEEE conference on Supercomputing!@#@!The model for data mining on streaming data assumes that there is a buffer of fixed length and a data stream of infinite length and the challenge is to extract patterns, changes, anomalies, and statistically significant structures by examining the data one time and storing records and derived attributes of length less than N. As data grids, data webs, and semantic webs become more common, mining distributed streaming data will become more and more important. The first step when presented with two or more distributed streams is to merge them using a common key. In this paper, we present two algorithms for merging streaming data using a common key. We also present experimental studies showing these algorithms scale in practice to OC-12 networks.
index67!@#@!1999!@#@!On the Application of Personalization Techniques to News Servers on the WWW!@#@!Proceedings of the 6th Congress of the Italian Association for Artificial Intelligence on Advances in Artificial Intelligence!@#@!null
index68!@#@!1980!@#@!Segmentierung von Blutzellbildern unter Ber&uuml;cksichtigung von a priori Wissen &uuml;ber den Bildinhalt!@#@!Erzeugung und Analyse von Bildern und Strukturen, DGaO-DAGM Tagung!@#@!null
index69!@#@!1997!@#@!Modular Composition of Transaction Programs with Deductive Databases!@#@!Proceedings of the 6th International Workshop on Database Programming Languages!@#@!null
index70!@#@!2002!@#@!Observability and the case of probability!@#@!Data mining, rough sets and granular computing!@#@!The modeling of problems in scientific observation has motivated the development of mathematical tools to deal with the several ways of classifying or granulating the universes of discourse: the world as it is perceived. The aim of this paper is to review and clarify various mathematical aspects related to observability problems within a classical boolean structure or a fuzzy context. In doing so, it is shown how ideas arising in Fuzzy Sets theory can become fine tools to handle most of the granulating problems. In the last section we study the observability of the label "probable" viewed as a fuzzy set.
index71!@#@!2003!@#@!Hardware-assisted view-dependent isosurface extraction using spherical partition!@#@!Proceedings of the symposium on Data visualisation 2003!@#@!Extracting only the visible portion of an isosurface can improve both the computation efficiency and the rendering speed. However, the visibility test overhead can be quite high for large scale data sets. In this paper, we present a view-dependent isosurface extraction algorithm utilizing occlusion query hardware to accelerate visible isosurface extraction. A spherical partition scheme is proposed to traverse the data blocks in a layered front-to-back order. Such traversal order helps our algorithm to identify the visible isosurface blocks more quickly with fewer visibility queries. Our algorithm can compute a more complete isosurface in a smaller amount of time, and thus is suitable for time-critical visualization applications.
index72!@#@!1997!@#@!History-Based Batch Job Scheduling on Workstation Clusters!@#@!Architektur von Rechensystemen, Arbeitsteilige Systemarchitekturen: Konzepte, L&ouml;sungen, Anwendungen, Trends - Vortr&auml;ge der 14. ITG/GI-Fachtagung ARCS '97!@#@!null
index73!@#@!2002!@#@!Introduction: special issue on the ninth Pacific Graphics Conference (PG 2001)!@#@!Graphical Models!@#@!null
index74!@#@!2001!@#@!Applied Information Security for m-Commerce and Digital Television Environments!@#@!Proceedings of the Second International Conference on Electronic Commerce and Web Technologies!@#@!null
index75!@#@!1996!@#@!A Comparative Analysis of Information Systems Issues Facing Canadian Business!@#@!Proceedings of the 29th Hawaii International Conference on System Sciences Volume 2: Decision Support and Knowledge-Based Systems!@#@!A national survey of 158 Canadian IS personnel at various organizational levels was conducted using a modified Delphi technique and follow-up interviews to identify the critical issues in information systems during the next three to five years. Critical information systems issues were identified including 1) building a responsive IT infrastructure, 2) improving IS project management practices, and 3) planning and managing communication networks. Significant differences in the rating of the importance of these issues were reported between small and large firms, private and public sector firms, IS executives and lower levels of IS personnel. A comparison of the current results with previous U.S. and Canadian studies revealed that Canadian IS personnel are currently placing a stronger emphasis on the need to address technology-related issues rather than managerial issues. Qualitative data to be collected in follow-up interviews will be reported at the conference to cast some light on the reasoning behind the ratings and the sources of information that were used in the assessment of their importance.
index76!@#@!1993!@#@!Linking System Design Tools and Hardware Design Tools!@#@!Proceedings of the 11th IFIP WG10.2 International Conference sponsored by IFIP WG10.2 and in cooperation with IEEE COMPSOC on Computer Hardware Description Languages and their Applications!@#@!null
index77!@#@!2002!@#@!Human-computer interaction for kids!@#@!The human-computer interaction handbook: fundamentals, evolving technologies and emerging applications!@#@!null
index78!@#@!1996!@#@!Policing function in ATM network using multi-layer neural network!@#@!Proceedings of the 21st Annual IEEE Conference on Local Computer Networks!@#@!Artificial neural networks provide an attractive alternative in performing the policing function at the user network interface (UNI) of an asynchronous transfer mode (ATM) network. In order to guarantee quality of service (QOS) for the established connections in ATM networks, one of the policing functions at the UNI is to ensure that all data streams entering the ATM network conform to the allocated bandwidth, or otherwise the cell loss priority (CLP) bit in the ATM cell header must be set to reflect the situation that the output of the UNI has exceeded the permissible bandwidth. Feed-forward neural networks with back-propagation learning algorithms are chosen to perform the policing function at the UNI. Numerical results are presented to illustrate that the neural network is capable of performing the policing function.
index79!@#@!2003!@#@!Making sense of the economy: entrepreneurial strategic thinking and acting as theory building and theory testing under ambiguity!@#@!Knowledge management and networked environments: leveraging intellectual capital in virtual business communities!@#@!null
index80!@#@!1996!@#@!Author Index!@#@!Proceedings of the 29th Hawaii International Conference on System Sciences Volume 2: Decision Support and Knowledge-Based Systems!@#@!Summary form only given. This presentation discusses wireless technologies that can be used in developing mobile work force solutions for both WAN and LAN environments. Recent wireless LAN product announcements from IBM's Networking Systems are also covered and positioned with these technologies, highlighting IBM's strengths. First, market segmentation and opportunities are reviewed along with customer benefits and value. Next, three wireless WAN technologies (circuit switched cellular, cellular digital packet data, and radio data networks) are discussed with their advantages and disadvantages. This is followed by wireless LAN technologies discussion, which includes important customer considerations and IBM strengths. Finally, the topic closes with a review of Networking System's wireless products and positioning relative to other IBM wireless products. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player
index81!@#@!2002!@#@!Monotone Systems in Data Mining!@#@!Proceedings of the Baltic Conference, BalticDB&amp;IS 2002 - Volume 2!@#@!null
index82!@#@!2002!@#@!ATTac-2001: A Learning, Autonomous Bidding Agent!@#@!Revised Papers from the Workshop on Agent Mediated Electronic Commerce on Agent-Mediated Electronic Commerce IV, Designing Mechanisms and Systems!@#@!null
index83!@#@!1996!@#@!Optimizing Path Expressions Using Navigational Algebraic Operators!@#@!Proceedings of the 7th International Conference on Database and Expert Systems Applications!@#@!null
index84!@#@!1999!@#@!Neural Networks for Combinatorial Optimization: a Review of More Than a Decade of Research!@#@!INFORMS Journal on Computing!@#@!It has been over a decade since neural networks were first applied to solve combinatorial optimization problems. During this period, enthusiasm has been erratic as new approaches are developed and (sometimes years later) their limitations are realized. This article briefly summarizes the work that has been done and presents the current standing of neural networks for combinatorial optimization by considering each of the major classes of combinatorial optimization problems. Areas which have not yet been studied are identified for future research.
index85!@#@!2002!@#@!Getting Most Out of Evolutionary Approaches!@#@!EH!@#@!Evolutionary algorithms (EAs) have been widely used in evolvable hardware. The very term, evolvable hardware, reflects the importance and omnitude of EAs in this field. However, EAs have primarily been used as an optimisation or search tool, which can explore a large and complex space. While success has been demonstrated by EAs in exploring unconventional designs that are hard to reach by human experts, it is interesting to ask the question whetherwe have fully used all the potentialities of EAs. We argue in this paper that there is rich information in a population which can and should be exploited. The classical approach of evolving the best individual in a population may not be the best one. A truly population-based approach that emphasizes population rather than the best individual can often bring in several important benefits to evolvable hardware, including efficiency, accuracy, adaptiveness, andfault-tolerance.
index86!@#@!2003!@#@!Secure environment for real-time tele-collaboration on virtual simulation of radiation treatment planning!@#@!Technology and Health Care!@#@!A secure framework is described for real-time tele-collaboration on Virtual Simulation procedure of Radiation Treatment Planning. An integrated approach is followed clustering the security issues faced by the system into organizational issues, security issues over the LAN and security issues over the LAN-to-LAN connection. The design and the implementation of the security services are performed according to the identified security requirements, along with the need for real time communication between the collaborating health care professionals. A detailed description of the implementation is given, presenting a solution, which can directly be tailored to other tele-collaboration services in the field of health care. The pilot study of the proposed security components proves the feasibility of the secure environment, and the consistency with the high performance demands of the application.
index87!@#@!1999!@#@!Computation of Symmetry Measures for Polygonal Shapes!@#@!Proceedings of the 8th International Conference on Computer Analysis of Images and Patterns!@#@!null
index88!@#@!1998!@#@!A Hierarchical Approach to Managing Dairy Routing!@#@!Interfaces!@#@!We designed and implemented a decision support system to organize the delivery network for the products of a large dairy. To deal with this complex problem, we employed a five-level hierarchic structure distributing the clients among the sales promoters in the levels of greater aggregation and assigning shops to individual drivers in the level with the greatest detail, which corresponds to a version of the traveling salesman problem with time windows. We implemented the model on a microcomputer, importing the necessary data from the company mainframe.
index89!@#@!1999!@#@!Message from the General Co-Chairs!@#@!Proceedings of the Sixth Asia Pacific Software Engineering Conference!@#@!null
index90!@#@!2002!@#@!Goodput Analysis and Link Adaptation for IEEE 802.11a Wireless LANs!@#@!IEEE Transactions on Mobile Computing!@#@!Link adaptation to dynamically select the data transmission rate at a given time has been recognized as an effective way to improve the goodput performance of the IEEE 802.11 wireless local-area networks (WLANs). Recently, with the introduction of the new high-speed 802.11a physical layer (PHY), it is even more important to have a well-designed link adaptation scheme work with the 802.11a PHY such that its multiple transmission rates can be exploited. In this paper, we first present a generic method to analyze the goodput performance of an 802.11a system under the Distributed Coordination Function (DCF) and express the expected effective goodput as a closed-form function of the data payload length, the frame retry count, the wireless channel condition, and the selected data transmission rate. Then, based on the theoretical analysis, we propose a novel MPDU (MAC Protocol Data Unit)-based link adaptation scheme for the 802.11a systems. It is a simple table-driven approach and the basic idea is to preestablish a best PHY mode table by applying the dynamic programming technique. The best PHY mode table is indexed by the system status triplet that consists of the data payload length, the wireless channel condition, and the frame retry count. At runtime, a wireless station determines the most appropriate PHY mode for the next transmission attempt by a simple table lookup, using the most up-to-date system status as the index. Our in-depth simulation shows that the proposed MPDU-based link adaptation scheme outperforms the single-mode schemes and the AutoRate Fallback (ARF) scheme¿which is used in Lucent Technologies' WaveLAN-II networking devices¿significantly in terms of the average goodput, the frame drop rate, and the average number of transmission attempts per data frame delivery.
index91!@#@!1997!@#@!Optimal Adaptive Broadcasting with a Bounded Fraction of Faulty Nodes (Extended Abstract)!@#@!Proceedings of the 5th Annual European Symposium on Algorithms!@#@!null
index92!@#@!2003!@#@!On exponential h-expansiveness of semigroups of operators in Banach spaces!@#@!Nonlinear Analysis: Theory, Methods &amp; Applications!@#@!This paper introduces the concept of exponential h-expansiveness for semigroups of nonlinear operators, which is an extension of classical concept of exponential expansiveness. Following the idea of obtaining an unitary treatment for stability and expansiveness, necessary and sufficient conditions for exponential h-expansiveness are given. As particular cases, the variants for exponential expansiveness of some well-known stability results due to Datko, Pazy, Ichikawa, Rolewicz and Neerven are obtained.
index93!@#@!2000!@#@!Parallel Parsing of MPEG Video in a Multi-threaded Multiprocessor Environment!@#@!Proceedings of the 15 IPDPS 2000 Workshops on Parallel and Distributed Processing!@#@!null
index94!@#@!2003!@#@!Erratum: P. van Beek and R. Dechter's theorem on constraint looseness and local consistency!@#@!Journal of the ACM (JACM)!@#@!null
index95!@#@!2000!@#@!Visualizing Multidimensional Raster Data with rView!@#@!Proceedings of the 11th International Workshop on Database and Expert Systems Applications!@#@!rView is a visual front end to the RasDaMan DBMS, providing raster data visualization functionality and a graphical user interface to the database system. RasDaMan, a commercial array DBMS whose prototype has been developed by FORWISS, is designed for raster data of arbitrary dimensionality and base type, which makes it a powerful storage system for all types of rastered data. This generality calls for a similarity flexible visualization tool for data stored in the database. rView has been designed as a generic visualization tool with very few restrictions regarding dimensionality and base (i.e., array cell) type; among other things, it provides several visualization techniques like texture mapping, voxel- and height field rendering, which may be combined with user-configurable mappings to the RGB colour space.
index96!@#@!1998!@#@!Improved Empty Freight Car Distribution!@#@!Transportation Science!@#@!In this paper we consider the problem of distributing empty freight cars in a railway company. We describe and analyze the current planning process, identify the shortcomings of the process, and stress the importance of a reliable distribution process for satisfying customer demand and reducing capital costs. We show how the process can be improved using an optimization model which includes capacity constraints on the trains and adheres explicitly to the arrival and departure times of the trains. The optimization model can be characterized as a multicommodity network flow model with integer requirements. Computational tests show that the model can be solved in acceptable time for real size problems, and indicate that the model generates distribution plans that can improve the quality of the planning process.
index97!@#@!1999!@#@!Evaluating the complexity of databases for person identification and verification!@#@!Proceedings of the 8th International Conference on Computer Analysis of Images and Patterns!@#@!null
index98!@#@!2000!@#@!Online dynamic reordering!@#@!The VLDB Journal &mdash; The International Journal on Very Large Data Bases!@#@!We present a pipelining, dynamically tunable reorder operator for providing user control during long running, data- intensive operations. Users can see partial results and accordingly direct the processing by specifying preferences for various data items; data of interest is prioritized for early processing. The reordering mechanism is efficient and non-blocking and can be used over arbitrary data streams from files and indexes, as well as continuous data feeds. We also investigate several policies for the reordering based on the performance goals of various typical applications. We present performance results for reordering in the context of an online aggregation implementation in Informix and in the context of sorting and scrolling in a large-scale spreadsheet. Our experiments demonstrate that for a variety of data distributions and applications, reordering is responsive to dynamic preference changes, imposes minimal overheads in overall completion time, and provides dramatic improvements in the quality of the feedback over time. Surprisingly, preliminary experiments indicate that online reordering can also be useful in traditional batch query processing, because it can serve as a form of pipelined, approximate sorting.
index99!@#@!1992!@#@!Usenet Nuggets!@#@!ACM SIGARCH Computer Architecture News!@#@!null
index100!@#@!2003!@#@!Inside risks!@#@!Communications of the ACM!@#@!null
index101!@#@!1996!@#@!On the Removal of Anti and Output Dependences!@#@!Proceedings of the IEEE International Conference on Application-Specific Systems, Architectures, and Processors!@#@!In this paper we build upon results of Padua and Wolfe who introduce two graph transformations to eliminate anti and output dependences. We first give a unified framework for such transformations. Then, given a loop nest, we aim at determining which statements should be transformed so as to break artificial cycles involving anti or output dependences. The problem of finding the minimum number of statements to be transformed is shown to be NP-complete in the strong sense, and we propose two efficient heuristics.
index102!@#@!2003!@#@!On natural living room communication with "ComAdapter": adapting to the differences in room structure!@#@!CHI '03 extended abstracts on Human factors in computing systems!@#@!Aiming at rich and useful communication in our daily home life, we propose a novel communication concept, "ComAdapter", in which people can mutually share their intention and emotion by exchanging their spontaneous behavior. ComAdapter can create shared space communication that allow us to communicate with another party in a remote location as though other party has entered our room. To achieve this, ComAdapter offsets the differences in the configurations of the rooms. In a simple preliminary system, body motions are successfully adapted and transmitted between two rooms with different layout. The success of the experiment confirms the validity and potential of ComAdapter.
index103!@#@!1998!@#@!Making Good Features Track Better!@#@!Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition!@#@!null
index104!@#@!1996!@#@!Ordinal Measures for Visual Correspondence!@#@!CVPR!@#@!We present ordinal measures for establishing image correspondence. Linear correspondence measures like correlation and the sum of squared differences are known to be fragile. Ordinal measures, which are based on relative ordering of intensity values in windows, have demonstrable robustness to depth discontinuities, occlusion and noise. The relative ordering of intensity values in each window is represented by a rank permutation which is obtained by sorting the corresponding intensity data. By using a novel distance metric between the rank permutations, we arrive at ordinal correlation coefficients. These coefficients are independent of absolute intensity scale, i.e they are normalized measures. Further, since rank permutations are invariant to monotone transformations of the intensity values, the coefficients are unaffected by nonlinear effects like gamma variation between images. We have developed a simple algorithm for their efficient implementation. Experiments suggest the superiority of ordinal measures over existing techniques under non-ideal conditions. Though we present ordinal measures in the context of stereo, they serve as a general tool for image matching that is applicable to other vision problems such as motion estimation and image registration.
index105!@#@!1986!@#@!&Uuml;bersichtsvortrag: Methoden der digitalen Signalverarbeitung in der Bildverarbeitung und Mustererkennung!@#@!Mustererkennung 1986, 8. DAGM-Symposium!@#@!null
index106!@#@!2002!@#@!Improving the design of business and interactive system concepts in a digital business consultancy!@#@!Designing Interactive Systems!@#@!Often, the multidisciplinary design of business and interactive system concepts is not particularly collaborative nor nearly as "user-centered" as the organization doing the design claims. This paper describes efforts at changing that within a high speed and low resource environment by involving all disciplines in early user research and in the synthesis of the findings and their application to design activities. The focus is on two high-profile design projects, one involving personal media management and the other involving organizational knowledge management. We describe what we did and why, and how well what we did worked, with particular attention to the affects of organizational culture and politics on success.
index107!@#@!1997!@#@!Dedan: A Kernel of Data Structures and Algorithms for Automated Deduction with Equality Clauses!@#@!Proceedings of the 14th International Conference on Automated Deduction!@#@!null
index108!@#@!2003!@#@!Sensors Assisted Telemanipulation for Maximizing Manipulation Capabilities of Persons With Disabilities!@#@!HAPTICS!@#@!This paper describes a telemanipulation system to assist persons with disabilities performed dexterous manipulation tasks. This research is expected to enhance the teleoperation performanc through the use of scaled mapping from master to slave manipulation based uponsensory data. This is particularly useful when the user has restricted range of movements due to certain disabilities such as muscular dystrophy, a stroke, or any form of pathological tremor.Assistance functions are used for mapping such that human input is enhanced rather than superseded by the computer. A common vocational rehabilitation test referred to as Box and Blocks was chosen to test the effectiveness of this sensor-assisted function. A variable scaling scheme was developed using available sensory data.In the simulation mode, a visual environment was created for the Box and Blocks test. This was used to predict if a person with disabilities would be able to perform a task comfortably. The real test was performed using a master and slave manipulator system with acamera and laser rang finder. A motion constraint was added to the master to simulate a user with disabilities. The results demonstrated that the sensor assistance not only reduced required input motion, idle time, and execution time, but also increased manipulation accuracyduring the Box and Blocks test.
index109!@#@!2003!@#@!Modeling uncertainty in flow simulations via generalized polynomial chaos!@#@!Journal of Computational Physics!@#@!We present a new algorithm to model the input uncertainty and its propagation in incompressible flow simulations. The stochastic input is represented spectrally by employing orthogonal polynomial functionals from the Askey scheme as trial basis to represent the random space. A standard Galerkin projection is applied in the random dimension to obtain the equations in the weak form. The resulting system of deterministic equations is then solved with standard methods to obtain the solution for each random mode. This approach can be considered as a generalization of the original polynomial chaos expansion, first introduced by Wiener [Am. J. Math. 60 (1938) 897]. The original method employs the Hermite polynomials (one of the 13 members of the Askey scheme) as the basis in random space. The algorithm is applied to micro-channel flows with random wall boundary conditions, and to external flows with random freestream. Efficiency and convergence are studied by comparing with exact solutions as well as numerical solutions obtained by Monte Carlo simulations. It is shown that the generalized polynomial chaos method promises a substantial speed-up compared with the Monte Carlo method. The utilization of different type orthogonal polynomials from the Askey scheme also provides a more efficient way to represent general non-Gaussian processes compared with the original Wiener-Hermite expansions.
index110!@#@!1993!@#@!Knowledge Extraction from Machine-Readable Dictionaries: An Evaluation!@#@!Proceedings of the Third International EAMT Workshop on Machine Translation and the Lexicon!@#@!null
index111!@#@!1996!@#@!Back-pressure buffering scheme to improve the cell loss property on the output buffered ATM switch!@#@!Proceedings of the 21st Annual IEEE Conference on Local Computer Networks!@#@!We have studied back-pressure buffering mechanisms to improve the cell loss property in output buffered ATM switches. In order to minimize the cell loss in an output buffer, the back-pressure buffering mechanism pressures the transmission of input cells to the switch fabric according to the load status of the output buffer. We have studied and proposed two back-pressure buffering mechanisms; one is the push-out mechanism with a single FIFO and the other is the selective pressure mechanism with a shared memory. The main subjects of this study were: (1) a performance comparison using computer simulation between a system without back-pressure buffering and a system with the proposed back-pressure schemes and (2) a proposal for a practical implementation structure. Through the simulation results, we conclude that a pure push-out mechanism cannot improve the performance but a selective pressure mechanism will provide enormous improvement of the cell loss property with a small sized memory.
index112!@#@!1995!@#@!TRJM: a high speed programmable ATM-SDH mapper!@#@!Proceedings of the 1995 European conference on Design and Test!@#@!Presents the design of the TRJM integrated circuit. This ASIC has been developed to implement the ATM transmission convergence sublayer interfaces for different SONET rates and its SDH equivalents. The chip has been manufactured using a standard cell 0.6 microns 3-layer metal CMOS technology. It contains 350,000 transistors split in 42 K gates and 18 Kbit from dual port RAM.
index113!@#@!2003!@#@!A MAC Protocol for New and Handoff Calls with Finite Population!@#@!Wireless Personal Communications: An International Journal!@#@!A MAC protocol for new and handoff calls with a finite population of users, rather than with an infinite user population as in dynamic channel reservation scheme (DCRS), is considered. Similar to DCRS, we divide the wireless channels into shared channels and reserved channels. The handoff calls access any available channel with probability of one, while the new calls access a shared channel with probability of one and access a reserved channel with a request probability. We propose three simpler formulae than that used in the existing DCRS in setting the request probability. In addition, the handoff calls in our proposed protocol are allowed to queue in a finite buffer. To evaluate the system performance, a mathematical model based on queuing theory, rather than a simulation method used in DCRS, is developed. It is a general model that can be adopted for any types of request probabilities including DCRS. Suggestions of how to get the optimum values of the design parameters are also given.
index114!@#@!1993!@#@!GCV-Aided Linear Image Regularization for the Reconstruction of Wave Distribution Function of Magnetospheric VLF/ELF Waves!@#@!Proceedings of the 5th International Conference on Computer Analysis of Images and Patterns!@#@!null
index115!@#@!2002!@#@!An expert system for evaluating the make or buy decision!@#@!Computers and Industrial Engineering!@#@!The aim of this paper is to show how a knowledge-based systems technology can assist in the area of strategic purchasing. The authors discuss a knowledge-based system (KBS) designed to help companies in the make or buy decision, which is arguably the most fundamental component of manufacturing strategy. A model of the make or buy decision was developed conceptually from a thorough review of the literature and was supported by a series of interviews with procurement managers. The model consists of five main stages: identifying and weighting performance categories; analyzing technical capabilities; comparing internal and external capabilities; analyzing supplier organizational capabilities; total acquisition cost analysis. A KBS was developed which incorporates these five phases into the outsourcing decision. Preliminary evaluation indicates that the KBS can assist the purchasing team by providing feedback to suppliers, monitoring suppliers against performance benchmarks, improving cooperation between the multifunctional purchasing team members and reduces the time involved in conducting the make or buy evaluation. Ultimately, the KBS tool developed can assist an organization in enhancing its competitive position.
index116!@#@!2001!@#@!Multiple-writer entry consistency!@#@!Cluster computing!@#@!In this paper, we present the design, implementation and evaluation of a new distributed shared memory (DSM) coherence model called multiple-writer entry consistency (MEC). MEC combines the efficient communication mechanisms of Lazy Release Consistency (LRC) with the flexible data management of the Shared Regions [17, 11] and Entry Consistency (EC) models [5]. This is achieved in MEC by decoupling synchronization from coherence (in contrast to the tight coupling of synchronization and coherence present in EC)while retaining the familiar synchronization structure found in Release Consistent (RC) programs. The advantage of MEC is that it allows region-based coherence protocols (those that manage data at the granularity of user-defined shared regions) to be used along side page-based protocols within an application and within the RC framework. Our experimental evaluation on an 8 processor system shows that using MEC reduces parallel execution times by margins ranging from 5% to 46% in five of the six applications that we study. However, the parallel execution time of the LRC version of the remaining application is lower than the MEC version by 48%. We conclude that offering both page-based and region-based models for coherence within the same system is not only practical but necessary.
index117!@#@!2002!@#@!Aggregation principle in the theory of nonlinear PDE!@#@!Technologies for constructing intelligent systems: tools!@#@!It is considered a pair of generalized aggregation operators connected by distributive law. It is given a complete characterization of such pairs of operations. The obtained results are applied on nonlinear PDE.
index118!@#@!1998!@#@!A Metadata Architecture for Digital Libraries!@#@!Proceedings of the Advances in Digital Libraries Conference!@#@!From an architectural perspective there is no essential distinction between data and metadata. Both can be represented in Distributed Active Relationships (DARs) which are an extension of the Warwick Framework. The DAR model is a powerful way to express relationships between networked resources and allow such relationships to be dynamically downloadable and executable.
index119!@#@!2003!@#@!A survey of permission-based distributed mutual exclusion algorithms!@#@!Computer Standards &amp; Interfaces!@#@!The problem of mutual exclusion in distributed systems has attracted considerable attention over the last two decades. The mutual exclusion problem requires that, at a time, only one of the contending processes be allowed to enter its critical section (CS). A number of solutions have been provided to the mutual exclusion problem in distributed systems. Different algorithms have used different techniques to achieve mutual exclusion and have different performances. Depending on the technique used, these algorithms have been classified as token-based and permission-based algorithms. In this paper, we present a survey of various permission-based distributed mutual exclusion (PBDME) algorithms and their comparative performance.
index120!@#@!1990!@#@!A Resolution Principle for Clauses with Constraints!@#@!Proceedings of the 10th International Conference on Automated Deduction!@#@!null
index121!@#@!1993!@#@!Algorithms for Shape from Shading, Lighting Direction and Motion!@#@!Proceedings of the 5th International Conference on Computer Analysis of Images and Patterns!@#@!null
index122!@#@!1996!@#@!An analysis of impacts of long-term traffic correlations on congestion control in ATM-based local computer networks!@#@!Proceedings of the 21st Annual IEEE Conference on Local Computer Networks!@#@!We analyse the impacts of the long-term correlations discovered in data and video traffic on congestion control in ATM-based local area networks based on catastrophe theory. Our work shows that long-term correlations may cause the network performance to degrade catastrophically even if the cell rate of the traffic source can be adjusted dynamically according to the network load and the peak cell rate can be bounded effectively. Experimental evidence exists supporting our analytical results. Therefore, without taking traffic correlations into account, congestion control and quality-of-service guarantees may not be effective.
index123!@#@!2003!@#@!A Synthesis of P rallel Out-of-core Sorting Programs on Heterogeneous Clusters!@#@!Proceedings of the 3st International Symposium on Cluster Computing and the Grid!@#@!The paper considers he problem of parallel external sorting in the contex of a form of heterogeneousclusters. We introduce two algorithms and we compare them two another one that we have previously developed. Since most common sort algorithms assumehigh-speed random access to all intermediate memory,they are unsuitable if the values to be sorted don't fitin main memory. This is the case for cluster computing platforms which are made of standard, cheap andscarce components. For that class of computing resources a good use of I/O operations compatible withthe requirements of load balancing and computationalcomplexity are the key to success. We explore threetechniques and show how they can be deployed forclusters with processor performances related by a multiplicative factor. We validate the approaches in showing experimental results for the load balancing factor.
index124!@#@!2002!@#@!Review of "The internet and society" by James Slevin. Cambridge, MA, Polity press, 2000!@#@!Social Science Computer Review!@#@!null
index125!@#@!2003!@#@!Optimizing Rhenania's Mail-Order Business Through Dynamic Multilevel Modeling (DMLM)!@#@!Interfaces!@#@!Rhenania, a German direct mail-order company, turned its catalog mailing practices around within one year and consequently moved up in market position from number 5 to number 2. A dynamic multilevel modeling (DMLM) approach uses elasticities to determine the optimal frequency of catalog mailings, a customer-segmentation approach allows for optimization of mailings, and a recency, frequency, monetary-value (RFM) segmentation in combination with a chi-square automatic interaction detection (CHAID) algorithm determines when customers should receive a reactivation package--as opposed to a catalog--to optimize mailing efficiency further. The DMLM approach was so effective that Rhenania acquired two competitors (one a subdivision of Springer Verlag).
index126!@#@!2001!@#@!Tracking of fluid-advected odor plumes: strategies inspired by insect orientation to pheromone!@#@!Adaptive Behavior!@#@!Autonomous vehicles with plume-tracing capabilities would be valuable for finding chemical sources in fluid flows. This article considers strategies allowing autonomous vehicles to find and trace an odor plume to its source. These strategies are inspired by the maneuvers of moths flying upwind along a pheromone plume. Although moth maneuvers are well documented, the mechanisms underlying sensory perception and navigation are not fully understood; therefore, a key objective was to define sensor, signal-processing, and actuation algorithms for autonomous vehicles. The strategies presented do not precisely mimic insect orientation to odors. Optimizing performance, however, suggests orientation strategies that may have biological counterparts. The results demonstrate the importance of cross-plume counterturning strategies for maintaining intermittent contact with the chemical plume, given noisy sensory information. It is important for the searcher to maintain intermittent contact with the plume because flow direction while detecting odor is the main indicator of the instantaneous desired direction of motion.
index127!@#@!1997!@#@!Hypothesis Testing Approach on Noisy Cases in RICAD!@#@!Proceedings of the 1997 IEEE Knowledge and Data Engineering Exchange Workshop!@#@!Enabling the database applications to perform intelligent records retrieval is one of the important issues in database research. From one perspective, this particular issue has also been investigated in artificial intelligence (AI) research. Case-Based Reasoning (CBR) is an approach in AI that focuses on a similar issue. CBR systems mainly try to find the most similar cases from their case bases, and propose their answers based on the found cases. However, the main problem with this approach is that noisy cases can directly affect the accuracy of proposed solutions. This problem can also occur in database applications, if they also intend to formulate the correct answer for their users rather than just retrieving the records. This paper reviews the current practice in CBR research, especially on how the CBR systems are dealing with the problem of noisy cases, and describes how RICAD deals with noisy cases.
index128!@#@!2002!@#@!Summed squared distance error reduction by simultaneous multiprojections and applications!@#@!Applied Mathematics and Computation!@#@!A parallel projection scheme in which projections are performed simultaneously on all constraints at each iteration is presented. It is a multiprojections scheme because different distance functions can be minimized for each projection as long as they are based on weighted L2 norms. The use of multiple distance functions enables simplifications of the various projection operations, leading to an efficient implementation of this algorithm. This is true especially for constrained deconvolution type problems. Due to the inherent parallelism of the algorithm, projections onto more than two sets can be performed, even if one (or more) of the sets are nonconvex, maintaining a monotone decrease of a cost functional (with no further restrictions). This is in contrast to the serial projections onto convex sets (POCS) algorithm where no more than two sets can be treated if one of the sets is nonconvex. Our method is a special case of a multiprojections method proposed by Censor and Elfving where generalized distance functions of the Bregman type are used. The restriction to weighted L2 norms leads to a simple and explicit form of this algorithm and allows relaxation and the use of nonconvex sets.
index129!@#@!2002!@#@!A Self-Timed Arithmetic Unit for Elliptic Curve Cryptography!@#@!Proceedings of the Euromicro Symposium on Digital Systems Design!@#@!This paper describes an efficient implementation of a crypto arithmetic unit, which computes the modular-operations addition, multiplication, and inversion in prime fields. These calculations are important for an application in elliptic curve cryptography (ECC). The hardware is designed in a self-timed and low-power approach. The paper discusses the pros and cons of this approach compared to a synchronous implementation.
index130!@#@!2001!@#@!Dynamic Control of a Queue with Adjustable Service Rate!@#@!Operations Research!@#@!We consider a single-server queue with Poisson arrivals, where holding costs are continuously incurred as a nondecreasing function of the queue length. The queue length evolves as a birth-and-death process with constant arrival rate ? = 1 and with state-dependent service rates Âµ nthat can be chosen from a fixed subset A of [0, 8). Finally, there is a nondecreasing cost-of-effort functionc(Â·) on A, and service costs are incurred at ratec(Âµ n ) when the queue length isn. The objective is to minimize average cost per time unit over an infinite planning horizon. The standard optimality equation of average-cost dynamic programming allows one to write out the optimal service rates in terms of the minimum achievable average costz*. Here we present a method for computingz* that is so fast and so transparent it may be reasonably described as an explicit solution for the problem of service rate control. The optimal service rates are nondecreasing as a function of queue length and are bounded if the holding cost function is bounded. From a managerial standpoint it is natural to comparez*, the minimum average cost achievable with state-dependent service rates, against the minimum average cost achievable with a single fixed service rate. The difference between those two minima represents the economic value of a responsive service mechanism, and numerical examples are presented that show it can be substantial.
index131!@#@!2000!@#@!Modifications of Uncertain Data: A Bayesian Framework for Belief Revision!@#@!Information Systems Research!@#@!The inherent uncertainty pervasive over the real world often forces business decisions to be made using uncertain data. The conventional relational model does not have the ability to handle uncertain data. In recent years, several approaches have been proposed in the literature for representing uncertain data by extending the relational model, primarily using probability theory. The aspect of database modification, however, has not been addressed in prior research. It is clear that any modification of existing probabilistic data, based on new information, amounts to the revision of one's belief about real-world objects. In this paper, we examine the aspect of belief revision and develop a generalized algorithm that can be used for the modification of existing data in a probabilistic relational database. The belief revision scheme is shown to beclosed,consistent, andcomplete.
index132!@#@!1995!@#@!Fundamentals of Context=Sensitive Rewriting!@#@!Proceedings of the 22nd Seminar on Current Trends in Theory and Practice of Informatics!@#@!null
index133!@#@!2003!@#@!Editorial!@#@!Wireless Networks!@#@!null
index134!@#@!2003!@#@!Detection and Analysis of Unexpected State Components in Biological Systems!@#@!Proceedings of the First International Workshop on Computational Methods in Systems Biology!@#@!null
index135!@#@!1987!@#@!Or-Parallel Execution Models of Prolog!@#@!Proceedings of the International Joint Conference on Theory and Practice of Software Development, Volume 2: Advanced Seminar on Foundations of Innovative Software Development II and Colloquium on Functional and Logic Programming and Specifications (CFLP)!@#@!null
index136!@#@!1998!@#@!Heuristics for Finding Large Independent Sets, with Applications to Coloring Semi-random Graphs!@#@!Proceedings of the 39th Annual Symposium on Foundations of Computer Science!@#@!We study a semi-random graph model for finding independent sets. For q>0, an n-vertex graph with an independent set S of size qn is constructed by blending random and adversarial decisions. Randomly and independently with probability p, each pair of vertices, such that one is in S and the other is not, is connected by an edge. An adversary can then add edges arbitrarily (provided that S remains an independent set). The smaller p is, the larger the control the adversary has over the semi-random graph. We design heuristics that with high probability recover S when p>(1+e)ln(n)/|S|, for any constant e>0. We show that when p
index137!@#@!1999!@#@!Towards a Model for Spatio-Temporal Schema Selection!@#@!Proceedings of the 10th International Workshop on Database & Expert Systems Applications!@#@!Schema versioning provides a mechanism for handling change in the structure of database systems and has been investigated widely, both in the context of static and temporal databases. With the growing interest in spatial and spatio-temporal data as well as the mechanisms for holding such data, the spatial context within which data is formatted also becomes an issue. This paper presents a generalized model that accommodates schema versioning within static, temporal, spatial and spatio-temporal relational and object-oriented databases.
index138!@#@!1995!@#@!Interconnection of FDDI-II networks through an ATM backbone- An analysis!@#@!Proceedings of the 20th Annual IEEE Conference on Local Computer Networks!@#@!The waiting time and queue length characteristics of isochronous, synchronous and asynchronous traffic at the gateway between FDDI-II and ATM networks are analyzed. A generalized approach to analyze various classes of traffic separately, is discussed. We first present an overview of our gateway model. Next, a deterministic analysis of isochronous traffic is presented. Synchronous and asynchronous classes of traffic are analyzed with the gateway model used. These results are compared with those generated by our simulator.
index139!@#@!1999!@#@!Multi-Chip Neuromorphic Motion Processing!@#@!Proceedings of the 20th Anniversary Conference on Advanced Research in VLSI!@#@!We describe a multi-chip CMOS VLSI visual motion processing system which combines analog circuitry with an asynchronous digital interchip communications protocol to allow more complex motion processing than is possible with all the circuitry in the focal plane. The two basic VLSI building blocks are a sender chip which incorporates a 2D imager array and transmits the position of moving spatial edges, and a receiver chip which computes a 2D optical flow vector field from the edge information. The elementary two-chip motion processing system consisting of a single sender and receiver is first characterized. Subsequently, two three-chip motion processing systems are described. The first such system uses two sender chips to compute the presence of motion only at a particular stereoscopic disparity. The second such system uses two receivers to simultaneously compute a linear and polar topographic mapping of the image plane, resulting in information about image translation, rotation, and expansion. These three-chip systems demonstrate the modularity and flexibility of the multi-chip neuromorphic approach.
index140!@#@!1999!@#@!Rate-Distortion Analysis of Spike Processes!@#@!Proceedings of the Conference on Data Compression!@#@!Recent rate distortion analyses of image transform coders are based on a trade-off between the lossless coding of coefficient positions vs. the lossy coding of the coefficient values. We propose spike processes as a tool that allows a more fundamental trade-off, namely between lossy position coding and lossy value coding. We investigate the Hamming distortion case and give analytic results for single and multiple spikes. We then consider upper bounds for a single Gaussian spike with squared error distortion. The obtained results show a rate distortion behavior which switches from linear at low rates to exponential at high rates.
index141!@#@!2001!@#@!User-centered design methods in practice: a survey of the state of the art!@#@!Proceedings of the 2001 conference of the Centre for Advanced Studies on Collaborative research!@#@!This paper reports the results of a recent survey involving over one hundred leading professionals of user-centered design (UCD). The survey covered a broad range of issues ranging from the profile of a typical UCD project including the percentage of total budget on UCD, organizational impact of UCD, measures of UCD success, and the most widely used methods and techniques. Results show that cost-benefit tradeoffs are a key consideration in the adoption of UCD methods. Measures of UCD effectiveness are lacking and rarely applied. There is a major discrepancy between the commonly cited measures and what were actually applied.
index142!@#@!1994!@#@!Replicated Data Management in Mobile Environments: Anything New Under the Sun?!@#@!Proceedings of the IFIP WG10.3 Working Conference on Applications in Parallel and Distributed Computing!@#@!null
index143!@#@!1998!@#@!Human-Computer Anxiety and Phobia: A Consideration of Foundations and Interventions!@#@!Proceedings of the Fourth Symposium on Human Interaction with Complex Systems!@#@!null
index144!@#@!1999!@#@!Research Report. Learning From Goal-Directed Error Recovery Strategy!@#@!Information Systems Research!@#@!Research on training has traditionally viewed errors made by trainees as detrimental to learning. A great deal of effort has been devoted to finding effective ways of preventing errors from occurring during training. Recently, some researchers have adopted a different perspective: that errors may provide a learning opportunity for trainees. What has been investigated less is the specific mechanism through which errors can foster learning. The objective of our research was to investigate and possibly reconcile these differing viewpoints by examining the error recovery process. We found that, in some situations, errors enhance learning when the trainee adopts an error recovery process that emphasizes the goal structure of the task. We suggest several ways of coaching trainees in training sessions to adopt such error recovery strategies.
index145!@#@!2003!@#@!Distributed PIN verification scheme for improving security of mobile devices!@#@!Mobile Networks and Applications!@#@!The main driving force for the rapid acceptance rate of small sized mobile devices is the capability to perform e-commerce transactions at any time and at any place, especially while on the move. There are, however, also weaknesses of this type of e-commerce, often called mobile e-commerce, or m-commerce. Due to their small size and easy portability mobile devices can easily be lost or stolen. Whereas the economic values and privacy threats protected with Personal Identification Numbers (PIN) are not particularly high for normal voice-enabled mobile phones, this is not true any more when phones have developed to Personal Trusted Devices (PTDs). Still, PINs are used also in this new context for authorization and identification purposes. PINs are currently used both for protection of the devices and for authentication, as well as authorization of the users. It is commonly recognized that not many techniques of storing the PINs into the memory of the device or on the SIM card are safe. Even less sophisticated thieves might uncover the PIN inside the stolen mobile devices and for sophisticated thieves uncovering the PIN stored "safely" might be possible. In this paper we propose a new scheme to cope with the problem of uncovering the PIN that reduces the risks of m-commerce. The basic idea is that instead of storing the entire PIN digits (or some hash value) in the mobile device, we store part of the PIN in a remote machine in the network. The PIN verification then involves both the mobile device and the remote machine, which must verify their respective parts of the PIN. Also, the improvements of the security over the existing schemes are shown using a probabilistic model. In the best case, where the probability of discovering the PIN irrespective of the storage scheme is negligible in relation to directly uncovering it, the increase in security is over 1000%.
index146!@#@!1998!@#@!Validation of Knowledge-Based Systems by Means of Stochastic Search!@#@!Proceedings of the 9th International Workshop on Database and Expert Systems Applications!@#@!In this paper, the use of stochastic search to validate first-order knowledge-based systems is investigated. It is well-known that such techniques can prove efficient in showing that consistency constraints do hold, at least in the propositional case. Powerful heuristics about the trace of stochastic search allow proofs of inconsistency to be obtained as well. But, how stochastic search can be applied to first-order knowledge-bases without giving rise to a combinatorial space explosion remains an open issue. In this paper, a partial instantiation schema is proposed in the context of the incremental consistency/inconsistency problem. It allows forms of depth-limited consistency and inconsistency to be handled in an effective manner, showing promising paths for the development of new efficient consistency checking techniques for first-order knowledge bases.
index147!@#@!1999!@#@!Speaker Biographies!@#@!Proceedings of the 15th Annual Computer Security Applications Conference!@#@!null
index148!@#@!2002!@#@!Preface!@#@!Aggregation operators: new trends and applications!@#@!null
index149!@#@!2002!@#@!Data Resampling for Path Based Clustering!@#@!Proceedings of the 24th DAGM Symposium on Pattern Recognition!@#@!null
index150!@#@!2002!@#@!Simulated annealing with advanced adaptive neighborhood!@#@!Second international workshop on Intelligent systems design and application!@#@!null
index151!@#@!2001!@#@!A Markov Random Field Image Segmentation Model Using Combined Color and Texture Features!@#@!Proceedings of the 9th International Conference on Computer Analysis of Images and Patterns!@#@!null
index152!@#@!2003!@#@!Review: SCO Linux 4!@#@!Linux Journal!@#@!null
index153!@#@!2001!@#@!Simple Procedures for Selecting the Best Simulated System When the Number of Alternatives is Large!@#@!Operations Research!@#@!In this paper, we address the problem of finding the simulated system with the best (maximum or minimum) expected performance when the number of alternatives is finite, but large enough that ranking-and-selection (R&S) procedures may require too much computation to be practical. Our approach is to use the data provided by the first stage of sampling in an R&S procedure to screen out alternatives that are not competitive, and thereby avoid the (typically much larger) second-stage sample for these systems. Our procedures represent a compromise between standard R&S procedures--which are easy to implement, but can be computationally inefficient--and fully sequential procedures--which can be statistically efficient, but are more difficult to implement and depend on more restrictive assumptions. We present a general theory for constructing combined screening and indifference-zone selection procedures, several specific procedures and a portion of an extensive empirical evaluation.
index154!@#@!1994!@#@!Using Contexts to Represent Text!@#@!Proceedings of the Second International Conference on Conceptual Structures: Current Practices!@#@!null
index155!@#@!2002!@#@!Software systems for tabular data releases!@#@!International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems!@#@!We describe two classes of software systems that release tabular summaries of an underlying database. Table servers respond to user queries for (marginal) sub-tables of the "full" table summarizing the entire database, and are characterized by dynamic assessment of disclosure risk, in light of previously answered queries. Optimal tabular releases are static releases of sets of sub-tables that are characterized by maximizing the amount of information released, as given by a measure of data utility, subject to a constraint on disclosure risk. Underlying abstractions - primarily associated with the query space, as well as released and unreleasable sub-tables and frontiers, computational algorithms and issues, especially scalability, and prototype software implementations are discussed.
index156!@#@!2000!@#@!Aspect Ratio Adaptive Normalization for Handwritten Character Recognition!@#@!Proceedings of the Third International Conference on Advances in Multimodal Interfaces!@#@!null
index157!@#@!1995!@#@!&Uuml;ber nicht lernbare Probleme oder Ein Modell f&uuml;r die vorzeitige S&auml;ttigung bei vorw&auml;rtsgekoppelten Neuronalen Netzen!@#@!Mustererkennung 1995, 17. DAGM-Symposium!@#@!null
index158!@#@!2003!@#@!An easy way to create a web site for your course!@#@!Journal of Computing Sciences in Colleges!@#@!null
index159!@#@!2002!@#@!MAGE" A Metacomputing Environment for Parallel Program Development on Cluster Computers!@#@!CLUSTER!@#@!This paper describes the design of MAGE¿ Metacomputing and Grid Environment ¿ an environment for developing and executing parallel programs on COTS cluster computers and grids. The intent of MAGE is to provide a layer of abstraction at the level of parallel program compilation, execution, and monitoring. The user is isolated from the details of these operations, while preserving a robust, flexible set of capabilities for advanced parallel program development. While most metacomputing abstractions focus on access to extant parallel resources, or on integrating dispersed resources into a grid, MAGE integrates cluster middleware with workstation applications, and extends this paradigm by focusing on providinga development environment for the creation of new parallel programs. The flexible, modular design of the MAGE components ensures portability to different clustering platforms and promotes eventual integration of a MAGE-based system with a grid system.
index160!@#@!2001!@#@!Designing Democratic Community Networks: Involving Communities through Civil Participation!@#@!Revised Papers from the Second Kyoto Workshop on Digital Cities II,  Computational and Sociological Approaches!@#@!null
index161!@#@!2000!@#@!A Comparison of Mobile Agent and Client-Server Paradigms for Information Retrieval Tasks in Virtual Enterprises!@#@!Proceedings of the Academia/Industry Working Conference on Research Challenges!@#@!In next-generation enterprises it will become increasingly important to retrieve information efficiently and rapidly from widely dispersed sites in a virtual enterprise, and the number of users who wish to do using wireless and portable devices will increase significantly. This paper considers the use of mobile agent technology rather than traditional client-server computing for information retrieval by mobile and wireless users in a virtual enterprise. We argue that to be successful mobile agent platforms must coexist with, and be presented to the applications programmer side-by-side with, traditional client-server middleware like CORBA and DCOM, and we sketch middleware architecture for doing so.We then develop an analytical model that examines the claimed performance benefits of mobile agents over client-server computing for a mobile information retrieval scenario. Our evaluation of the model shows that mobile agents are not always better than client-server calls in terms of average response times; they are only beneficial if the space overhead of the mobile agent code is not too large or if the wireless link connecting the mobile user to the fixed servers of the virtual enterprise is error-prone.
index162!@#@!1995!@#@!Software Environment Support for Integrated Formal Program Specification and Development!@#@!Proceedings of the Second Asia Pacific Software Engineering Conference!@#@!Formal program development has gained widespread academic interest as a rigorous software engineering technique. One of the main hurdles for the wider IT industry in adopting these formal techniques is a lack of tools to support their use in combination with more traditional development techniques. This paper describes an integrated environment for object-oriented software development which incorporates formal Object-Z specifications for classes. These formal specification views are kept consistent with more traditional design and implementation views, allowing software developers to design, refine, implement and document their software utilizing integrated formal techniques.
index163!@#@!2003!@#@!Designing and implementing small quantum circuits and algorithms!@#@!Proceedings of the 40th annual Design Automation Conference!@#@!It appears, in principle, that the laws of quantum mechanics allow a quantum computer to solve certain mathematical problems more rapidly than can be done using a classical computer. However, in order to build such a quantum computer a number of technological problems need to be overcome. A stepping stone to this goal is the implementation of relatively simple quantum algorithms using current experimental techniques.This paper explores small scale quantum algorithms from two different perspectives. Firstly, it will be shown how small scale quantum algorithms can be tailored to fit current schemes for implementing a quantum computer. Secondly, I will review a simple model of computation, based on read-only-memory. This model allows the comparison of the space-efficiency of reversible error-free classical computation with reversible, error-free quantum computation. The quantum model has been shown to be more powerful than the classical model.
index164!@#@!1996!@#@!High-Availability LH* Schemes with Mirroring!@#@!Proceedings of the First IFCIS International Conference on Cooperative Information Systems!@#@!null
index165!@#@!2001!@#@!Searching the deep web!@#@!Journal of Computing Sciences in Colleges!@#@!null
index166!@#@!1998!@#@!Computing Conspiracies!@#@!Proceedings of the 9th International Workshop on Database and Expert Systems Applications!@#@!The concept of 'segregation of duties' is well-known in both organisational and security contexts. For example, the Clark-Wilson model stresses the importance of such a policy appropriate for regulating the involvement of subjects in acting upon business information and business values. However, it gives no guidelines on how to distinguish a proper policy from an improper one. Furthermore, the discipline of auditing has developed numerous schemes for segregation of duties. In this paper we use a model that allows quantification of - and reasoning about - audit-technical segregation of duties. Our approach is based on normative ('Soll') and actual ('Ist') specifications of a company's circular flow of business values in terms of enriched Petri nets. In this type of Petri net the markers represent money, goods, debts and registrations of these business values, the places represent their buffer locations and the transitions represent transformation procedures. Associated to these Petri net elements are agents and their authorisations and abilities. Undetectable use of company assets can now be modelled in the 'Ist' net by the general Petri net notion of 'T-invariant'. The design of a proper scheme for segregation of duties then reduces to maximisation of the number of agents that need to be minimally involved in order to establish a firing of such a T-invariant.
index167!@#@!2000!@#@!CASSIEL: Modeling Intelligent Agents for a Lifelong Learning Environment!@#@!Proceedings of the Mexican International Conference on Artificial Intelligence: Advances in Artificial Intelligence!@#@!null
index168!@#@!2000!@#@!A Data Model for Temporal XML Documents!@#@!Proceedings of the 11th International Conference on Database and Expert Systems Applications!@#@!null
index169!@#@!2003!@#@!Integrated design method for flip chip CSP with electrical, thermal and thermo-mechanical qualifications!@#@!Finite Elements in Analysis and Design!@#@!A new design method involving electrical, thermal and thermo-mechanical characterizations was developed to optimize the geometric parameters and material properties of a flip chip CSP. A two-dimensional nonlinear finite element model was created using the APDL commercial software ANSYS programming technique to connect with the search routines of genetic algorithms. The electrical characterization optimization objective function was used to set the characteristic impedance of the solder bump and corresponded with the first incident voltage adapting the CMOS switch event to reduce the response time delay in the binary command as well as maintaining the chip level efficiency. The thermal resistance determines the package thermal performance; that is, the objective function is to minimize the thermal resistance under certain power dissipation parameters. Thermally induced stress and warpage dominate the thermo-mechanical behavior. The objective function is the minimization of the thermal stress gradients around the chip, bump, underfill and molding compound as well as mechanical warpage in the entire package. The optimization results show that a remarkable strategy for packaging design was achieved.
index170!@#@!1999!@#@!Intelligent, ANN-Based Identification System of Complex Generating Sets Operating Mode!@#@!Proceedings of the 6th International Conference on Computational Intelligence, Theory and Applications: Fuzzy Days!@#@!null
index171!@#@!2000!@#@!Improving Algorithms for Boosting!@#@!Proceedings of the Thirteenth Annual Conference on Computational Learning Theory!@#@!null
index172!@#@!1997!@#@!Multi-thread graph: a system model for real-time embedded software synthesis!@#@!Proceedings of the 1997 European conference on Design and Test!@#@!Software synthesis is a new approach which focuses on the support of real-time embedded multi-tasking software without the use of operating systems. A software synthesis system starts from a concurrent process system specification and maps this description automatically onto one or more processors. In this paper the internal system-level model which captures the embedded software and which is the backbone of our software synthesis methodology, is presented. The model captures the fine-grain behaviour of a system, and supports multiple threads of control (concurrency), synchronisation, data communication, hierarchy and timing constraints.
index173!@#@!2003!@#@!Interactive locality optimization on NUMA architectures!@#@!Software Visualization!@#@!Optimizing the performance of shared-memory NUMA programs remains something of a black art, requiring that application writers possess deep understanding of their programs' behaviors. This difficulty represents one of the remaining hindrances to the widespread adoption and deployment of these cost-efficient and scalable shared-memory NUMA architectures. To address this problem, we have developed a performance monitoring infrastructure and a corresponding set of tools to aid in visualizing and understanding the subtleties of the memory access behavior of parallel NUMA applications with large datasets. The tools are designed to be general, interoperable, and easily portable. We give detailed examples of the use of one particular tool in the set. We have used this memory access visualization tool profitably on a range of applications, improving performance by around 90%, on average.
index174!@#@!2001!@#@!Segmentation and length estimation of 3D discrete curves!@#@!Digital and image geometry: advanced lectures!@#@!We propose in this paper an arithmetical definition of 3-D discrete lines as well as an efficient construction algorithm. From this notion, an algorithm of 3-D discrete lines segmentation has been developed. It is then used to calculate the length of a discrete curve. A proof of the multigrid convergence of length estimators is presented.
index175!@#@!1998!@#@!An Objective Comparison Methodology of Edge Detection Algorithms Using a Structure from Motion Task!@#@!Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition!@#@!null
index176!@#@!2002!@#@!Complexity at large!@#@!Complexity!@#@!null
index177!@#@!2003!@#@!Minimizing broadcast latency and redundancy in ad hoc networks!@#@!International Symposium on Mobile Ad Hoc Networking &amp; Computing!@#@!Network wide broadcasting is a fundamental operation in ad hoc networks. In broadcasting, a source node end a message to all the other nodes in the network. In this paper, we consider the problem of collision-free broadcasting in ad hoc wireless networks. Our objective is to minimize the latency and the number of retransmission in the broadcast. We show that minimum latency broadcasting i NP-hard for ad hoc wireless networks. We also present a simple and distributed collision-free broadcasting algorithm for broadcasting a message. For networks with bounded node transmission ranges, our algorithm simultaneously guarantees that the latency and the number of retransmission are within O(1)times their respective optimal values. Our algorithm and analysis extends to the case when multiple messages are broadcast from multiple sources. Experimental studies indicate that our algorithm perform much better in practice than the analytical guarantee provided for the worst case.
index178!@#@!1995!@#@!A Cost Evaluator for Parallel Database Systems!@#@!Proceedings of the 6th International Conference on Database and Expert Systems Applications!@#@!null
index179!@#@!1986!@#@!A Polynomial Algorithm for Recognizing Samll Cutwidth in Hypergraphs!@#@!Proceedings of the VLSI Algorithms and Architectures, Aegean Worksho on Computing!@#@!null
index180!@#@!2002!@#@!Challenging traditions of inquiry in software practice!@#@!Social thinking: software practice!@#@!null
index181!@#@!2003!@#@!On Event Routing in Content-Based Publish/Subscribe through Dynamic Networks!@#@!Proceedings of the The Ninth IEEE Workshop on Future Trends of Distributed Computing Systems!@#@!Content-based publish/subscribe communication systems are a popular technology for many-to-many information diffusion over large scale networks. Scalable solutions are obtained considering a network of distributed event brokers, dispatching information (events) from producers (publishers) to consumers (subscribers). Many scalable and efficient solution for routing events in content-based systems exist, that selectively send events only toward the interested subscribers. However, if subscribers having similar interest are present in different parts of the network, the benefits of such routing strategies significantly decrease. In this paper we propose a novel approach for enhancing content-based routing, based on the dynamic reconfiguration of the broker network. The reconfiguration aims at aiding the routingprocess by placing close to each others brokers that manage subscribers with similar interests. Metrics for measuring similarity of interests are discussed and a reconfiguration algorithm is presented.
index182!@#@!2001!@#@!Benders Decomposition for Simultaneous Aircraft Routing and Crew Scheduling!@#@!Transportation Science!@#@!Given a set of flight legs to be flown by a single type of aircraft, the simultaneous aircraft routing and crew scheduling problem consists of determining a minimum-cost set of aircraft routes and crew pairings such that each flight leg is covered by one aircraft and one crew, and side constraints are satisfied. While some side constraints such as maximum flight time and maintenance requirements involve only crews or aircraft, linking constraints impose minimum connection times for crews that depend on aircraft connections. To handle these linking constraints, a solution approach based on Benders decomposition is proposed. The solution process iterates between a master problem that solves the aircraft routing problem, and a subproblem that solves the crew pairing problem. Because of their particular structure, both of these problems are solved by column generation. A heuristic branch-and-bound method is used to compute integer solutions. On a set of test instances based on data provided by an airline, the integrated approach produced significant cost savings in comparison with the sequential planning process commonly used in practice. The largest instance solved contains more than 500 flight legs over a 3-day period.
index183!@#@!2002!@#@!Transformation of SDL specifications for system-level timing analysis!@#@!Proceedings of the tenth international symposium on Hardware/software codesign!@#@!Complex embedded systems are typically specified using multiple domain-specific languages. After code-generation, the implementation is simulated and tested. Validation of non-functional properties, in particular timing, remains a problem because full test coverage cannot be achieved for realistic designs. The alternative, formal timing analysis, requires a system representation based on key application and architecture properties. These properties must first be extracted from a system specification to enable analysis. In this paper we present a suitable transformation of SDL specifications for system-level timing analysis. We show ways to vary modeling accuracy in order to apply available formal techniques. A practical approach utilizing a recently developed system model is presented.
index184!@#@!2001!@#@!On Fusion of Multiple Views for Active Object Recognition!@#@!Proceedings of the 23rd DAGM-Symposium on Pattern Recognition!@#@!null
index185!@#@!2000!@#@!Service-based software: the future for flexible software!@#@!Proceedings of the Seventh Asia-Pacific Software Engineering Conference!@#@!For the past 40 years, the techniques, processes and methods of software development have been dominated by supply-side issues, giving rise to a software industry oriented towards developers rather than users. To achieve the levels of functionality, flexibility and time-to-market required by users, a radical shift is required in the development of software, with a more demand-centric view, leading to software which will be delivered as a service within the framework of an open marketplace. Already, there are some signs that this approach is being adopted by industry, but in a very limited way. We summarise research and a research method which has resulted in a long-term strategic view of software engineering innovation. Based on this foundation, we describe more recent work, which has resulted in an innovative demand-side model for the future of software. We propose a service architecture in which components may be bound instantly, just at the time they are needed, and then the binding may be discarded. A major benefit of this approach is that it leads to highly flexible and agile software that should be able to meet rapidly changing business needs.
index186!@#@!1998!@#@!CSD'98 Organization!@#@!Proceedings of the 1998 International Conference on Application of Concurrency to System Design!@#@!null
index187!@#@!2002!@#@!An outline of a course on operating system principles!@#@!The origin of concurrent programming: from semaphores to remote procedure calls!@#@!In 1970 the author began writing a comprehensive textbook on operating system principles. This is a description of its structure and how far it had progressed a year later.
index188!@#@!1978!@#@!Bilddarstellung durch konvexe Elementarmuster!@#@!Bildverarbeitung und Mustererkennung, DAGM Symposium!@#@!null
index189!@#@!1998!@#@!Dependability - A Unifying Concept!@#@!Proceedings of the Conference on Computer Security, Dependability, and Assurance: From Needs to Solutions!@#@!This paper discusses the need for a clear set of system dependability concepts and terminology, adequate for situations in which there are uncertainties about system boundaries, the very complexity of systems (and their specifications, if they have any) is a major problem, judgements as to possible causes or consequences of failure may need be very subtle, and there are only fallible provisions for preventing faults causing failures. It then relates this terminology to that in use in the survivability, critical infrastructures, information warfare, and intrusion detection research communities, before describing the European Dependability Initiative, a contribution to the planning of the European Union's Information Society Technologies (IST) Program.
index190!@#@!2003!@#@!Properties of the Reflected Ornstein&ndash;Uhlenbeck Process!@#@!Queueing Systems: Theory and Applications!@#@!Consider an Ornstein&ndash;Uhlenbeck process with reflection at the origin. Such a process arises as an approximating process both for queueing systems with reneging or state-dependent balking and for multi-server loss models. Consequently, it becomes important to understand its basic properties. In this paper, we show that both the steady-state and transient behavior of the reflected Ornstein&ndash;Uhlenbeck process is reasonably tractable. Specifically, we (1) provide an approximation for its transient moments, (2) compute a perturbation expansion for its transition density, (3) give an approximation for the distribution of level crossing times, and (4) establish the growth rate of the maximum process.
index191!@#@!1988!@#@!An Environment For Automated Reasoning About Partial Functions!@#@!Proceedings of the 9th International Conference on Automated Deduction!@#@!null
index192!@#@!2000!@#@!User Acceptance of Videoconferencing: Perceptions of Task Characteristics and Media Traits!@#@!Proceedings of the 33rd Hawaii International Conference on System Sciences-Volume 1 - Volume 1!@#@!While there are several theoretical models that might explain the acceptance and usage of videoconferencing systems, little empirical research has been conducted to corroborate these theories and to establish which factors are important to videoconferencing participants. This study draws on the trait theories of media selection to assess the associations between user acceptance of videoconferencing technology and user perceptions of task characteristics and media traits. The findings show that perceptions of task characteristics and media traits are associated with the perceived utility and ease-of-use of videoconferencing systems.
index193!@#@!2000!@#@!A Proposal of a Memory Management Architecture for Mobile Computing Environments!@#@!Proceedings of the 11th International Workshop on Database and Expert Systems Applications!@#@!In recent years, mobile computing environments are becoming more realized by the rapid popularization of cellular phones and the miniaturization and the enhancement of the performance of mobile terminals. However, several technological issues remain difficult such as the narrow bandwidth of wireless communications, the limited battery duration of mobile terminals, and the others. Moreover, it is hard to develop application programs that operate in mobile computing environments because of the complicated procedure of wireless communications. This paper proposes a common memory management mechanism for mobile terminals and servers called Memory Management Architecture for Mobile Computing Environments (MMM). MMM allocates a part of the memory of a mobile terminal and a part of the memory of a server as common memory while maintaining the consistency of the common memory areas. MMM is evaluated using sample application program models against traditional memory. The result shows that MMM can reduce wireless traffic to maintain consistency, and that depending on the different charging categories, a different prefetching scheme makes it more efficient in minimizing communication cost.
index194!@#@!2003!@#@!Reflections on a UK Masters Level Software Engineering Programme Intended for the Home and International Market!@#@!Proceedings of the 16th Conference on Software Engineering Education and Training!@#@!There are currently insufficient skilled Software Engineers to meet the needs of industryacross the world. Intensive taught Masters level programmes represent one solution to thisshortfall. One such programme is the MSc in Software Engineering offered by the Universityof Sunderland in the UK. This was developed to satisfy student needs both within and outsidethe European Union.. The constraints and challenges that needed to be addressed in thedevelopment of the programme are outlined. The programme and the various pathwaysthrough it are described. Student feedback on the programme is reported. The programme isevaluated and some of the lessons learned since its inception in 1999 are reviewed.
index195!@#@!1995!@#@!Synthesis of I/sub DDQ/-testable circuits: integrating built-in current sensors!@#@!Proceedings of the 1995 European conference on Design and Test!@#@!"On-Chip" I/sub DDQ/ testing by the incorporation of Built-In Current (BIC) sensors has some advantages over "off-chip" techniques. However, the integration of sensors poses analog design problems which are hard to solve for a digital designer. The automatic incorporation of the sensors using parameterized BIC cells could be a promising alternative. The work reported here identifies partitioning criteria to guide the synthesis of I/sub DDQ/-testable circuits. The circuit must be partitioned, such that the defective I/sub DDQ/ is observable, and the power supply voltage perturbation is within specified limits. In addition to these constraints, cost criteria are considered: circuit extra delay, area overhead of the BIC sensors, connectivity costs of the test circuitry, and the test application time. The parameters are estimated based on logical as well as electrical level information of the target cell library to be used in the technology mapping phase of the synthesis process. The resulting cost function is optimized by an evolution-based algorithm. When run over large benchmark circuits our method gives significantly superior results to those obtained using simpler and less comprehensive partitioning methods.
index196!@#@!1999!@#@!Limits on the Efficiency of One-Way Permutation-Based Hash Functions!@#@!Proceedings of the 40th Annual Symposium on Foundations of Computer Science!@#@!Naor and Yung have shown that a one-bit-compressing universal one-way hash function (UOWHF) can be constructed based on a one-way permutation. This construction can be iterated to build a UOWHF which compresses by \math bits, at the cost of \math invocations of the one-way permutation. We show that this construction is not far from optimal, in the following sense: there exists an oracle relative to which there exists a one-way permutation with inversion probability \math (for any \math, but any construction of an \math-bit-compressing UOWHF requires \math invocations of the one-way permutation, on average. (For example, there exists in this relativized world a one-way permutation with inversion probability \math, but no UOWHF that invokes it fewer than \math times.) Thus any proof that a more efficient UOWHF can be derived from a one-way permutation is necessarily non-relativizing; in particular, no provable construction of a more efficient UOWHF can exist based solely on a "black box" one-way permutation. This result can be viewed as a partial justification for the practice of building efficient UOWHFs from stronger primitives (such as collision-intractable hash functions), rather than from weaker primitives such as one-way permutations.
index197!@#@!2003!@#@!Noise and specific detectivity of pyroelectric detectors using lead titanate zirconate (PZT) thin films!@#@!Microelectronic Engineering!@#@!Pyroelectric infrared detectors using sol-gel deposited lead zirconate titanate (PZT) thin films were fabricated. It was found that specific detectivity D* of the detector is a strong function of the modulation frequency of the incident radiation. Noise plays an important role at low frequencies (< 20 Hz). When the modulation frequency is low ( < 10 Hz), the noise is dominated by 1/f noise. Johnson noise dominates the noise at frequencies higher than 10 Hz. This characteristic can be clearly seen from the noise-frequency spectrum. A one-dimensional heat conduction theoretical model was used to simulate the dynamic responses of the pyroelectric IR detector. The simulated results fitted quite well with the experimental results. D* of the detector was predicted with the assumption that the Johnson noise was the dominating noise source.
index198!@#@!1999!@#@!The Virtual Cell: Creating Models of Complex Cellular Events!@#@!Proceedings of the 12th IEEE Symposium on Computer-Based Medical Systems!@#@!Computer scientists, mathematicians, and physicists are collaborating with cell biologists to build a tool, "Virtual Cell", that can merge data of cellular biochemistry with knowledge of cell structure to help us understand how cells produce complex behaviors. A cell is a highly complex factory that organizes thousands of different molecules to produce a specialized function. Microscopists have catalogued a wealth of data about the detailed structures within different types of cells and biochemists have assembled details about the properties and reactions of many of a cell's individual molecular constituents. The experimental information gathered from the test tube and from the microscope is married within "Virtual Cell" to construct a computer model which can produce simulations of how cells carry out a given function (e.g. secretion of insulin, contraction of heart muscle). What is produced are digital movies showing how each molecular species moves and reacts inside the cell during the cell biological process. Perhaps the most exciting application of this tool is that it allows scientists to ask questions about what happens when one step in a complex chain of events misfires or how a drug that is known to affect just a single enzyme might change the way a cell carries out a specific function. But in addition to its use as a research tool, "Virtual Cell" can be a valuable teaching aid and may serve as a focus for organizing the tremendous knowledge base that comprises modern cell biology and biochemistry.The Virtual Cell is a fully modular computational framework that permits construction of models, application of numerical solvers to perform simulations, and analysis of simulation results. An intuitive JAVA interface includes options for database access, geometry definition (including directly from experimental images), specification of compartment topology, species definition and assignment, chemical reaction input, and computational mesh. Deterministic and stochastic physical formulations have been implemented. The algorithms have been rigorously tested against exact solutions including various membrane and boundary conditions. This talk will describe the status of the project and provide a demonstration of several applications to cell biological problems.
index199!@#@!1998!@#@!A Computing Model for Distributed Processing Systems and Its Application!@#@!Proceedings of the Fifth Asia Pacific Software Engineering Conference!@#@!When implementing an application system in a distributed computing environment, several architectural questions arise such as, how and where computing resources are distributed, and how the communication among computing resources should be implemented. To simplify the process of making these choices, we have developed a distributed computing model. This model classifies distributed processing systems into seven categories based on the location of data storage and the style of processing between client and server. This paper describes our model and its use in planning the infrastructure of a new system for one of our customers.
index200!@#@!2002!@#@!Syslog!@#@!Sys Admin!@#@!null
index201!@#@!2001!@#@!A Retrieval Method for Real-Time Spatial Data Browsing!@#@!Proceedings of the 12th International Conference on Database and Expert Systems Applications!@#@!null
index202!@#@!2003!@#@!A logarithmic approximation algorithm for the minimum energy consumption broadcast subgraph problem!@#@!Information Processing Letters!@#@!Motivated by the problem of supporting energy-efficient broadcasting in ad hoc wireless networks, we study the Minimum Energy Consumption Broadcast Subgraph (MECBS) problem. We present the first logarithmic approximation algorithm for the problem which uses an interesting reduction to Node-Weighted Connected Dominating Set.
index203!@#@!1996!@#@!Hardware Check of Arithmetic Devices with Abridged Execution of Operations!@#@!Proceedings of the 1996 European conference on Design and Test!@#@!There is propound the check by modulo method of multiplier with the abridgement of computation, that is in high-performance floating-point arithmetic devices. The forming of uncalculated part of the operation result by processing of small capacity check codes of the operands and their parts is on the basis of the method. It provides simplicity of the check circuit for which equipment expenses are in linear depending on the capacity of operands under condition squaring dependence of expenses of the main equipment.
index204!@#@!2002!@#@!Practical Collision Detection in Rendering Hardware for Two Complex 3D Polygon Objects!@#@!Proceedings of the 20th UK conference on Eurographics!@#@!We present a technique to perform real-time collision detection of two complex 3D polygon objects using commodity and workstation rendering hardware. This technique is O(n), and performs favorably in comparison to existing traditional methods in many circumstances. On PCs or workstations, this technique can be performed almost entirely in rendering hardware. This frees general CPU cycles for other processing tasks. Alternatively, more CPU cycles can be used for collision detection, freeing rendering hardware cycles for other tasks. This technique is also highly customizable to specific applications.
index205!@#@!1991!@#@!Ein Satz von merkmalbestimmenden Basisoperationen zur Auswertung von Bildpyramiden!@#@!Mustererkennung 1991, 13. DAGM-Symposium!@#@!null
index206!@#@!1992!@#@!Proving Equality Theorems with Hyper-Linking!@#@!Proceedings of the 11th International Conference on Automated Deduction: Automated Deduction!@#@!null
index207!@#@!2002!@#@!Sneak previews: AEP delivers a quick and inexpensive contender for the accelerator market!@#@!Network Computing!@#@!null
index208!@#@!2003!@#@!Gaussian rules on unbounded intervals!@#@!Journal of Complexity!@#@!A quadrature rule as simple as the classical Gauss formula, with a lower computational cost and having the same convergence order of best weighted polynomial approximation in L1 is constructed to approximate integrals on unbounded intervals. An analogous problem is discussed in the case of Lagrange interpolation in weighted L2 norm. The order of convergence in our results is the best in the literature for the considered classes of functions.
index209!@#@!1998!@#@!Organizing Committee!@#@!Automated Software Engineering!@#@!null
index210!@#@!1999!@#@!Evaluating the Effectiveness of Fault Tolerance in Replicated Database Management Systems!@#@!Proceedings of the Twenty-Ninth Annual International Symposium on Fault-Tolerant Computing!@#@!Database management systems (DBMS) achieve high availability and fault tolerance usually by replication. However, fault tolerance does not come for free. Therefore, DBMSs serving critical applications with real time requirements must find a tradeoff between fault tolerance cost and performance. The purpose of this study is two-fold. It evaluates the effectiveness of DBMS fault tolerance in the presence of corruption in database buffer cache, which poses serious threat to the integrity requirement of the DBMSs.The first experiment of this study evaluates the effectiveness of fault tolerance, and the fault impact on database integrity, performance, and availability on a replicated DBMS, ClustRa, in the presence of software faults that corrupt the volatile data buffer cache. The second experiment identify the weak data structure components in the data buffer cache that give fatal consequences when corrupted, and suggest the need for some form of guarding them individually or collectively.
index211!@#@!1992!@#@!Integration of Telephony into DP Applications: A Building Block for Intelligent Information Systems!@#@!Proceedings of the IFIP 12th World Computer Congress on Personal Computers and Intelligent Systems - Information Processing '92 - Volume 3 - Volume 3!@#@!null
index212!@#@!2003!@#@!Empirical Evaluation of Ensemble Feature Subset Selection Methods for Learning from a High-Dimensional Database in Drug Design!@#@!Proceedings of the 3rd IEEE Symposium on BioInformatics and BioEngineering!@#@!Discovering a new drug is one of the most important goals in not only the pharmaceutical field but also a variety of fields including molecular biology, chemistry and medical science. The importance of computationally understanding the relationships between a given chemical compound and its drug activity has been pronounced. In the data set regarding drug activity of chemical compounds, each row corresponds to a chemical compound, and columns are the descriptors of the compound and a label indicating rug activity of the compound. Recently, the size of the descriptors has become larger to obtain more detailed information from a given set of compounds. Actually, the number of columns (attributes or features) ofsome drug data sets reaches hundreds of thousands or a million. The purpose of this paper is to empirically evaluate the performance of ensemble feature subset selection strategies by applying them to such a high-dimensional data set actually used in the process of rug design. We examined the performance of three ensemble methods, including a query learning based method, comparing with that of one of the latest feature subset selection methods. The evaluation was performed on a data set which contains approximately 140,000 features. Our results show that the query learning based methodology outperformed the other three methods, in terms of the final prediction accuracy and time-efficiency. We have also examined the effect of noise in the data and found that the advantage of the method becomes more pronounced for larger noise levels.
index213!@#@!2001!@#@!QUBE: A System for Deciding Quantified Boolean Formulas Satisfiability!@#@!Proceedings of the First International Joint Conference on Automated Reasoning!@#@!null
index214!@#@!2002!@#@!High-level net processes!@#@!Formal and natural computing!@#@!The notion of processes for low-level Petri nets based on occurrence nets is well known and it represents the basis for the study of the non-sequential behavior of Petri nets. Processes for high-level nets N are often defined as processes of the low level net Flat(N) which is obtained from N via a construction called "flattening". In this paper we define high-level processes for high-level nets based on a suitable notion of high-level occurrence nets. The flattening of a high-level occurrence net is in general not a low-level occurrence net, due to so called "assignment conflicts" in the high-level net. The main technical result is a syntactical characterization of assignment conflicts. But the main focus of this paper is a conceptual discussion of future perspectives of high-level net processes including concurrency and data type aspects. Specifically, in the second part of the paper, we discuss possible extensions of high-level net processes, which are formally introduced for algebraic high-level nets in the first part of this paper. Of special interest are high-level processes with data type behavior, amalgamation, and other kinds of constructions, which are essential aspects for a proposed component concept for high-level nets.
index215!@#@!2002!@#@!Building a Task Language for Segmentation and Recognition of User Input to Cooperative Manipulation Systems!@#@!Proceedings of the 10th Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems!@#@!We present the results of using Hidden Markov Models (HMMs) for automatic segmentation and recognition of user motions. Previous work on recognition of user intent with man/machine interfaces has used task-level HMMs with a single hidden state for each sub-task. In contrast, many speech recognition systems employ HMMs at the phoneme level, and use a network of HMMs to model words. We analogously make use of multi-state, continuous HMMs to model action at the "gesteme" level, and a network of HMMs to describe a task or activity. As a result, we are able to create a "task language" that is used to model and segment two different tasks performed with a human-machine cooperative manipulation system. Tests were performed using force and position data recorded from an instrument held simultaneously by a robot and human operator. Experimental results show a recognition accuracy exceeding 85%. The resulting information could be used for intelligent command of virtual and teleoperated environments, and implementation of contextually appropriate virtual fixtures for dynamic operator assistance while executing complex tasks.
index216!@#@!2000!@#@!Management of Change in Structured Verification!@#@!Automated Software Engineering!@#@!The use of formal methods in large complex applications implies the need for an evolutionary formal program development in which specification and verification phases are interleaved. However, any change of a specification either by adding new parts or by changing erroneous parts affects existing verification work in a subtle way. In this paper, we present a truth maintenance system for structured specification and verification. It is based on the simple but powerful notion of a development graph as an underlying data structure to represent an actual consistent state of a formal development. Based on this notion we try to minimize the consequences of changes of existing verification work.
index217!@#@!1999!@#@!Recursive Function Definition over Coinductive Types!@#@!Proceedings of the 12th International Conference on Theorem Proving in Higher Order Logics!@#@!null
index218!@#@!1999!@#@!Vector-Space Image Model (VSIM) for Content-Based Retrieval!@#@!Proceedings of the 10th International Workshop on Database & Expert Systems Applications!@#@!A new method for content-based image retrieval is being presented. This method uses a vector-space model to represent images in a multidimensional space. This model allows the use of multiple attributes in the retrieval process and also identifies the most selective values for each attribute. Therefore by ignoring the less significant values the user can reduce the dimensionality of the feature set and simplify the vector model. It also allows the user to choose any similarity measure depending on the application. The user can also assign weights to the different attributes depending on the retrieval mechanism intended. These characteristics of the retrieval method increase the retrieval efficiency and makes the model very flexible as it can be used universally for retrieving images from different domains.
index219!@#@!1999!@#@!?SUDS-SDL: A Tool for Diagnosis and Understanding Software Specifications!@#@!Proceedings of the Sixth Asia Pacific Software Engineering Conference!@#@!Available statistical data shows that the cost of repairing software faults rises dramatically in later development stages. It is important to reduce software faults in the early stages of software development, such as requirement and design specification. In particular, the new technology of generating implementation code from specification requires highly reliable design specifications. Much research has been done on verification and validation, such as model checking [1].We believe such approaches are similar to software testing. We apply our state-of-the-art technology in software coverage testing, program diagnosis and understanding to stages as early as software requirements and designs. Early analysis provides many benefits, including 1) early detection and recovery of software faults, 2) visualization and simulation of the software specifications, 3) improvement of the confidence on the specification, 4) making programming on the specification level more possible, and 5) reduction of the number of introduced faults.This paper presents the technology and the accompanying tool suite to the diagnosis and understanding of software specifications. We use the simulation of the specifications to collect the execution trace for computing the coverage and slicing data. Our technology is based on both the control flow and the data flow of the executable specifications. It first generates a program flow diagram from the specification and then automatically analyses the coverage features of the diagram. It collects the corresponding flow data during the simulation time to be mapped to the flow diagram. The coverage information for the original specification is then obtained from the coverage information of the flow diagram. This technology has been used for C, C++, and Java, and has proven effective [2].We have obtained concrete examples of the software specifications in Specification and Description Language (SDL) [3]. We developed a tool that is in the final stage of testing. The tool is able to aid the debugging, testing, diagnosis, understanding, and feature allocation of the SDL specifications. We have an early demonstration of the tool to illustrate its usage and its advantages over other tools in the area.
index220!@#@!1997!@#@!Low power FSM design using Huffman-style encoding!@#@!Proceedings of the 1997 European conference on Design and Test!@#@!This paper presents a novel approach to synthesize low power FSMs using non-uniform code length. Switching activity is reduced by decreasing the expected number of state bits switched less than [log |S|] The state set S of the FSM is decomposed into two sets based on the limit state probabilities. The state set with very high probability is encoded with less than [log|S|] bits. The other state set, being less probable, is encoded using more than [log|S|] bits. To the best of our knowledge, this is the first time two code lengths ore used for one state machine. This encoding is realized by using flip-flops with gated clock. The logic generating the enable signal of the clock uses only a single minterm. The state sets can be encoded using any uniform-length encoding algorithm with objectives of low power and low area. The experiments show an average of 13% and 18% reduction in power for two encoding algorithms respectively.
index221!@#@!1995!@#@!Control Structures!@#@!Proceedings of the 10th Annual IEEE Symposium on Logic in Computer Science!@#@!Action calculi are a class of action structures with added structure. Each action calculus AC(K) is determined by a set K of controls, equipped with reaction rules; calculi such as Petri nets, the typed lambda calculus and the pi calculus are obtained by varying K. This paper defines for each K a category CS(K), characterized by equational axioms, of action structures with added structure; they are called control structures and provide models of the calculus AC(K), which is initial in the category. The surface of an action is defined; it is an abstract correlate of the syntactic notion of free name. Three equational characterizations of surface are found equivalent. It permits a non-syntactic treatment of the linkage among the components of an interactive system. Finally, control structures and their morphisms offer a means of classifying the variety of dynamic disciplines in models of concurrency, such as the mobility present in the pi calculus but absent in other calculi.
index222!@#@!2000!@#@!A Generic Graphical Specification Environment for Security Protocol Modelling!@#@!Proceedings of the IFIP TC11 Fifteenth Annual Working Conference on Information Security for Global Information Infrastructures!@#@!null
index223!@#@!1998!@#@!Effect of Hidden Terminals on the Performance of IEEE 802.11 MAC Protocol!@#@!Proceedings of the 23rd Annual IEEE Conference on Local Computer Networks!@#@!The hidden terminal problem is unique to wireless networks and as of now, there is very limited understanding about its effects on network performance. Results are presented from a simulation study of the IEEE 802.11 MAC protocol when operating in the presence of hidden terminals. We also propose a framework for modeling hidden terminals which can handle complex scenarios of both mobility and static obstructions. Our simulations indicate that hidden terminals can have a very detrimental effect on the performance of the IEEE 802.11 MAC protocol. Although throughput is acceptable when about 10 percent of station pairs are hidden, packet delay can increase by an order of magnitude. Performance of the protocol drops sharply when the number of hidden pairs exceeds 10 percent.
index224!@#@!2003!@#@!Perturbed Ishikawa type iterative algorithm for generalized quasivariational inclusions!@#@!Applied Mathematics and Computation!@#@!In this paper, a perturbed Ishikawa type iterative algorithm of solving a new class of generalized nonlinear implicit quasivariational inclusions are suggested and analysed. First, an existence theorem of solutions for generalized nonlinear implicit quasivariational inclusion is proved under suitable assumptions. Then, the convergence of the perturbed Ishikawa type iterative sequences generated by the new algorithm is proved. As special cases, some known results are also discussed.
index225!@#@!1997!@#@!Coarse Coding Accouts for Improvement of Spatial Discrimination after Plastic Reorganization in Rats and Humans!@#@!Proceedings of the 7th International Conference on Artificial Neural Networks!@#@!null
index226!@#@!2002!@#@!Ethical codes and their effect on conduct!@#@!Journal of Computing Sciences in Colleges!@#@!The simplest and most visible way for an organization to show its commitment to ethics is to issue a code of ethics that encourages the organization members to behave in an ethical way. This study investigates the efficacy of a code of ethics in a hypothetical situation. It shows that even a brief exposure to a code of ethics can have the desired effect.
index227!@#@!2002!@#@!An Efficient Branch-and-Bound Algorithm for the Assignment of Protein Backbone NMR Peaks!@#@!Proceedings of the IEEE Computer Society Conference on Bioinformatics!@#@!NMR resonance assignment is one of the key steps in solving an NMR protein structure. The assignment process links resonance peaks to individual residues of the target protein sequence, providing the prerequisite for establishing intra- and inter-residue spatial relationships between atoms. The assignment process is tedious and time-consuming, which could take many weeks. Though there exist a number of computer programs to assist the assignment process, many NMR labs are still doing the assignments manually to ensure quality. This paper presents a new computational method based on our recent work towardsautomating the assignment process, particularly the process of backbone resonance peak assignment. We formulate the assignment problem as a constrained weighted bipartite matching problem. While the problem, in the most general situation, is NP-hard, we present an efficient solution based on a branch-and-bound algorithm with effective bounding techniques and a greedy filtering algorithm for reducing the search space. Our experimental results on 70instances of (pseudo) real NMR data derived from 14 proteins demonstrate that the new solution runs much faster than a recently introduced (exhaustive) two-layer algorithm and recovers more correct peak assignments than the two-layer algorithm.
index228!@#@!2000!@#@!How to Prevent Type Flaw Attacks on Security Protocols!@#@!Proceedings of the 13th IEEE workshop on Computer Security Foundations!@#@!A type flaw attack on a security protocol is an attack where a field that was originally intended to have one type is subsequently interpreted as having another type. A number of type flaw attacks have appeared in the academic literature. In this paper, we prove that type flaw attacks can be prevented using a simple technique of tagging each field with some information indicating its intended type.
index229!@#@!2000!@#@!Computer Support System for Aneurysm Treatment!@#@!CBMS!@#@!An important medical problem of the noninvasive treatment of brain aneurysm demands special attention. The main reason is that in many cases, it is necessary to have direct information about size, shape, and exact location of the aneurysm. To provide a medical specialist with such information, a Virtual Aneurysm (VA) system has been created. Problems of its realization and efficiency are discussed in this paper. A novel approach to the simulation and visualization in biomedical systems is suggested, to achieve higher efficiency of the simulation and visualization. It is called branching simulation.
index230!@#@!1996!@#@!An Initial Comparison of Software and Engineering Designs of Automotive Cruise Control Systems!@#@!Proceedings of the 1996 Australian Software Engineering Conference!@#@!We contribute to the debate about the relation between software design and standard engineering design. We do this by examining the approaches taken by both disciplines to the design of a small embedded system. The example chosen is that of an automotive cruise control system whose design is described in both computing and automotive literature. We do not attempt to argue that software development should be more like other engineering disciplines nor do we support the argument that software development is too complex or different in nature to be compared to traditional engineering.
index231!@#@!1992!@#@!An Execution Model for Distributed Database Transactions and Its Implementation in VPL!@#@!Proceedings of the 3rd International Conference on Extending Database Technology: Advances in Database Technology!@#@!null
index232!@#@!2003!@#@!Technical papers: software understanding!@#@!International Conference on Software Engineering!@#@!null
index233!@#@!2002!@#@!A dynamic method for dominant point detection!@#@!Graphical Models!@#@!Detecting dominant points is an important step for shape representation. Most of dominant point detection methods attend to preset or find the region of support of each point. In this paper, we demonstrate an improved method for determining the region of support in the dominant point detection. Instead of setting the regions of support for points independently, the region of support dynamically depending on the previous region of support. The experimental results show that the proposed method is effective in detecting dominant points.
index234!@#@!2001!@#@!Osaka University "Trackies 2000"!@#@!RoboCup 2000: Robot Soccer World Cup IV!@#@!null
index235!@#@!2002!@#@!Constructing a video server with tertiary storage: practice and experience!@#@!Multimedia Systems!@#@!Handling a tertiary storage device, such as an optical disk library, in the framework of a disk-based stream service model, requires a sophisticated streaming model for the server, and it should consider the device-specific performance characteristics of tertiary storage. This paper discusses the design and implementation of a video server which uses tertiary storage as a source of media archiving. We have carefully designed the streaming mechanism for a server whose key functionalities include stream scheduling, disk caching and admission control. The stream scheduling model incorporates the tertiary media staging into a disk-based scheduling process, and also enhances the utilization of tertiary device bandwidth. The disk caching mechanism manages the limited capacity of the hard disk efficiently to guarantee the availability of media segments on the hard disk. The admission controller provides an adequate mechanism which decides upon the admission of a new request based on the current resource availability of the server. The proposed system has been implemented on a general-purpose operating system and it is fully operational. The design principles of the server are validated with real experiments, and the performance characteristics are analyzed. The results guide us on how servers with tertiary storage should be deployed effectively in a real environment.
index236!@#@!2002!@#@!Algorithms for mining system audit data!@#@!Data mining, rough sets and granular computing!@#@!We describe our research in applying data mining techniques to construct intrusion detection models. The key ideas are to mine system audit data for consistent and useful patterns of program and user behavior, and use the set of relevant system features presented in the patterns to compute classifiers that can recognize anomalies and known intrusions. Our past experiments showed that classification rules can be used to detect intrusions, provided that sufficient audit data is available for training and the right set of system features are selected. We use the association rules and frequent episodes computed from audit data as the basis for guiding the audit data gathering and feature selection processes. In order to compute only the relevant patterns, we consider the "order of importance" and "reference" relations among the attributes of data, and modify these two basic algorithms accordingly to use axis attribute(s) and reference attribute(s) as forms of item constraints in the data mining process. We also use an iterative level-wise approximate mining procedure for uncovering the low frequency but important patterns. We report our experiments in using these algorithms on real-world audit data.
index237!@#@!1998!@#@!Effectiveness of Producer-Initiated Communication!@#@!Proceedings of the Thirty-First Annual Hawaii International Conference on System Sciences-Volume 7 - Volume 7!@#@!null
index238!@#@!2003!@#@!Optimistic parallel simulation of a large-scale view storage system!@#@!Future Generation Computer Systems!@#@!In this paper, we present the design and implementation of a complex view storage system model. Here, a hierarchy of view storage servers are connected to an array of client-side local disks. The term view refers to the output or result of a query made on the part of an application that is executing on a client machine. These queries can to be arbitrarily complex and formulated using SQL. The goal of this system is to reduce the turnaround time of queries by exploiting locality both at the local disk level as well as between clients and servers prior to making the request to the highest level database server. This model has been designed for execution with an optimistic simulation engine. One of the primary drawbacks of this parallel synchronization mechanism has been high overheads due to state-saving. We attack this problem by implementing the model using reverse computation. Here, the event processing routines are made reversible, which avoids having incrementally state-saving values that can be reverse computed, such as ++ and --. Destructive assignments of the form a = b are saved using a swap operation, which precludes the need for additional state space. In our performance study of this application, we find that speedups range from 1.5 to over 5 on four processors. Super-linear speedups are attributed to a slow memory subsystem and the increased availability of level-1 and level-2 cache when moving to a larger number of processors.
index239!@#@!1986!@#@!A Classification of Algorithms which Are Well Suited for Implementations on the DAP as a Basis for Further Research on Parallel Programming!@#@!Conference on Algorithms and Hardware for Parallel Processing!@#@!null
index240!@#@!2003!@#@!Questioning the Software Engineering Unquestionables!@#@!IEEE Software!@#@!null
index241!@#@!1991!@#@!Hybrid Encoding: Constraints on Adressing Structure!@#@!Proceedings of the 2nd Congress of the Italian Association for Artificial Intelligence on Trends in Artificial Intelligence!@#@!null
index242!@#@!1997!@#@!A statistical brain-mapping system for the evaluation of communication disorders!@#@!CBMS!@#@!The authors describe the implementation of SISMAPEO, a database system designed to manage brain electrical activity mapping (BEAM) information which enables practitioners to carry out statistical analysis on groups and individuals based on topography maps. In order to evaluate their system they followed a methodology in which each patient is exposed to eyes-closed (OC) and eyes-open (OA) activation methods. Twenty 4-second epochs with a subset of 18 electrodes selected from the 10-20 International System referential montage are recorded. The register is transformed to the frequency domain via a FFT algorithm and then it is analyzed using statistical parameters for each typical band of the EEG spectrum. They present comparisons based on the t-score test, between two infant groups: a group with learning disabilities and a control. An analysis of the resulting coloured brain-mapping studies is presented. These patients show no evidence of abnormality in any imaging study such as CT or NMR. That is why they are using alternative ways of evaluating disorders such as neurophysiologic ones. At this point, they concentrate only on brain mapping records but the SISMAPEO system is planned to manage other relevant records, e.g., EMG or evoked potentials. They are carrying out clinical validations on infants with language and learning disorders.
index243!@#@!1996!@#@!A framework for MLS interoperability!@#@!Proceedings of the 1996 High-Assurance Systems Engineering Workshop!@#@!Distributed object oriented computing (DOC) is a new computing paradigm that promotes component based development, location independence, scalability, software reuse, etc. Users of multilevel security (MLS) technology want to take advantage of these new technologies However, the process of incorporating new technologies into MLS products is slower than the analogous process for non secure commercial products because MLS products must go through rigorous evaluation/certification procedures. We propose an architectural framework that speeds up the process of introducing new technologies to MLS users. We examine the drawbacks of traditional MLS approaches and take a fresh look at the requirements of MLS users. We then introduce security critical components that can enable MLS solutions and an MLS architectural framework that can accommodate not only legacy systems but also new technologies including DOC, without jeopardizing system security. Our framework separates security critical components/functions from the rest of the system because these components must go through rigorous evaluation/certification processes. This approach enables the secure use of new technologies for MLS users.
index244!@#@!1995!@#@!Sympathy: fast exact minimization of fixed polarity Reed-Muller expressions for symmetric functions!@#@!Proceedings of the 1995 European conference on Design and Test!@#@!In this paper a polynomial time algorithm for the minimization of Fixed Polarity Reed-Muller Expressions (FPRMs) for totally symmetric functions based on Ordered Functional Decision Diagrams (OFDDs) is presented. A generalization to partially symmetric functions is investigated. The algorithm has been implemented as the program Sympathy. Experimental results in comparison to previously published methods are given to show the efficiency of the approach.
index245!@#@!1988!@#@!Intractable Problems in Number Theory!@#@!Proceedings of the 8th Annual International Cryptology Conference on Advances in Cryptology!@#@!null
index246!@#@!2003!@#@!Comparison of Bicubic and Bézier Polynomials for Surface Parameterization in Volumetric Images!@#@!Proceedings of the 3rd IEEE Symposium on BioInformatics and BioEngineering!@#@!Curvature-based surface features are well suited for use in multimodal medical image registration. The accuracy of such feature-based registration techniques is dependent upon the reliability of the feature computation. The computation of curvature features requires second derivative information that is best obtained from a parametric surface representation. We present a method of explicitly parameterizing surfaces from volumetric data. Surfaces are extracted, without a global thresholding, using active contour models. A Mong basis for each surface patch is estimated and used to transform the patch into local, or parametric, coordinates. Surface patches are fit to first a bicubic polynomial and second to a bézier polynomial. The bicubic polynomial is fit in local coordinates using least squaressolved by singular value decomposition. Bézier polynomial is fit using de Casteljau algorithm. We tested our method by reconstructing surfaces from the surface model and analytically computing gaussian and mean curvatures. The model was tested on analytical and medical data and the results of both methods are compared.
index247!@#@!2003!@#@!Documenting software architectures: views and beyond!@#@!International Conference on Software Engineering!@#@!null
index248!@#@!2003!@#@!Algebraic Algorithmics: Theory and Applications!@#@!Cybernetics and Systems Analysis!@#@!This article is a review of works on the algebra of algorithms, which is a new promising line of investigation in the field of algebraic algorithmics and is progressing rapidly in Ukraine and abroad. To this line belong explorations into a multilevel structural software design method developed at the Automatic Programming Department at the V. M. Glushkov Cybernetics Institute of the Academy of Sciences of Ukraine.
index249!@#@!1999!@#@!A Fuzzy Hopfield-Tank Traveling Salesman Problem Model!@#@!INFORMS Journal on Computing!@#@!This article describes a Hopfield-Tank model of the Euclidean traveling salesman problem (using Aiyers subspace approach) that incorporates a fuzzy interpretation of the rows of the activation array. This fuzzy approach is used to explain the networks behavior. The fuzzy interpretation consists of computing the center of mass of the positive activations in each row. This produces real numbers along the time line, one for each city, and defines a tour in a natural way (referred to as a fuzzy tour). A fuzzy tour is computed at each iteration, and examination of such tours exposes fine features of the network dynamics. For example, these tours demonstrate that the network goes through (at least) three phases: centroid, monotonic, and nearest-city The centroid (initial) phase of the network produces an approximation to the centroid tour (i.e., the tour that orders the cities by central angle with respect to the centroid of the cities). The second phase produces an approximation to the monotonic tour (i.e., the tour that orders the cities by their projection onto the principal axis of the cities). The third phase produces an approximation to a nearest-city tour, that is, a tour whose length is between the tour lengths of the nearest-city-best (best starting city) and nearest-city-worst (worst starting city). Simulations are presented for up to 125 uniformly randomly generated cities.
index250!@#@!2003!@#@!Developing an Undergraduate Software Engineering Degree!@#@!Proceedings of the 16th Conference on Software Engineering Education and Training!@#@!null
index251!@#@!2003!@#@!Distributed communication algorithms for ad hoc mobile networks!@#@!Journal of Parallel and Distributed Computing!@#@!An ad hoc mobile network is a collection of mobile hosts, with wireless communication capabilities, forming a temporary network without the aid of any established fixed infrastructure. In such networks, topological connectivity is subject to frequent, unpredictable change. Our work focuses on networks with high rate of such changes to connectivity. For such dynamically changing networks we propose protocols which exploit the co-ordinated (by the protocol) motion of a small part of the network. We show that such protocols can be designed to work correctly and efficiently even in the case of arbitrary (but not malicious) movements of the hosts not affected by the protocol. We also propose a methodology for the analysis of the expected behavior of protocols for such networks, based on the assumption that mobile hosts (those whose motion is not guided by the protocol) conduct concurrent random walks in their motion space. In particular, our work examines the fundamental problem of communication and proposes distributed algorithms for it. We provide rigorous proofs of their correctness, and also give performance analyses by combinatorial tools. Finally, we have evaluated these protocols by experimental means.
index252!@#@!1979!@#@!Ein Ansatz zur Analyse komplexer Muster!@#@!Angewandte Szenenanalyse, DAGM Symposium!@#@!null
index253!@#@!1994!@#@!Superposition in Picture Languages!@#@!Proceedings of the 19th International Colloquium on Trees in Algebra and Programming!@#@!null
index254!@#@!1995!@#@!The information highway and Africa!@#@!Proceedings of the 1995 conference of the Centre for Advanced Studies on Collaborative research!@#@!The information highway heralds the very next revolution in communications. North America, Europe, and Japan pursue their plans to create the most advanced communications systems yet developed. This paper asks if the superhighway is affordable and relevant for african development.Issues and problems discussed include : - the information highway infrastructure, its control and the main actors, and the main actors; - social, cultural, political, and economic aspects of computer networking and their impact on network development and the availability of information; - promoting democratic access to information and enhancing possibilities for "South--South" information transfer and communication.
index255!@#@!2001!@#@!Addendum to "Presolve Analysis of Linear Programs Prior to Applying an Interior Point Method"!@#@!INFORMS Journal on Computing!@#@!In this note we point out that the assumptions of Propositions 1 and 2 in Gondzio (1997) are not sufficiently restrictive. We give an example that demonstrates the lack of precision in these propositions and discuss the necessary modifications of the propositions.
index256!@#@!1995!@#@!Interfacing FPGA/VLSI Processor Arrays!@#@!Proceedings of the IEEE International Conference on Application Specific Array Processors!@#@!Mapping DSP algorithms to FPGA/VLSI circuits is an important issue in Application-Specific Array Processor design. Since a DSP algorithm can be abstracted as a graph where each node is a shift-invariant DG (Dependence Graph) and the edges denote the data flow, it is possible to map a DSP algorithm to a set of processor arrays with some interface circuits. The interface design depends on the projection/scheduling vectors used on the two corresponding shift-invariant DGs and the interfacing cost is very significant when a lot of delays are necessary or when the processor operations are relatively inexpensive in terms of area. Therefore, when selecting these vectors in a design environment, the effect on the interface circuit must be accurately computed. In this paper, various interface circuit designs are presented and categorized based on the data conversion requirement. An algorithm to select a design from many design options to minimize the cost is also described.
index257!@#@!2003!@#@!Experiences!@#@!ACM SIGCSE Bulletin!@#@!null
index258!@#@!2003!@#@!Capacity and flow assignment issues in MPLS networks!@#@!International Journal of Network Management!@#@!MPLS technology enables IP networks to accept the challenge raised by emerging communication paradigms. This paper describes a nonlinear model with path capacity as design variables and space priority as constraints. The analysis shows that the close-form solution exists if traffic flows are allocated by an independent protocol.
index259!@#@!1999!@#@!Bridging Epistemologies: the Generative Dance Between Organizational Knowledge and Organizational Knowing!@#@!Organization Science!@#@!Much current work on organizational knowledge, intellectual capital, knowledge-creating organizations, knowledge work, and the like rests on a single, traditional understanding of the nature of knowledge. We call this understanding the "episte-mology of possession," since it treats knowledge as something people possess. Yet, this epistemology cannot account for the knowing found in individual and group practice. Knowing as action calls for an "epistemology of practice." Moreover, the epistemology of possession tends to privilege explicit over tacit knowledge, and knowledge possessed by individuals over that possessed by groups. Current work on organizations is limited by this privileging and by the scant attention given to knowing in its own right. Organizations are better understood if explicit, tacit, individual and group knowledge are treated as four distinct and coequal forms of knowledge (each doing work the others cannot), and if knowledge and knowing are seen as mutually enabling (not competing). We hold that knowledge is a tool of knowing, that knowing is an aspect of our interaction with the social and physical world, and that the interplay of knowledge and knowing can generate new knowledge and new ways of knowing. We believe this generative dance between knowledge and knowing is a powerful source of organizational innovation. Harnessing this innovation calls for organizational and technological infrastructures that support the interplay of knowledge and knowing. Ultimately, these concepts make possible a more robust framing of such epistemologically-centered concerns as core competencies, the management of intellectual capital, etc. We explore these views through three brief case studies drawn from recent research.
index260!@#@!2003!@#@!Huffman Tree Decomposition and Its Coding Applications!@#@!Proceedings of the 17th International Conference on Advanced Information Networking and Applications!@#@!In this paper a new Huffman tree decomposition technique is presented. The basis for this technique involves a set of encoding schemes. These encoding schemes exploit the technique of parallel computation to speed up the encoding and decoding procedures for the Huffman encoding scheme. The proposed encoding schemes also impose a complex structure on the resulting codewords such that the decoding procedures have the potential to become error correcting ones.
index261!@#@!2003!@#@!Analysis of combined voice/data/video operation in cable and DSL access networks: graceful degradation under overload!@#@!Performance Evaluation!@#@!We develop exact models to analyze the performance of several types and grades of data, voice and video sessions over a cable or DSL-based access network. Each session is characterized by a minimum guaranteed data-rate and a maximum allowed data-rate. Sessions would normally transmit at the maximum rate but under congestion some or all sessions would see graceful rate degradation. For each class the blocking probability, the average data-rate attained by a session, the probability that the attained data-rate exceeds a certain target value, and the data-rate that is exceeded a certain target percent of the time are computed. In addition, a system-wide probability of data-rate degradation is also computed. A bufferless model with product-form structure and insensitivity to session holding time distribution except through mean (heavy-tailed distributions are allowed), and a buffered model with standard Markov chain structure are developed. The models are also generalized to allow data-rate degradation of real-time streaming traffic (e.g., switch from G.711 to G.728 encoding or turn on silence suppression) whenever the total bandwidth usage exceeds a certain threshold. Whenever a model is sensitive to session holding time distribution, that sensitivity is studied through simulations. Several numerical examples are given to illustrate the use of the models in providing quality of service mechanisms over the "last mile" of access.
index262!@#@!2000!@#@!Domain Name Based Visualization of Web Histories in a Zoomable User Interface!@#@!Proceedings of the 11th International Workshop on Database and Expert Systems Applications!@#@!Users of hypertext systems like the World Wide Web (WWW) often find themselves following hypertext links deeper and deeper, only to find themselves "lost" and unable to find their way back to the previously visited pages. We have implemented a Web browser companion called Domain Tree Browser (DTB) that builds a tree structured visual navigation history while browsing the Web. The Domain Tree Browser organizes the URLs visited based on the domain name of each URL and shows thumbnails of each page in a zoomable window.
index263!@#@!2003!@#@!Dynamic selection and effective compression of key frames for video abstraction!@#@!Pattern Recognition Letters!@#@!This paper reports on a new key frame based video abstraction method. With our method, a video sequence is first segmented into a number of video shots. Several key frames are selected in each shot using a dynamic selection technique. For these key frames, a motion-based clustering algorithm is applied so that key frames in the same cluster are alike in sense of motion compensation error, while those from different clusters are quit dissimilar. Then a novel cluster-based coding scheme is developed for efficient representation of the key frames. Simulations show that the proposed method can select key frames according to the dynamics of a video sequence and abstract the video with different levels of scalability.
index264!@#@!2003!@#@!Compression of RADARSAT Data with Block Adaptive Wavelets!@#@!Proceedings of the Conference on Data Compression!@#@!null
index265!@#@!2000!@#@!Re-Engineering of Estelle Specifications for Maintenance and Evolution Purposes!@#@!Proceedings of the Conference on Software Maintenance and Reengineering!@#@!In this paper we propose a re-engineering tool for Estelle specifications. The tool performs the conversion from a textual representation of an Estelle specification into a graphical one. It allows to realize automatic transition transformations during this conversion. Moreover, changes can be directly made on this graphical representation and the result converted back to the textual form. These features make this tool essential for maintenance, reuse and evolution of Estelle specifications.
index266!@#@!1985!@#@!Einfl&uuml;sse von "Moving-window"-Verfahren auf Texturdiskriminanzeigenschaften in Echokardiogrammen!@#@!Mustererkennung 1985, DAGM-Symposium!@#@!null
index267!@#@!2002!@#@!Topological Quadrangulations of Closed Triangulated Surfaces Using the Reeb Graph!@#@!Proceedings of the 10th International Conference on Discrete Geometry for Computer Imagery!@#@!null
index268!@#@!2002!@#@!Planning with a language for extended goals!@#@!Eighteenth national conference on Artificial intelligence!@#@!Planning for extended goals in non-deterministic domains is one of the most significant and challenging planning problems. In spite of the recent results in this field, no work has proposed a language designed specifically for planning. As a consequence, it is still impossible to specify and plan for several classes of goals that are typical of real world applications, like for instance "try to achieve a goal whenever possible", or "if you fail to achieve a goal, recover by trying to achieve something else".We propose a new goal language that allows for capturing the intended meaning of these goals. We give a semantics to this language that is radically different from the usual semantics for extended goals, e.g., the semantics for LTL or CTL. Finally, we implement an algorithm for planning for extended goals expressed in this language, and experiment with it on a parametric domain.
index269!@#@!1988!@#@!A Restriction of Factoring in Binary Resolution!@#@!Proceedings of the 9th International Conference on Automated Deduction!@#@!null
index270!@#@!2002!@#@!A Unified Decomposition of Ensemble Loss for Predicting Ensemble Performance!@#@!Proceedings of the Nineteenth International Conference on Machine Learning!@#@!null
index271!@#@!1997!@#@!Undirected single source shortest paths in linear time!@#@!Proceedings of the 38th Annual Symposium on Foundations of Computer Science!@#@!The single source shortest paths problem (SSSP) is one of the classic problems in algorithmic graph theory: given a weighted graph G with a source vertex s, find the shortest path from s to all other vertices in the graph. Since 1959 all theoretical developments in SSSP have been based on Dijkstra's algorithm, visiting the vertices in order of increasing distance from s. Thus, any implementation of Dijkstra's algorithm sorts the vertices according to their distances from s. However, we do not know how to sort in linear time. Here, a deterministic linear time and linear space algorithm is presented for the undirected single source shortest paths problem with integer weights. The algorithm avoids the sorting bottle-neck by building a hierarchical bucketing structure, identifying vertex pairs that may be visited in any order.
index272!@#@!1995!@#@!A scalable time-sharing scheduling for partitionable distributed memory parallel machines!@#@!Proceedings of the 28th Hawaii International Conference on System Sciences!@#@!We propose a new process scheduling queue system called the distributed queue tree (DQT) for a distributed memory, dynamically partitionable parallel machines. We assume that partitions can be nested dynamically and that a process in a partition can be preempted. The combination of dynamically nested partitioning and time-sharing scheduling may provide an interactive environment and higher processor utilization. The key idea of DQT is to distribute process scheduling queues to each partition. We propose a round-robin scheduling algorithm and several task allocation policies on DQT. The simulation results show that time-sharing with DQT results in better processor utilization than that available from batch scheduling in high-load situations.
index273!@#@!1998!@#@!Intelligent Systems and Active DSS!@#@!Proceedings of the Thirty-First Annual Hawaii International Conference on System Sciences-Volume 5 - Volume 5!@#@!null
index274!@#@!2003!@#@!Sneak previews: surf's up!@#@!Network Computing!@#@!null
index275!@#@!2000!@#@!Multistage Inventory Management with Expediting!@#@!Operations Research!@#@!After reformulating Clark and Scarf's (1960) classical serial multi-echelon model so that the lead time between adjacent echelons is one week (period), the option to expedite between each resulting echelon is added. Thus, each week requires a decision to be made at each echelon on how many units to expedite in from the next upstream echelon (to be received immediately) and how many to regular order (to be received in one week), with the remainder detained (left as is). The model can be interpreted as addressing dynamic lead time management, in which the (remaining) effective lead time for each ordered unit can be dynamically reduced by expediting and/or extended. Use of Clark and Scarf's (1960) idea of echelon stocks reduces a complex, multidimensional stocking problem to the analysis of a series of one-dimensional subproblems. What are calledtop-down base stock policies, which are readily amenable to managerial interpretation, are shown to be optimal. Myopic policies are shown to be optimal in the stationary, in1nite horizon case. The results are illustrated numerically.
index276!@#@!1987!@#@!ESPRIT 932: Knowledge Based Real-Time Supervision in Computer Integrated Manufacturing (CIM)!@#@!Wissensbasierte Systeme, 2. Internationaler GI-Kongress,!@#@!null
index277!@#@!2000!@#@!HOMASCOW: A Holonic Multi-Agent System for Cooperative Work!@#@!Proceedings of the 11th International Workshop on Database and Expert Systems Applications!@#@!Assistance tools for actors of cooperative systems, which are often centralized are increasingly designed to adhere to the system organization using a distributed architecture. However, generally these systems have difficulty in managing data coherency at the global level. In answer to this problem, we turned towards a particular organizational model: holonic systems. This concept has guided us in the design of the Holonic Multi-Agent System (HOLOMAS), which offers a good compromise between the distribution of knowledge and control centralization. In fact, the use of the HOLOMAS appeared to be necessary following the study of the procedures used in the patent department of a large company.
index278!@#@!2000!@#@!Achieving moderate fairness for UDP flows by path-status classification!@#@!Proceedings of the 25th Annual IEEE Conference on Local Computer Networks!@#@!We propose a scheme of rate control for continuous UDP flow with moderate fairness. First, per-packet relative one-way trip time (ROTT) of a UDP stream at a receiver on the Internet is investigated extensively, and it is found that spikes with successive plots, which we call spike-trains, often appear on a time-ROTT graph. Also, congestion-related losses are found to be strongly correlated only to the spike-trains and the path status is effectively identified by such spike-trains. Based on these observations, a rate control with moderate fairness using the path-status, PAth-STatus-based RAte control (PASTRA), is presented. The effectiveness of PASTRA in achieving moderate fairness for UDP streams on the Internet is demonstrated.
index279!@#@!1994!@#@!The Applicability of Logic Program Analysis and Transformation to Theorem Proving!@#@!Proceedings of the 12th International Conference on Automated Deduction!@#@!null
index280!@#@!1999!@#@!Quality of Service Management in Healthcare Organizations: A Case Study!@#@!Proceedings of the 12th IEEE Symposium on Computer-Based Medical Systems!@#@!Healthcare organizations are looking for Information Technology(IT) based solutions to face increased competition, changing government regulations, and the challenge to improve efficiencies and the quality of service. Many health care organizations have established cost effective enterprise-wide computing technologies, such as client/server based systems, to improve the effectiveness of information delivery and thereby quality of service(QoS) of patient care.The accessibility of patient information including data and images from anywhere/anytime over the distributed network systems, greatly improves the effectiveness of the patient encounter and thereby quality of service management in health care organizations. This can not be achieved without the involvement of human element at all stages of a healthcare management environment where services must be consolidated without compromising the quality of patient care. While the quality of service requirements vary from user to user and from application to application, these requirements need to be translated (mapped) to a finite set of network and system resource requirements.This paper addresses the problem of developing QoS specification in healthcare industry.
index281!@#@!2003!@#@!HelpfulMed: intelligent searching for medical information over the internet!@#@!Journal of the American Society for Information Science and Technology!@#@!Medical professionals and researchers need information from reputable sources to accomplish their work. Unfortunately, the Web has a large number of documents that are irrelevant to their work, even those documents that purport to be "medically-related." This paper describes an architecture designed to integrate advanced searching and indexing algorithms, an automatic thesaurus, or "concept space," and Kohonen-based Self-Organizing Map (SOM) technologies to provide searchers with fine-grained results. Initial results indicate that these systems provide complementary retrieval functionalities. HelpfulMed not only allows users to search Web pages and other online databases, but also allows them to build searches through the use of an automatic thesaurus and browse a graphical display of medical-related topics. Evaluation results for each of the different components are included. Our spidering algorithm outperformed both breadth-first search and PageRank spiders on a test collection of 100,000 Web pages. The automatically generated thesaurus performed as well as both MeSH and UMLS--systems which require human mediation for currency. Lastly, a variant of the Kohonen SOM was comparable to MeSH terms in perceived cluster precision and significantly better at perceived cluster recall.
index282!@#@!2003!@#@!Threshold Utility, Choice, and Binary Relations!@#@!Automation and Remote Control!@#@!Representation of the binary relations and choice functions by the utility functions was considered. The results of utility maximization were presented for the classical case of no comparison threshold and with a threshold depending on one alternative. Models were constructed where the threshold depends on two compared alternatives and/or admissible set of alternatives. A model of choice describing H.A. Simon's concept of choice was proposed and considered. The class of binary relations of partial order and its subclasses were studied. Some new classes of binary relations such as weak biorders and simple and simplest semiorders were constructed, and their representations by the threshold utility function were determined.
index283!@#@!1995!@#@!Author Index!@#@!Proceedings of the Computer Architectures for Machine Perception!@#@!Abstract: Developing software for distributed computing systems is challenging, due to lack of good software development methodologies for distributed computing systems. It is very important to develop reliable, adaptable and expandable application software for distributed computing systems. Autonomous decentralized systems (ADS) is a distributed computing system with online expandability, online maintainability and fault tolerance capability. A framework for developing ADS application software is presented. Our framework consists of object oriented requirements analysis, system design, implementation, allocation, verification and maintenance. It is based on the object oriented computation model developed for ADS application software development which supports online expandability and online modifiability. CASE environments for ADS software development are also discussed.
index284!@#@!1994!@#@!Local Specification of Distributed Families of Sequential Objects!@#@!Selected papers from the 10th Workshop on Specification of Abstract Data Types Joint with the 5th COMPASS Workshop on Recent Trends in Data Type Specification!@#@!null
index285!@#@!1998!@#@!Yes, "Bait and Switch" Really Benefits Consumers!@#@!Marketing Science!@#@!In our 1990 Marketing Science paper we demonstrated that a law prohibiting bait and switch may have the surprising consequence of hurting the consumers it was designed to protect. Wilkie, Mela, and Gundlach (1998) postulate that this may be false if up selling is equally effective when the bait brand is available and when it is out of stock. We show here that our earlier conclusion is correct in a more general setting: A law prohibiting bait and switch in a competitive market can reduce consumer well-being but never improve it. When bait and switch occurs, it creates welfare gains, and when it would create welfare losses, it does not occur, regardless of a law prohibiting the practice.
index286!@#@!2002!@#@!Code Placement and Replacement Strategies for Wideband CDMA OVSF Code Tree Management!@#@!IEEE Transactions on Mobile Computing!@#@!The use of OVSF codes in WCDMA systems has offered opportunities to provide variable data rates to flexibly support applications with different bandwidth requirements. Two important issues in such an environment are the code placement problem and code replacement problem. The former may have significant impact on code utilization and, thus, code blocking probability, while the latter may affect the code reassignment cost if dynamic code assignment is to be conducted. The general objective is to make the OVSF code tree as compact as possible so as to support more new calls by incurring less blocking probability and less reassignment costs. Earlier studies about these two problems either do not consider the structure of the OVSF code tree or cannot utilize the OVSF codes efficiently. To reduce the call blocking probability and the code reassignment cost, we propose two simple yet efficient strategies that can be adopted by both code placement and code replacement: leftmost and crowded-first. Numerical analyses on call blocking probability and bandwidth utilization of OVSF code trees when code reassignment is supported are provided. Our simulation results show that the crowded-first strategy can significantly reduce, for example, the code blocking probability by 77 percent and the number of reassignments by 81 percent, as opposed to the random strategy when the system is 80 percent fully loaded and the max SF = 256.
index287!@#@!2002!@#@!Transformation formula for a double Clausenian hypergeometric series, its q-analogue, and its invariance group!@#@!Journal of Computational and Applied Mathematics!@#@!A transformation formula for a double basic hypergeometric series of type φ1:2;20:2;2 is derived. This transformation yields a double series analogue of Sears' transformation for a terminating 3φ2 series. In the limit q → 1, the formula reduces to a transformation for a terminating double Clausenian hypergeometric series of unit argument (one of the proper Kampé de Fériet series, F1:2;20:2;2(1,1)). This formula is a double series analogue of Whipple's terminating 3F2 transformation. This transformation gives rise to a transformation group (the invariance group) acting on the parameters of the double series. The invariance group is examined and shown to be a subgroup of a double copy of the symmetries of the square.
index288!@#@!2003!@#@!Using data analysis to discover the fundamental theorem of calculus!@#@!PRIMUS: problems, resources, and issues in mathematics undergraduate studies!@#@!The authors use ideas on fitting functions to data to lead students to motivate the concept of the antiderivative and formulas for the integrals of various basic functions, as well as to discover the Fundamental Theorem of Calculus.
index289!@#@!2002!@#@!Review of "Ruling the root: Understanding the domain name system controversy" by Milton L. Mueller the MIT press!@#@!Ubiquity!@#@!null
index290!@#@!1993!@#@!Insulin: An Instruction Set Simulation Environment!@#@!Proceedings of the 11th IFIP WG10.2 International Conference sponsored by IFIP WG10.2 and in cooperation with IEEE COMPSOC on Computer Hardware Description Languages and their Applications!@#@!null
index291!@#@!2003!@#@!The impact of affective design of product packaging upon consumer purchase decisions!@#@!Designing Pleasurable Products And Interfaces!@#@!Affective design aims to create a product that has expected levels of functionality and usability but, additionally offers the user a positive emotional experience. Some success has been achieved by using the Kansei engineering approach but this has not been explicitly applied to packaging design.This paper reports on the first stages of an Affective Packaging Design research programme and presents the result of experiments that explore the relationships between consumer selection and packaging shape using a combination of questionnaires, focus groups and the semantic differential technique. The stimuli for the experiment were examples of confectionery packaging.Results will be presented which indicate relationships between confectionery packaging shape and recipient demographic profile. It is concluded that to inform the design process the study it is important to consider the whole purchase experience, for example, product purchaser, product user and purchase reasons.
index292!@#@!2002!@#@!Advanced disinfection and health-care aspects of wastewater reclamation and reuse in agriculture in Mediterranean regions!@#@!Development and application of computer techniques to environmental studies!@#@!In order to address water pollution and conservation in Mediterranean basin the Polytechnic University of Bari led a 3-year joint research project focused on technical and health care aspects of wastewater reuse in agriculture funded by the European Commission. This paper summarizes activities performed and main conclusions and recommendations drawn on the basis of experimental results.
index293!@#@!1999!@#@!The Ultrascalar Processor-An Asymptotically Scalable Superscalar Microarchitecture!@#@!Proceedings of the 20th Anniversary Conference on Advanced Research in VLSI!@#@!The poor scalability of existing superscalar processors has been of great concern to the computer engineering community. In particular, the critical-path lengths of many components in existing implementations grow as T(n2) where n is the fetch width, the issue width, or the window size. This paper presents a novel implementation, called the Ultrascalar processor, that dramatically reduces the asymptotic critical-path length of a superscalar processor. The processor is implemented by a large collection of ALUs with controllers (together called execution stations) connected together by a network of parallel-prefix tree circuits. A fat-tree network connects an interleaved cache to the execution stations.
index294!@#@!1995!@#@!A technique to determine power-efficient, high-performance superscalar processors!@#@!Proceedings of the 28th Hawaii International Conference on System Sciences!@#@!Processor performance advances are increasingly inhibited by limitations in thermal power dissipation. Part of the problem is the lack of architectural power estimates before implementation. Although high-performance designs exist that dissipate low power, the method for finding these designs has been through trial-and-error. The paper presents systematic techniques to find low-power, high-performance superscalar processors tailored to specific user benchmarks. The model of power is novel because it separates power into architectural and technology components. The architectural component is found via trace-driven simulation, which also produces performance estimates. An example technology model is presented that estimates the technology component, along with critical delay time and real estate usage. This model is based on case studies of actual designs. It is used to solve an important problem: increasing the duplication in superscalar execution units without excessive power consumption. Results are presented from runs using simulated annealing to maximize processor performance subject to power and area constraints. The major contributions of the paper are the separation of architectural and technology components of dynamic power, the use of trace-driven simulation for architectural power measurement, and the use of a near-optimal search to tailor a processor design to a benchmark.
index295!@#@!1998!@#@!Ontobroker in a Nutshell!@#@!Proceedings of the Second European Conference on Research and Advanced Technology for Digital Libraries!@#@!null
index296!@#@!2001!@#@!A real-time process algebra with open intervals and maximal progress!@#@!Nordic Journal of Computing!@#@!Many real-time process algebras have the maximal progress assumption. In those process algebras, the time intervals in which actions are enabled are left-closed. This paper presents a process algebra that satisfies the maximal progress assumption and allows left-open intervals. A non-observable time step is introduced to model the time when an urgent action enabled in interval (0,1) is taken. Furthermore, we have to distinguish between observable actions and actions which only get enabled after a non-observable time step. This is necessary, since the latter actions may only produce internal actions. The distinction is done by extending the set of actions by marked actions.The real-time process algebra presented here is an extension of Milner's CCS. This algebra can be used to model dynamic priority of actions at the same point in time. We introduce various equivalence relations based on bisimulation.
index297!@#@!1996!@#@!Performance evaluation of the binary logarithmic arbitration method (BLAM)!@#@!Proceedings of the 21st Annual IEEE Conference on Local Computer Networks!@#@!The binary logarithmic arbitration method (BLAM) is currently under review by the IEEE 802.3 standards committee for possible standardization. BLAM is a new arbitration algorithm for Ethernet that is backwards compatible with the existing binary exponential backoff (BEB) algorithm. Simulation models of BEB and BLAM are developed. Using these models, four experiments evaluating BEB and BLAM under overload conditions are described. The experiments focus on a small population Ethernet, scaling to large population Ethernets, BLAM and BEB compatibility, and the ability to transmit 64-kbps voice streams. It is shown that BLAM supports higher throughput and lower delay than BEB. BLAM also demonstrates notably lower variability in delay than BEB. For the transmission of voice streams, it is shown that BLAM offers outstanding performance in the percentage of voice packets successfully transmitted within a hard deadline of 10 or 20 milliseconds.
index298!@#@!1995!@#@!Message from the General Chair!@#@!Proceedings of the IEEE International Workshop on Defect and Fault Tolerance in VLSI Systems!@#@!null
index299!@#@!1991!@#@!A Modular Approach to Denotational Semantics!@#@!Proceedings of the 4th International Conference on Category Theory and Computer Science!@#@!null
index300!@#@!1998!@#@!A Transmission-Constrained Unit Commitment Method!@#@!Proceedings of the Thirty-First Annual Hawaii International Conference on System Sciences - Volume 3!@#@!This paper presents a transmission-constrained unit commitment method using a Lagrangian relaxation approach. The transmission constraints are modeled as linear constraints based on a DC power flow model. The transmission constraints, as well as the demand and spinning reserve constraints, are relaxed by attaching Lagrange multipliers. In this paper we take a new approach in the algorithmic scheme. A three-phase algorithm is devised including dual optimization, a feasibility phase and unit decommitment. A test problem involving more than 2500 transmission lines and 2200 buses is tested along with other test problems.
index301!@#@!1998!@#@!An Algorithm for Identifying the Frame of a Pointed Finite Conical Hull!@#@!INFORMS Journal on Computing!@#@!We present an algorithm for identifying the extreme rays of the conical hull of a finite set of vectors whose generated cone is pointed. This problem appears in diverse areas including sto-chastic programming, computational geometry, and non-parametric efficiency measurement. The standard approach consists of solving a linear program for every element of the set of vectors. The new algorithm differs in that it solves fewer and substantially smaller LPs. Extensive computational testing vali-dates the algorithm and demonstrates that for a wide range of problems it is computationally superior to the standard approach.
index302!@#@!2002!@#@!Rapid Prototyping of Mixed Hardware and Software Systems!@#@!Proceedings of the Euromicro Symposium on Digital Systems Design!@#@!This paper presents a practical approach to hardware/software partitioning, which is targeted at the rapid prototyping of embedded systems as a mixture of software and reconfigurable hardware. In our method, an application is firstly specified in the high-level programming language C ¿ this is considered to be an executable functional specification. We subsequently allow this specification to be partitioned into hardware and software modules. The hardware modules, which are defined in Handel-C, are synthesised and mapped to a Xilinx Virtex FPGA. The FPGA is situated on a PCB, which is installed in a standard PC. The software modules are executed on the same PC. The paper describes the methodology, and shows how the partitioning process can be readily achieved with minimal changes to the original C program via the use of a predefined library. A simple example is used to illustrate the design process.
index303!@#@!1998!@#@!Foreword!@#@!Proceedings of the 3rd. International Conference on Face & Gesture Recognition!@#@!The collection of papers that follow this Editorial (beginning on page 43) come from the symposium &ldquo;Computing Futures in Engineering Design&rdquo; that was held on the campus of Harvey Mudd College in Claremont, California, on May 2&ndash;3, 1997. The symposium focused on future roles of computing in doing design and engineering and in the teaching of design and engineering. The intention of the symposium organizer, Clive Dym, was to provide useful insight, advice, and information to educators about how they might think about the future of design in engineering education.
index304!@#@!2002!@#@!A Method to Reduce Power Dissipation during Test for Sequential Circuits!@#@!Proceedings of the 11th Asian Test Symposium!@#@!For recent VLSIs designe for low power, reduction ofpower dissipation during test is one of the most impor-tant problems.This paper presents a metho to reducepower dissipation during test for sequential circuits.The goal is to obtain test vectors for sequential circuitsthat achieve low power dissipation.In our method,testvectors generate by ATPG are given and they are im-prove to reduce power dissipation without losing theoriginal stuck-at fault coverage.Due to the correlationbetween power dissipation and the number of transitiongates, the number of transition gates is evaluate foreach test vector during modification of test vectors.Inorder to keep the original fault coverage, logic simula-tion and fault simulation are performed, every time atest vector is modified.The effectiveness of our methodis shown by experimental results for ISCAS '89 bench-mark circuits.
index305!@#@!1997!@#@!Complete Cuboidal Sets in Axiomatic Domain Theory!@#@!Proceedings of the 12th Annual IEEE Symposium on Logic in Computer Science!@#@!We study the enrichment of models of axiomatic domain theory. To this end, we introduce a new and broader notion of domain, viz. that of complete cuboidal set, that complies with the axiomatic requirements. We show that the category of complete cuboidal sets provides a general notion of enrichment for a wide class of axiomatic domain-theoretic structures.
index306!@#@!2002!@#@!Towards autonomous characters for interactive media!@#@!Intelligent agents for mobile and virtual media!@#@!This chapter describes a project to develop virtual environment-based Teletubby characters, as in the children's television programme. The differences between the media are considered and the requirements for character development. The multi-level architecture adopted, BALSA (Behavioural Architecture for Life-like Synthetic Agents), is described in detail and future developments are proposed.
index307!@#@!2000!@#@!Telemedicine: The Next Generation Is Here!@#@!Proceedings of the Academia/Industry Working Conference on Research Challenges!@#@!Telemedicine is a discipline that has existed as a Next Generation Enterprise for over four decades. This paper will discuss the history, driving forces, funding and specialties included in telemedicine as they manifest the characteristics of NGEs. Industry examples will be described. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player
index308!@#@!2003!@#@!Business-to-business interactions: issues and enabling technologies!@#@!The VLDB Journal &mdash; The International Journal on Very Large Data Bases!@#@!Business-to-Business (B2B) technologies pre-date the Web. They have existed for at least as long as the Internet. B2B applications were among the first to take advantage of advances in computer networking. The Electronic Data Interchange (EDI) business standard is an illustration of such an early adoption of the advances in computer networking. The ubiquity and the affordability of the Web has made it possible for the masses of businesses to automate their B2B interactions. However, several issues related to scale, content exchange, autonomy, heterogeneity, and other issues still need to be addressed. In this paper, we survey the main techniques, systems, products, and standards for B2B interactions. We propose a set of criteria for assessing the different B2B interaction techniques, standards, and products.
index309!@#@!1996!@#@!Calibration of a Foveated Wide-Angle Lens on an Active Vision Head!@#@!CVPR!@#@!Inspired by the properties of the humam visual system, a new active vision system called ESCHeR (Etl Stereo Compact Head For Robot Vision) has been recently implemented with foveated wide-angle lenses. The lenses exhibit a wide field of view along with a space-varying resolution for facilitating both detection and close observation. However, to handle such optical properties and achieve basic eye movement functions, new calibration methods are needed. Therefore, two novel and online techniques are presented that in one case perform a global identification of the optical process through artificial neural techniques and in the other case compute the physical parameters by using environmental feature-tracking and controlled rotations of the cameras. Self-alignment of the cameras is also achieved using a similar technique.
index310!@#@!1997!@#@!Alternating-time Temporal Logic!@#@!Proceedings of the 38th Annual Symposium on Foundations of Computer Science!@#@!Temporal logic comes in two varieties: linear-time temporal logic assumes implicit universal quantification over all paths that are generated by system moves; branching-time temporal logic allows explicit existential and universal quantification over all paths. We introduce a third, more general variety of temporal logic: alternating-time temporal logic offers selective quantification over those paths that are possible outcomes of games, such as the game in which the system and the environment alternate moves. While linear-time and branching-time logics are natural specification languages for closed systems, alternating-time logics are natural specification languages for open systems. For example, by preceding the temporal operator ``eventually'' with a selective path quantifier, we can specify that in the game between the system and the environment, the system has a strategy to reach a certain state. Also the problems of receptiveness, realizability, and controllability can be formulated as model-checking problems for alternating-time formulas. Depending on whether we admit arbitrary nesting of selective path quantifiers and temporal operators, we obtain the two alternating-time temporal logics ATL and ATL*. We interpret the formulas of ATL and ATL* with respect to two models of composition for open systems, synchronous and asynchronous. For synchronous systems, the expressive power of ATL beyond CTL comes at no cost: the model-checking complexity of synchronous ATL is linear in the size of the system and the length of the formula. The symbolic model-checking algorithm for CTL extends with few modifications to synchronous ATL, and with some work, also to asynchronous ATL, whose model-checking complexity is quadratic. This makes ATL an obvious candidate for the automatic verification of open systems. In the case of ATL*, the model-checking problem is closely related to the synthesis problem for linear-time formulas, and requires doubly exponential time for both synchronous and asynchronous systems.
index311!@#@!1998!@#@!Compositional Analysis of Expected Delays in Networks of Probabilistic I/O Automata!@#@!Proceedings of the 13th Annual IEEE Symposium on Logic in Computer Science!@#@!null
index312!@#@!1996!@#@!A comparative study of temporal DBMS architectures!@#@!Proceedings of the 7th International Workshop on Database and Expert Systems Applications!@#@!In the past few years, a number of implementations of temporal DBMSs has been reported. Most of these implementations share a common feature, which is that they have been built as an extension to a snapshot DBMS. The authors present three alternative design approaches that can be used for extending a snapshot DBMS to support temporal data, and evaluate the suitability of each approach, with respect to a number of design objectives.
index313!@#@!1996!@#@!Analogue Fault Modelling and Simulation for Supply Current Monitoring!@#@!Proceedings of the 1996 European conference on Design and Test!@#@!Fault simulation of analogue circuits is a very CPU intensive task. This paper describes a technique to increase the speed of fault simulation. The effects of bridging faults within operational amplifiers have been classified according to the externally observable behaviour reducing the number of fault simulations by two thirds. Parameterisable macromodels have been written in which both fault-free specifications and faulty effects can be modelled. The supply current is also modelled. These macromodels have been verified by embedding within a larger circuit, and have been shown to accurately model fault-free and faulty behaviour, and to propagate faulty effects correctly. The macromodels simulate about 7.5 times faster than the full transistor model.
index314!@#@!1996!@#@!On Stable Line Segments in Triangulations!@#@!Proceedings of the 8th Canadian Conference on Computational Geometry!@#@!null
index315!@#@!2001!@#@!Improved Recognition of Spectrally Mixed Land Cover Classes Using Spatial Textures and Voting Classifications!@#@!Proceedings of the 9th International Conference on Computer Analysis of Images and Patterns!@#@!null
index316!@#@!2002!@#@!Indexing Software for Ancient Kannada Books!@#@!LEC!@#@!This paper deals with the automatic generation of indexto Kannada documents. The basic objective of thisexercise is to provide an efficient, user-friendly andreliable tool for index generation of Kannada documents.The input to the system may come either from an OpticalCharacter Recognition system if it is made available, orfrom typeset documents. The output provides an editableand searchable index. Results indicate that theapplication is fast, comprehensive, effective and error-free.
index317!@#@!2000!@#@!Kleisli: Its Exchange Format, Supporting Tools, and an Application in Protein Interaction Extraction!@#@!Proceedings of the 1st IEEE International Symposium on Bioinformatics and Biomedical Engineering!@#@!We describe the Pizzkell/Kleisli suite of software for bioinformatics data integration. We also present a protein interaction extraction system to illustrate the power of this software in the rapid construction of bioinformatics applications.
index318!@#@!2003!@#@!DNA computing by blocking!@#@!Theoretical Computer Science!@#@!We present a method for molecular computing which relies on blocking (inactivating) this part of the total library of molecules that does not contribute to (finding) a solution--this happens essentially in one biostep (after the input has been read). The method is explained by presenting a DNA based algorithm for solving (albeit in the theoretical sense only!) the satisfiability problem.
index319!@#@!1991!@#@!Toward the Automatic Digitization of Map Text!@#@!Mustererkennung 1991, 13. DAGM-Symposium!@#@!null
index320!@#@!1980!@#@!The Design of a Subprocessor with Dynamic Microprogramming with MIMOLA!@#@!GI-NTG Fachtagung Struktur und Betrieb von Rechensystemen!@#@!null
index321!@#@!2003!@#@!Beyond the classroom!@#@!ACM SIGCSE Bulletin!@#@!null
index322!@#@!2001!@#@!Inventory Policies for Systems with Stochastic and Deterministic Demand!@#@!Operations Research!@#@!We consider a periodic review inventory system with demand arriving simultaneously from a deterministic source and a random source. The deterministic demand has to be satisfied immediately and the stochastic demand can be backordered. Assuming that the stochastic demand is never backlogged if there is stock in the system, we prove that a modified ( s, S) policy is optimal under general conditions if there is a setup cost. If there is a smoothing cost instead of the setup cost, we observe that the problem corresponds to a standard model with one source of demand.
index323!@#@!1996!@#@!A proposal of flow control mechanism for multicast ABR and its performance!@#@!Proceedings of the 21st Annual IEEE Conference on Local Computer Networks!@#@!One of the functions that should be provided in ATM LANs is multicast communication. For multicast communication on ATM LANs, the architecture of the switch fabric and protocols for signaling have been studied. However, when data communication using a multicast connection such as a LAN emulation service which expects the high throughput is provided, ABR (available bit rate) service on a multicast connection (multicast ABR) is also required. ABR service has been actively discussed in the ATM Forum. Unfortunately, the study on flow control mechanism for multicast ABR is not sufficient. This paper discusses a suitable flow control mechanism for multicast ABR and shows its performance. At first, it summarizes the approaches for the flow control and describes the outline of the proposed mechanism based on the suitable approach. Next it evaluates the performance and shows the effectiveness of the mechanism by simulations. Moreover, after pointing out the importance of operations in the case of link failures on the multicast tree, it discusses the cooperation in this case between the flow control and the related functions to detect these failures.
index324!@#@!2002!@#@!Is the Die Cast for the Token Game?!@#@!Proceedings of the 23rd International Conference on Applications and Theory of Petri Nets!@#@!null
index325!@#@!2002!@#@!Concurrency of Line Segments in Uncertain Geometry!@#@!Proceedings of the 10th International Conference on Discrete Geometry for Computer Imagery!@#@!null
index326!@#@!1998!@#@!An Enhanced Authentication Protocol for Personal Communication Systems!@#@!Proceedings of the 1998 IEEE Workshop on Application - Specific Software Engineering and Technology!@#@!null
index327!@#@!2002!@#@!Cytological Breast Fine Needle Aspirate Images Analysis with a Genetic Fuzzy Finite State Machine!@#@!CBMS!@#@!A system based on fuzzy finite State Machine (SM) has been developed for evaluatingcytological features derived directly from a digital scan of breast fine needle aspirate (NA)slides.The system uses computer vision techniques to analyse cell nuclei in order to extractdeterminate features and try to find by Genetic Algorithms (GA) the ideal SM able toclassify them.This application to breast cancer diagnosis uses characteristics of individualcells to discriminate benign from malignant breast lumps.In our system we try to find a texturemeasurement that can be included in the feature set to improve the classifier performance: acomplexity measurement of the structural pattern is used to discriminate between benign andmalign cells. With this measure and the technique described below we have observed that not only the absolute complexity of the image is relevant, but also the way in which the complexity is distributed at different scales .
index328!@#@!2002!@#@!Fault Attacks on RSA with CRT: Concrete Results and Practical Countermeasures!@#@!Revised Papers from the 4th International Workshop on Cryptographic Hardware and Embedded Systems!@#@!null
index329!@#@!2000!@#@!Organizational Challenges to the Development of Electronic Government!@#@!Proceedings of the 11th International Workshop on Database and Expert Systems Applications!@#@!This paper discusses major organizational challenges faced by initiatives to implement e-government. Firstly, guiding principles and problems of restructuring administrative functions and processes are pointed out. Secondly, requirements of and barriers to coordination and cooperation within public administration are discussed with a view on specific national strategies. As a third challenge the need to organize monitoring of performance in terms of e-government is examined.
index330!@#@!1989!@#@!System Simulation and the Sensitivity of Self-Stabilization!@#@!Proceedings on Mathematical Foundations of Computer Science 1989!@#@!null
index331!@#@!2003!@#@!Paranoid penguin: using firewall builder, Part I!@#@!Linux Journal!@#@!null
index332!@#@!2003!@#@!Visualization of program-execution data for deployed software!@#@!Software Visualization!@#@!Software products are often released with missing functionality, errors, or incompatibilities that may result in failures in the field, inferior performances, or, more generally, user dissatisfaction. In previous work, we presented the GAMMA technology, which facilitates remote analysis and measurement of deployed software and allows for gathering programexecution data from the field. When monitoring a high number of deployed instances of a software product, however, a large amount of data is collected. Such raw data are useless in the absence of a suitable data-mining and visualization technique that supports exploration and understanding of the data. In this paper, we present a new technique for collecting, storing, and visualizing program-execution data gathered from deployed instances of a software product. We also present a prototype toolset, GAMMATELLA, that implements the technique. We show how the visualization capabilities of GAMMATELLA allows for effectively investigating several kinds of execution-related information in an interactive fashion.
index333!@#@!1994!@#@!On Projective and Separable Properties!@#@!Proceedings of the 19th International Colloquium on Trees in Algebra and Programming!@#@!null
index334!@#@!2002!@#@!Modified PrefixSpan Method for Motif Discovery in Sequence Databases!@#@!Proceedings of the 7th Pacific Rim International Conference on Artificial Intelligence: Trends in Artificial Intelligence!@#@!null
index335!@#@!2001!@#@!Flexible Control of Parallelism in a Multiprocessor PC Router!@#@!Proceedings of the General Track: 2002 USENIX Annual Technical Conference!@#@!null
index336!@#@!2000!@#@!Virtual View Face Image Synthesis Using 3D Spring-Based Face Model from a Single Image!@#@!Proceedings of the Fourth IEEE International Conference on Automatic Face and Gesture Recognition 2000!@#@!It is known that 2D views of a person can be synthesis if the face 3D model of that person is available. This paper proposes a new method, called 3D Spring-Based Face Model (SBFM), to determine the precise face model of a person with different poses and facial expressions from a single image. The SBFM combines the concepts of generic 3D face model in computer graphics and deformable template in computer vision. Face image databases from MIT AI lab and Yale University are used to test our proposed method and the results are encouraging.
index337!@#@!2003!@#@!On a new family of Hermite polynomials associated to parabolic cylinder functions!@#@!Applied Mathematics and Computation!@#@!We use the integral representation method to establish the link between Hermite polynomials of ordinary nature and a family of recently introduced Hermite polynomials associated with the parabolic cylinder functions.
index338!@#@!2002!@#@!Papers!@#@!ACM SIGIR Forum!@#@!null
index339!@#@!2002!@#@!A genetic-neuro algorithm for tiling problems with rotation and/or reflection of figures!@#@!Iranian Journal of Science and Technology!@#@!This paper describes an algorithm for tiling with polyminoes that consider rotation and/or reflection of figures in the steps of 90°. First, we review the previous parallel algorithms for tiling problems. Next, we propose a hybrid approach that is based on genetic algorithms (GA) and artificial neural networks(ANN). In this approach, the production of new members in GA and their evaluation are performed by a Hopfield neural network. Finally we compare our method with the previous works, and show that our method can produce global minima for many problems. The algorithm can be used for solving a variety of 2D-packing problems.
index340!@#@!1996!@#@!Simplicial Sets and Triangular Patches!@#@!Computer Graphics International!@#@!This work fits into the domain of topology-based geometric modeling. An assembling of non-overlapping patches can be interpreted as a subdivision of a geometric object into cells of different dimensions and a combinatorial structure can be associated with it. More precisely, our study deals with the manipulation of simplicial sets imbedded on triangular patches. We give the definition and properties of simplicial sets and triangular Bezier spaces and discuss the relationship between these two entities. The advantages of this approach are developped and some construction operations for the manipulation of this structure are presented.
index341!@#@!1997!@#@!Face Detection With Information-Based Maximum Discrimination!@#@!CVPR!@#@!Antonio J. Colmenarez and Thomas S. Huang In this paper we present a visual learning technique that maximizes the discrimination between positive and negative examples in a training set. We demonstrate our technique in the context of face detection with complex background without color or motion information, which has proven to be a challenging problem. We use a family of discrete Markov processes to model the face and background patterns and estimate the probability models using the data statistics. Then, we convert the learning process into an optimization, selecting the Markov process that optimizes the information-based discrimination between the two classes. The detection process is carried out by computing the likelihood ratio using the probability model obtained from the learning procedure. We show that because of the discrete nature of these models, the detection process is, by almost two orders of magnitude, less computationally expensive than neural network approaches. However, no improvement in terms of correct-answer/false-alarm tradeoff is achieved.
index342!@#@!1997!@#@!The project "Patient en Dossier"!@#@!CBMS!@#@!The project "Patient en Dossier" is subsidized by the IWT through the Actionprogramme Informationtechnology for Telenet Vlaanderen. The project examines the influence of the "Law for the Protection of the Personal Privacy"/sup 2/ on the electronic medical record (EMR) and the increase of the involvement of the patient in his own health care process. The project started on 1.1.96 and will run for three years.
index343!@#@!1999!@#@!Assessment of COTS Microkernels by Fault Injection!@#@!Proceedings of the conference on Dependable Computing for Critical Applications!@#@!This paper addresses the problem of using COTS microkernels in safety critical systems. As the behavior in the presence of faults of such basic components is seldom established, it is questionable whether they can be used to develop operating systems for critical applications. The approach proposed for the assessment of a COTS microkernel relies on fault injection as a means to obtain objective insights for the provision of upper layer services. A specific tool (MAFALDA) has been developed to implement this approach. We present and discuss the results obtained when applying the tool to the Chorus ClassiX r3 microkernel. Finally, some lessons learnt from these experiments and plans for future work are described.
index344!@#@!2002!@#@!Neurocomputing based Canadian weather analysis!@#@!Second international workshop on Intelligent systems design and application!@#@!This paper investigates the development of a reliable and efficient neuro-computing technique to forecast the peak weather in Vancouver, British Columbia, Canada. For developing the models, we used one year's data comprising of daily maximum temperature, wind-speed and visibility. This paper briefly explains how neural network models could be formulated using different learning methods and then investigates whether they can provide the required level of performance, which are sufficiently good and robust to provide a reliable model for practical peak weather forecasting. Experiment results demonstrate that neuro-forecast models show a very good prediction performance and the approach is effective and reliable.
index345!@#@!2003!@#@!Determination of the bases of a splitting matroid!@#@!European Journal of Combinatorics!@#@!In Discrete Math. 184 (1998) 267, the authors extended the splitting operation of graphs to binary matroids. In this paper, we characterize the set of bases of a splitting matroid and give some of its applications.
index346!@#@!1995!@#@!KBED: A Knowledge-Based Edge Detection System!@#@!Proceedings of the 6th International Conference on Database and Expert Systems Applications!@#@!null
index347!@#@!2003!@#@!From simulink to SCADE/lustre to TTA: a layered approach for distributed embedded applications!@#@!ACM SIGPLAN Notices!@#@!We present a layered end-to-end approach for the design and implementation of embedded software on a distributed platform. The approach comprises a high-level modeling and simulation layer (Simulink), a middle-level programming and validation layer (SCADE/Lustre) and a low-level execution layer (TTA). We provide algorithms and tools to pass from one layer to the next. First, a translator from Simulink to Lustre. Second, a set of real-time and code-distribution extensions to Lustre. Third, implementation techniques for decomposing a Lustre program into tasks and messages, scheduling the tasks and messages on the processors and the bus, distributing the Lustre code on the execution platform, and generating the necessary "glue" code.
index348!@#@!2003!@#@!Positive experiences with an open project assignment in an introductory programming course!@#@!International Conference on Software Engineering!@#@!The course SIF8005 Object-Oriented Programming at the NTNU is in many respects taught in a quite traditional manner, with a well-known textbook, lectures in huge auditoria, and compulsory exercises that the students have to deliver to be allowed to sit a final written exam. The exercise part of the course is a mixture of individual exercises on a weekly basis, and a somewhat larger project to be done by groups of 4 students.This paper particularly discusses the project, which has become a huge success after some notable changes were made for the 2001 offering of the course. Then the assignment profile was changed from one of fixed requirements set by staff to an open assignment, where each group made a computer game according to their own preferences. This change eliminated many of the problems present in earlier offerings and increased student inspiration.
index349!@#@!1999!@#@!Manipulating Software Semantics with Unified Computational Model and Software Quark Model!@#@!Proceedings of the Sixth Asia Pacific Software Engineering Conference!@#@!Manipulating semantic information is a challenging issue in software engineering. In this paper, we propose one possible way to handle semantic information of software in a mechanical way. The paper discusses our idea of a Unified Computational Model and a Software Quark Model, which serve as the foundation to attack the issue. In the Unified Computational Model, we have tried to define static semantics of all programming language constructs into Generalized Message Passing. That is to say, Generalized Message Passing is used to present perspective semantics of software. On the other hand, the Software Quark Model provides a sorted set of semantic primitives. It, in turn, is used to represent conceptual semantic information of software. We also present the possible framework for working with the Unified Computational Model and the Software Quark Model to tackle this challenging issue.
index350!@#@!1998!@#@!Elimination of Equality via Transformation with Ordering Constraints!@#@!Proceedings of the 15th International Conference on Automated Deduction: Automated Deduction!@#@!null
index351!@#@!2002!@#@!Encoding linear logic with interaction combinators!@#@!Information and Computation!@#@!The purpose of this paper is to demonstrate how Lafont's interaction combinators, a system of three symbols and six interaction rules, can be used to encode linear logic. Specifically, we give a translation of the multiplicative, exponential, and additive fragments of linear logic together with a strategy for cut-elimination which can be faithfully simulated. Finally, we show briefly how this encoding can be used for evaluating λ-terms. In addition to offering a very simple, perhaps the simplest, system of rewriting for linear logic and the λ-calculus, the interaction net implementation that we present has been shown by experimental testing to offer a good level of sharing in terms of the number of cut-elimination steps (resp. β-reduction steps). In particular it performs better than all extant finite systems of interaction nets.
index352!@#@!1996!@#@!Testing Speech Act Theory and Its Applicability to EDI and Other Computer-Processable Messages!@#@!Proceedings of the 29th Hawaii International Conference on System Sciences Volume 2: Decision Support and Knowledge-Based Systems!@#@!This paper discusses a small empirical study that investigates the relationship between electronic commerce and a linguistic theory called speech act theory (SAT). The study reveals that electronic data interchange messages and inter-application communication messages have the structure predicted by SAT. This should encourage information systems (IS) researchers to continue investigating SAT, IS practitioners to consider basing message structures on a SAT framework, and speech act theorists who support this theory.
index353!@#@!1996!@#@!Competitive Co-evolution Model on the Acquisition of Game Strategy!@#@!Selected papers from the First Asia-Pacific Conference on Simulated Evolution and Learning!@#@!null
index354!@#@!1995!@#@!Local Fourir Phase and Disparity Estimates: An Analytical Study!@#@!Proceedings of the 6th International Conference on Computer Analysis of Images and Patterns!@#@!null
index355!@#@!2002!@#@!A Framework to Translate UML Class Generalization into Java Code!@#@!Proceedings of the 8th International Conference on Object-Oriented. Information Systems!@#@!null
index356!@#@!1998!@#@!Evaluation of the Strength of Computer Aided Method Engineering for Product Development Process Modeling!@#@!Proceedings of the 9th International Conference on Database and Expert Systems Applications!@#@!null
index357!@#@!1996!@#@!Complementing semi-formal specifications with Z!@#@!Proceedings of The 11th Knowledge-Based Software Engineering Conference!@#@!The insertion of formal techniques into the daily practice of software engineering definitely improves the quality of specifications. An approach is proposed where semi-formal specifications are translated into the formal specification language Z and enriched by formal annotations. The paper starts from a specification of an access control system in terms of classical description techniques: entity-relationship schemas, data-flow diagrams, and state machine descriptions. It shows how these descriptions can be combined with formal definitions of types, constraints and functions.
index358!@#@!2002!@#@!Fair electronic cash based on double signatures!@#@!Journal of Computer Science and Technology!@#@!In order to decrease crimes such as money laundering, blackmailing etc. in electronic cash systems, fair electronic cash has been a major focus of academic research in electronic commence. When a bank finds some dubious cash or owner, the trusted entity or trustee can help him to revoke the anonymity of the cash. In the previous protocols, the trustee knows all the information of the cash whether he is trusted or not, that is, he can trace the user or cash unconditionally. Furthermore, the dishonest trustee may deceive a user, which means that he may withdraw cash while tracing other users. Such cases are unfair to the honest users.A new fair electronic cash protocol based on untrustworthy trustees is proposed in this paper. The key idea is that the coin structure should include the signatures of both the trustee and the bank so that the trustee shares the information of the cash with the bank, while we do not use the secret sharing scheme. In contrast with the previous protocols, neither the trustee nor the bank can trace the money without the help of the other entity. In this way, the privacy of the user is protected furthest. Also, the trustee is off-line in the protocol, which means that he will not be involved in withdrawing the cash. Therefore, the protocol is efficient for implementation.
index359!@#@!2002!@#@!Enhancement of Binding Update for Mobile IP!@#@!Proceedings of the 27th Annual IEEE Conference on Local Computer Networks!@#@!null
index360!@#@!1996!@#@!Closed Form Performance Distributions of a Discrete Time GIg/D/1/N Queue with Correlated Traffic!@#@!Proceedings of the Sixth IFIP WG6.3 Conference on Performance of Computer Networks: Data Communications and their Performance!@#@!null
index361!@#@!2000!@#@!Distributed Java Bytecode Genetic Programming with Telecom Applications!@#@!Proceedings of the European Conference on Genetic Programming!@#@!null
index362!@#@!2001!@#@!Editor's note: oh Donna, where art thou?!@#@!DB2 magazine!@#@!null
index363!@#@!2001!@#@!Estimating the Scalability of the Internet Key Exchange!@#@!Proceedings of the Third International Conference on Information and Communications Security!@#@!null
index364!@#@!2001!@#@!Feature Selection for Classification Using Genetic Algorithms with a Novel Encoding!@#@!Proceedings of the 9th International Conference on Computer Analysis of Images and Patterns!@#@!null
index365!@#@!2002!@#@!A Framework for Domain and Task Adaptive Named-Entity Recognition!@#@!Proceedings of the Baltic Conference, BalticDB&amp;IS 2002 - Volume 1!@#@!null
index366!@#@!2003!@#@!On the approximation of Feynman-Kac path integrals!@#@!Journal of Computational Physics!@#@!A general framework is proposed for the numerical approximation of Feynman-Kac path integrals in the context of quantum statistical mechanics. Each infinite-dimensional path integral is approximated by a Riemann integral over a finite-dimensional Sobolev space by restricting the integrand to a subspace of all admissible paths. Through this process, a wide class of methods is derived, with each method corresponding to a different choice for the approximating subspace. It is shown that the traditional "short-time" approximation and "Fourier discretization" Can be recovered by using linear and spectral basis functions, respectively. As an illustration of the flexibility afforded by the subspace approach, a novel method is formulated using cubic elements and is shown to have improved convergence properties when applied to model problems.
index367!@#@!1999!@#@!Fairness in Routing and Load Balancing!@#@!Proceedings of the 40th Annual Symposium on Foundations of Computer Science!@#@!We consider the issue of network routing subject to explicit fairness conditions. The optimization of fairness criteria interacts in a complex fashion with the optimization of network utilization and throughput; in this work, we undertake an investigation of this relationship through the framework of approximation algorithms.In a range of settings including both high-speed networks and Internet applications, max-min fairness has emerged as a widely accepted formulation of the notion of fairness. Informally, we say that an allocation of bandwidth is max-min fair if there is no way to give more bandwidth to any connection without decreasing the allocation to a connection of lesser or equal bandwidth. Given a collection of transmission routes, this criterion imposes a certain equilibrium condition on the bandwidth allocation, and some simple flow control mechanisms converge quickly to this equilibrium state. Indeed, the vast majority of previous work on max-min fairness has focused on this issue of associating rates with connections that are specified by a fixed set of paths. Very little work has been devoted to understanding the relationship between the way in which one selects paths for routing, and the amount of throughput one obtains from the resulting max-min fair allocation on these paths.In this work we consider the problem of selecting paths for routing so as to provide a bandwidth allocation that is as fair as possible (in the max-min sense). We obtain the first approximation algorithms for this basic optimization problem, for single-source unsplittable routings in an arbitrary directed graph. Special cases of our model include several fundamental load balancing problems, endowing them with a natural fairness criterion to which our approach can be applied. Our results form an interesting counterpart to earlier work of Megiddo, who considered max-min fairness for single-source fractional flow. The optimization problems in our setting become NP-complete, and require the development of new techniques for relating fractional relaxations of routing to the equilibrium constraints imposed by the fairness criterion.
index368!@#@!1993!@#@!Performance Specification and Measurement!@#@!Proceedings of the 11th IFIP WG10.2 International Conference sponsored by IFIP WG10.2 and in cooperation with IEEE COMPSOC on Computer Hardware Description Languages and their Applications!@#@!null
index369!@#@!1999!@#@!Flexible software agents for the automatic provision of PVCs in ATM networks (short paper)!@#@!Proceedings of the IFIP WG 6.1 International Working Conference on Distributed Applications and Interoperable Systems II!@#@!null
index370!@#@!2003!@#@!Persistence of lower dimensional invariant tori for nearly integrable Hamiltonian systems!@#@!Nonlinear Analysis: Theory, Methods &amp; Applications!@#@!null
index371!@#@!1998!@#@!Averting Expected Challenges Through Anticipatory Impression Management: a Study of Hospital Billing!@#@!Organization Science!@#@!Existing theory and research on organizational impression management focuses on how spokespersons use remedial tactics, following image-threatening events, to put their organization in the best possible light. By contrast, little theory or research has considered how organizations use impression management tactics to avert undesirable responses to upcoming events. This paper uses a qualitative and inductive study of billing procedures at three large hospitals to develop theory about how organization members use impression management tactics to fend off specific, expected challenges to organizational practices that are ambiguously negative. We found that hospitals use anticipatory impressio n management tactics to: (1) distract, diminish, or overwhelm patients' attention to hospital charges; and (2) to induce emotions that lead patients to simplify their information processing of those charges. Hospitals appear to use such anticipatory obfuscations both to fend off patients' initial challenges and to prevent their existing challenges from escalating. We discuss these findings in terms of their contributions to theories of symbolic management, social influence, and routine service encounters.
index372!@#@!1994!@#@!Multilevel Graph Grammars!@#@!Proceedings of the 20th International Workshop on Graph-Theoretic Concepts in Computer Science!@#@!null
index373!@#@!2002!@#@!Deductive Search for Errors in Free Data Type Specifications Using Model Generation!@#@!Proceedings of the 18th International Conference on Automated Deduction!@#@!null
index374!@#@!1995!@#@!Parallelization of two breadth-first search-based applications using different message-passing paradigms: an experimental evaluation!@#@!FRONTIERS!@#@!We present experimental results for parallelizing two breadth-first search-based applications on the CM-5 by using two different message-passing paradigms, one based on send/receive and the other based on active messages. The parallelization of these applications requires fine-grained communication. Our results show that the active messages-based implementation gives significant improvement over the send/receive-based implementation. The improvements can primarily be attributed to the lower latency of the active messages implementation.
index375!@#@!2001!@#@!Web-based asynchronous support for collaborative learning!@#@!Journal of Computing Sciences in Colleges!@#@!This paper investigates the construction of a WWW-enabled course support environment for learner-centered education. The system is designed to encourage students' responsibility, to make learning meaningful, and to support active knowledge construction in the specific curriculums of their study. This system, currently named REAL, carries the connotation of a Rich Environment for Active Learning, whose pedagogy comes from the constructivist's theory of learning. REAL facilitates the interaction among students and teachers by two notions. The first is maintaining a course-specific Web-site for students to look up course-related information. The second is providing a collaborative Web-based service with which students could initiate query requests through using specific inquiry Web-page, which acts as an interactive medium for teachers and students to exchange ideas, record actions, use e-mails, and upload/download files. Each interaction is captured asynchronously and maintained in a searchable archive for other students' reference. The REAL system, developed through the use of iterative prototyping, provides feedback for perceived learning. The paper also discusses lessons learned for teachers developing REAL, in the reflection of instructional methods, as well as some future development of the environment.
index376!@#@!1995!@#@!Tempest: a substrate for portable parallel programs!@#@!Proceedings of the 40th IEEE Computer Society International Conference!@#@!The paper describes Tempest, a collection of mechanisms for communication and synchronization in parallel programs. With these mechanisms, authors of compilers, libraries, and application programs can exploit-across a wide range of hardware platforms-the best of shared memory, message passing, and hybrid combinations of the two. Because Tempest provides mechanisms, not policies, programmers can tailor communication to a program's sharing pattern and semantics, rather than restructuring the program to run with the limited communication options offered by existing parallel machines. And since the mechanisms are easily supported on different machines. Tempest provides a portable interface across platforms. The paper describes the Tempest mechanisms, briefly explains how they are used, outlines several implementations on both custom and stock hardware, and presents preliminary performance results that demonstrate the benefits of this approach.
index377!@#@!2000!@#@!Analyzing the Test Generation Problem for an Application-Oriented Test of FPGAs!@#@!Proceedings of the IEEE European Test Workshop!@#@!The objective of this paper is to generate an Application-Oriented Test Procedure to be used by a FPGA user in a given application. General definitions concerning the specific problem of testing RAM-based FPGAs are first given such as the important concept of 'AC-non-redundant fault'. Using a set of circuits implemented on a XILINX 4000E, it is shown that a classical test pattern generation performed on the circuit netlist gives a low AC-non-redundant fault coverage and it is pointed out that test pattern generation performed on a FPGA representation is required. It is then demonstrated that removing most of the AC-redundant faults can significantly accelerate test pattern generation performed on the FPGA representation. Finally, a technique is proposed to even more accelerate the test pattern generation process by using a reduced FPGA description.
index378!@#@!1997!@#@!Hidden Annotation in Content Based Image Retrieval!@#@!Proceedings of the 1997 Workshop on Content-Based Access of Image and Video Libraries (CBAIVL '97)!@#@!The Bayesian relevance-feedback approach introduced with the PicHunter system is extended to include hidden semantic attributes. The general approach is motivated and experimental results are presented that demonstrate significant reductions in search times (28-32%) using these annotations.
index379!@#@!2002!@#@!Ontology development as undergraduate research!@#@!Journal of Computing Sciences in Colleges!@#@!Ontology development is a rich area of endeavor for undergraduate research. This paper briefly traces the evolution of ontology development in artificial intelligence (AI), gives some examples of successful applications by AI researchers, and presents arguments as to why ontology development is well suited for undergraduate research.
index380!@#@!1999!@#@!Generalized Cases: Representation and Steps Towards Efficient Similarity Assessment!@#@!Proceedings of the 23rd Annual German Conference on Artificial Intelligence: Advances in Artificial Intelligence!@#@!null
index381!@#@!1996!@#@!Active Information Delivery in a CORBA-based Distributed Information System!@#@!Proceedings of the First IFCIS International Conference on Cooperative Information Systems!@#@!Many application areas require the integration of heterogeneous information sources into a coherent distributed information system. With such systems, users frequently need not only be able to access information, but they also have to be notified automatically when new information that is relevant to their work becomes available. For example, in our environmental systems project, a civil servant needs to be informed when a measured air quality parameter exceeds a certain threshhold. Detection of such a critical situation requires subsequent monitoring of several data sources (e.g., a database recording measurement values and a database with limit values). This paper presents an approach for such situation monitoring which is based on CORBA, for the technical integration of heterogeneous systems and on active DBMS-style ECA-rules. In particular, it discusses how ECA-rules can be adopted in a CORBA environment, and describes a CORBA-based system for situation monitoring. The major implementation issues addressed are event detection within autonomous component systems and detection of complex distributed situations.
index382!@#@!1981!@#@!A View of Directions in Relational Database Theory!@#@!Proceedings of the 8th Colloquium on Automata, Languages and Programming!@#@!null
index383!@#@!2003!@#@!Preface!@#@!RF and microwave semiconductor device handbook!@#@!null
index384!@#@!1997!@#@!Autonomous Animated Interactive Characters: Do We Need Them?!@#@!Computer Graphics International!@#@!The author addresses the role of autonomy in interactive animated characters. He argues that even a small amount of autonomy can lift what is already a great interactive character into a new dimension. He shows how different levels of autonomy may be appropriate for different types of characters. He then argues that autonomy, intentionality, variability and adaptation are all critical components in creating the illusion of life in interactive characters. He reviews current work in the field and proposes a number of practical applications for autonomous characters in both interactive and non-interactive animation.
index385!@#@!2002!@#@!How Should Team Captains Order Golfers on the Final Day of the Ryder Cup Matches?!@#@!Interfaces!@#@!I used game theory to examine how team captains should select their slates for the final day of the Ryder Cup matches. Under the assumption that golfers have different abilities and are not influenced by pressure or momentum, I found that drawing names from a hat will do no worse than any other strategy.
index386!@#@!2002!@#@!Managing Dependencies in Component-Based Distributed Applications!@#@!Revised Papers from the International Workshop on Scientific Engineering for Distributed Java Applications!@#@!null
index387!@#@!1997!@#@!High-Level Synthesis of Analog Sensor Interface Front-Ends!@#@!Proceedings of the 1997 European conference on Design and Test!@#@!In this paper we compare three different methodologies for analog high-level synthesis. Two optimization-based methods-one with simulations in the loop, the other with equations-and a library-based approach are discussed and illustrated with experimental results. The comparison is made by means of a real life design example-a radiation detector interface ASIC-although the methodologies presented in this paper, are generally applicable.
index388!@#@!2002!@#@!Computational geometry!@#@!Computer graphics companion!@#@!null
index389!@#@!2002!@#@!DB2 DBA: page turners!@#@!DB2 magazine!@#@!null
index390!@#@!2003!@#@!Automorphism group computation and isomorphism testing in finite groups!@#@!Journal of Symbolic Computation!@#@!A new method for computing the automorphism group of a finite permutation group and for testing two such groups for isomorphism is described. Some performance statistics are included for an implementation of these algorithms in the Magma language.
index391!@#@!1998!@#@!A New Fully Polynomial Approximation Scheme for the Knapsack Problem!@#@!Proceedings of the International Workshop on Approximation Algorithms for Combinatorial Optimization!@#@!null
index392!@#@!1998!@#@!Ein hierarchischer neuronaler Klassifikator f&uuml;r die Erkennung von Einzelzeichen in mathematischen Formeltexten!@#@!Mustererkennung 1998, 20. DAGM-Symposium!@#@!null
index393!@#@!1986!@#@!Lernendes Verfahren zur Segmentierung industrieller Szenen!@#@!Mustererkennung 1986, 8. DAGM-Symposium!@#@!null
index394!@#@!1998!@#@!Testing Monotonicity!@#@!Proceedings of the 39th Annual Symposium on Foundations of Computer Science!@#@!We present a (randomized) test for monotonicity of Boolean functions. Namely, given the ability to query an unknown function f : {0,1}^n -> {0,1} at arguments of its choice, the test always accepts a monotone f, and rejects f with high probability if it is epsilon-far from being monotone (i.e., every monotone function differs from f on more than an epsilon fraction of the domain). The complexity of the test is poly(n/epsilon).The analysis of our algorithm relates two natural combinatorial quantities that can be measured with respect to a Boolean function; one being global to the function and the other being local to it.We also consider the problem of testing monotonicity based only on random examples labeled by the function. We show an Omega(\sqrt{2^n/epsilon}) lower bound on the number of required examples, and provide a matching upper bound (via an algorithm).
index395!@#@!1989!@#@!Index Selection in Relational Databases!@#@!Proceedings of the 2nd Symposium on Mathematical Fundamentals of Database Systems!@#@!null
index396!@#@!1991!@#@!Multispektralklassifikation von Fernerkundungsdaten mittels Neuronaler Netze!@#@!Mustererkennung 1991, 13. DAGM-Symposium!@#@!null
index397!@#@!2002!@#@!Contextual Matching of Software Library Components!@#@!Proceedings of the Ninth Asia-Pacific Software Engineering Conference!@#@!Many automated programming environments constructsoftware by integrating predefined components from a softwarelibrary. A fundamental challenge in this process is tomatch the programmer's specified requirements against thestated capabilities of the components. We explain how thechances of successfully achieving a match can be increasedby taking the program context surrounding each requirementinto consideration. Formal rules, based on programrefinement theory, are defined for context-based matching.The rules allow properties that can be proven to hold ata particular point in the program to justify matching withcomponents that operate correctly only in such a context.
index398!@#@!2003!@#@!End-user software engineering with assertions in the spreadsheet paradigm!@#@!International Conference on Software Engineering!@#@!There has been little research on end-user program development beyond the activity of programming. Devising ways to address additional activities related to end-user program development may be critical, however, because research shows that a large proportion of the programs written by end users contain faults. Toward this end, we have been working on ways to provide formal "software engineering" methodologies to end-user programmers. This paper describes an approach we have developed for supporting assertions in end-user software, focusing on the spreadsheet paradigm. We also report the results of a controlled experiment, with 59 end-user subjects, to investigate the usefulness of this approach. Our results show that the end users were able to use the assertions to reason about their spreadsheets, and that doing so was tied to both greater correctness and greater efficiency.
index399!@#@!2003!@#@!Video similarity detection for digital rights management!@#@!Proceedings of the 26th Australasian computer science conference - Volume 16!@#@!Vast quantities of video data are distributed around the world every day. Video content owners would like to be able to automatically detect any use of their material, in any media or representation. We investigate techniques for identifying similar video content in large collections. Current methods are based on related technology, such as image retrieval, but the effectiveness of these techniques has not been demonstrated for the task of locating video clips that are derived from the same original. We propose a new method for locating video clips, shot-length detection, and compare it to methods based on image retrieval. We test the methods in a variety of contexts and show that they have different strengths and weaknesses. Our results show that the shot-based approach is promising, but is not yet sufficiently robust for practical application.
index400!@#@!2003!@#@!User-oriented evaluation methods for information retrieval: a case study based on conceptual models for query expansion!@#@!Exploring artificial intelligence in the new millennium!@#@!This chapter discusses evaluation methods based on the use of nondichotomous relevance judgments in information retrieval (IR) experiments. It is argued that evaluation methods should credit IR methods for their ability to retrieve highly relevant documents. This is desirable from the user's point of view in modern large IR environments. The proposed methods are (1) a novel application of P-R curves and average precision computations based on separate recall bases for documents of different degrees of relevance, and (2) two novel measures computing the cumulative gain the user obtains by examining the retrieval result up to a given ranked position. We then demonstrate the use of these evaluation methods in a case study on the effectiveness of query types, based on combinations of query structures and expansion, in retrieving documents of various degrees of relevance. Query expansion is based on concepts, which are selected from a conceptual model, and then expanded by semantic relationships given in the model. The test is run with a best-match retrieval system (InQuery) in a text database consisting of newspaper articles. The case study indicates the usability of domain-dependent conceptual models in query expansion for IR. The results show that expanded queries with a strong query structure are most effective in retrieving highly relevant documents. The differences between the query types are practically essential and statistically significant. More generally, the novel evaluation methods and the case demonstrate that nondichotomous relevance assessments are applicable in IR experiments and allow harder testing of IR methods. Proposed methods are user-oriented because users' benefits and efforts--highly relevant documents and number of documents to be examined-- are taken into account.
index401!@#@!1996!@#@!Erkennung von Kraftfahrzeugen in M&uuml;llbunkern!@#@!Mustererkennung 1996, 18. DAGM-Symposium!@#@!null
index402!@#@!2003!@#@!An axiomatic semantics for the synchronous language Gentzen!@#@!Journal of Computer and System Sciences!@#@!We propose an axiomatic semantics for the synchronous language Gentzen, which is an instantiation of the paradigm Timed Concurrent Constraint Programming proposed by Saraswat, Jagadeesan and Gupta. We view Gentzen as a prototype of the class of state-oriented synchronous languages, since it offers the basic constructs that are shared by the languages in the class. Since synchronous concurrency cannot be simulated by arbitrary interleaving, we cannot exploit "head normal forms", on which axiomatic theories for asynchronous process calculi are based. We suggest how axiomatic semantics for other state-oriented synchronous languages can be obtained by expressing constructs of such languages in terms of Gentzen constructs.
index403!@#@!1998!@#@!On Counting Logics and Local Properties!@#@!Proceedings of the 13th Annual IEEE Symposium on Logic in Computer Science!@#@!null
index404!@#@!2002!@#@!Interference among Multiple TCP Flows over Congested ATM Links!@#@!Proceedings of the 27th Annual IEEE Conference on Local Computer Networks!@#@!In this paper we describe the throughput performance ofLinux TCP over multiple UBR flows in the presence ofhigh priority traffic class like CBR. We then proposed amodified congestion control algorithm for TCP toimprove its throughput over ATM networks in particular.The experimental results are provided to claim that ourproposed algorithm is dynamically sensitive to thecongestion in the network and adjusts the sender ratemore accurately. At the same time the fairness andsynchronization is achieved thoroughly better betweencontending TCP flows.
index405!@#@!1993!@#@!Simulation Techniques for Proving Properties of Real-Time Systems!@#@!A Decade of Concurrency, Reflections and Perspectives, REX School/Symposium!@#@!The method of simulations is an important technique for reasoning about real-time and other timing-based systems. It is adapted form an analogous method for untimed systems . This paper presents the simulation method in the context of a very general automation (i.e., labeled transition system) model for timing-based systems. Sketches are presented of several typical examples for which the method has been used successfully. Other complimentary tools are also described, in particular, invariants for safety proofs, progress functions for timing proofs,a and execution correspondences for liveness proofs. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player
index406!@#@!1983!@#@!Acyclic Database Schemes (of Various Degrees): A Painless Introduction!@#@!Proceedings of the 8th Colloquium on Trees in Algebra and Programming!@#@!null
index407!@#@!2002!@#@!A Recommendation System for Software Function Discovery!@#@!Proceedings of the Ninth Asia-Pacific Software Engineering Conference!@#@!Since many of today's application software provideusers with too many functions, the users sometimes cannotfind the useful functions. This paper proposes arecommendation system based on a collaborative filteringapproach to let users discover useful functions at low costfor the purpose of improving the user's productivity inusing application software. The proposed systemautomatically collects histories of software functionexecution (usage histories) from many users through theInternet. Based on the collaborative filtering approach,collected histories are used to recommend the user a setof candidate functions that may be useful to the individualuser. This paper illustrates conventional filteringalgorithms and proposes a new algorithm suitable forrecommendation of software functions. The result of anexperiment with a prototype recommendation systemshowed that the average ndpm of our algorithm wassmaller than that of the conventional algorithms; and, italso showed that the standard deviation of ndpm of ouralgorithm was smaller than that of the conventionalalgorithms. Furthermore, while every conventionalalgorithm had a case whose recommendation was worsethan the random algorithm, our algorithm did not.
index408!@#@!1997!@#@!True Multi-Image Alignment and its Application to Mosaicing and Lens Distortion Correction!@#@!CVPR!@#@!Multiple images of a scene are related through 2D/3D view transformations and linear and non-linear camera transformations. In all the traditional techniques to compute these transformations, especially the ones relying on direct intensity gradients, one image and its coordinate system have been assumed to be ideal and distortion free. In this paper, we present a formulation and an algorithm for true multi-image alignment that does not rely on the measurements of a reference image being distortion free. For instance, in the presence of lens distortion, none of the images can be assumed to be ideal. In our formulation, all the images are modeled as intensity measurements represented in their respective coordinate systems, each of which is related to an ideal coordinate system through an interior camera transformation and an exterior view transformation. The goal of the accompanying algorithm is to compute an image in the ideal coordinate system while solving for the transformCations that relate the ideal system with each of the data images.Key advantages of the technique presented in this paper are: (i) no reliance on one distortion free image, (ii) ability to register images and compute coordinate transformations even when the multiple images are of an extended scene with no overlap between the first and last frame of the sequence, and (iii) ability to handle linear and non-linear transformations within the same framework.The new algorithm is evaluated in the context of two applications: (i) correction of lens distortion, and (ii) cre- ation of video mosaics.
index409!@#@!1998!@#@!Source Model for VBR Coded Video Traffic in ATM Networks!@#@!Proceedings of the 23rd Annual IEEE Conference on Local Computer Networks!@#@!null
index410!@#@!2003!@#@!Minimal Realization of Completely Decidable Linear Differential Equations!@#@!Automation and Remote Control!@#@!For a linear system S in total differentials (Pfaff system), proposed was a procedure of constructing its minimal realization S0, that is, the Pfaff vector equation such that its phase space has the least dimensionality if the set of its output functions coincides with the family of the outputs of S.
index411!@#@!2003!@#@!Searching for revolution in structural computing!@#@!Journal of Network and Computer Applications!@#@!The structural computing paradigm has been described as one that holds significant promise and potential for the developers of both applications and infrastructure services. At this stage in its development, however, structural computing can be viewed mainly as an evolutionary progression of research in the hypermedia field rather than as the revolutionary force it was anticipated to be. The field of structural computing is still a new one though. It may still possess revolutionary potential that has so far gone untapped. In order for its revolutionary potential to be realized, however, research is needed that focuses on the fundamental ideas that define and distinguish the structural computing field. Only through an examination and exploration of its essential features can the revolutionary potential of structural computing be assessed.
index412!@#@!1998!@#@!Synthesis of Facial Images with Lip Motion from Several Real Views!@#@!Proceedings of the 3rd. International Conference on Face & Gesture Recognition!@#@!null
index413!@#@!2000!@#@!Localized Boosting!@#@!Proceedings of the Thirteenth Annual Conference on Computational Learning Theory!@#@!null
index414!@#@!2002!@#@!Factoring zero-dimensional ideals of linear partial differential operators!@#@!Proceedings of the 2002 international symposium on Symbolic and algebraic computation!@#@!We present an algorithm for factoring a zero-dimensional left ideal in the ring Q(x, y) [&part;x, &part;y], i.e. factoring a linear homogeneous partial differential system whose coefficients belong to Q(x, y), and whose solution space is finite-dimensional over Q. The algorithm computes all the zero-dimensional left ideals containing the given ideal. It generalizes the Beke-Schlesinger algorithm for factoring linear ordinary differential operators, and uses an algorithm for finding hyperexponential solutions of such ideals.
index415!@#@!2003!@#@!Exploiting self-similarity in geometry for voxel based solid modeling!@#@!Proceedings of the eighth ACM symposium on Solid modeling and applications!@#@!Voxel-based modeling techniques are known for their robustness and flexibility. However, they have three major shortcomings: (1) Memory intensive, since a large number of voxels are needed to represent high-resolution models (2) Computationally expensive, since a large number of voxels need to be visited (3) Computationally expensive isosurface extraction is needed to visualize the results. We describe techniques which alleviate these by taking advantage of self-similarity in the data making voxel-techniques practical and attractive. We describe algorithms for MEMS process emulation, isosurface extraction and visualization which utilize these techniques.
index416!@#@!2000!@#@!The Circuit Object Organization Library!@#@!Proceedings of the 5th Australasian Computer Architecture Conference!@#@!The Circuit Object Organization Library is a C++ class library for developing continuously executing circuit generator programs used in real-time, adaptive reconfigurable computing applications. A C++ program linked with COOL can execute autonomously, since COOL provides a high-speed place and route facility for realizing fine grained FPGA circuits from object-oriented structural descriptions. With COOL the need for separate hardware description and software programming languages disappears. The class inheritance concept is used to define specialized circuits, composed of gate, port, and wire objects. An applications programming interface borrowing from graphical user interface toolkits, automatic storage reclamation, and use of operator overloading make circuit description intuitive and relatively accessible to developers without a strong hardware background. COOL features constructive placement algorithms, and a two-stage router that minimizes average run time, yet handles difficult routes via a last-resort Lee maze router. Preliminary tests reveal that COOL can realize circuits at rates of tens of thousands of gates per second on a low-end PC.
index417!@#@!1995!@#@!Intervals and the deduction of drug binding site models!@#@!Proceedings of the 28th Hawaii International Conference on System Sciences!@#@!In the search for new drugs, it often occurs that the binding affinities of several compounds to a common receptor macromolecule are known experimentally. But the structure of the receptor is not known. We describe an extraordinarily objective computer algorithm for deducing the important geometric and energetic features of the common binding site, starting only from the chemical structures of the ligands and their observed binding. The user does not have to propose a pharmacophore, guess the bioactive conformations of the ligands, or suggest ways to superimpose the active compounds. The method takes into account conformational flexibility of the ligands, stereospecific binding, diverse or unrelated chemical structures, inaccurate or qualitative binding data, and the possibility that chemically similar ligands may or may not bind to the receptor in similar orientations.
index418!@#@!2003!@#@!Optimal binary search trees with costs depending on the access paths!@#@!Theoretical Computer Science!@#@!We describe algorithms for constructing optimal binary search trees, in which the access cost of a key depends on the k preceding keys which were reached in the path to it. This problem has applications to searching on secondary memory and robotics. Two kinds of optimal trees are considered, namely optimal worst case trees and weighted average case trees. The time and space complexities of both algorithms are O(nk+2) and O(nk+1), respectively. The algorithms are based on a convenient decomposition and characterizations of sequences of keys which are paths of special kinds in binary search trees. Finally, using generating functions, we present an exact analysis of the number of steps performed by the algorithms.
index419!@#@!2002!@#@!Maximizing Diversity Among k-NN Classifiers, An Experimental Study!@#@!Proceedings of the International Conference on Parallel and Distributed Processing Techniques and Applications - Volume 3!@#@!null
index420!@#@!2002!@#@!On intuitionistic gradation of openness!@#@!Fuzzy Sets and Systems!@#@!In this paper, we introduce a concept of intuitionistic gradation of openness on fuzzy subsets of a nonempty set X and define an intuitionistic fuzzy topological space. We prove that the category of intuitionistic fuzzy topological spaces and gradation preserving mappings is a topological category. We study compactness of intuitionistic fuzzy topological spaces and prove an analogue of Tychonoff's theorem.
index421!@#@!1998!@#@!On The Danger Of Developing Measures Without Clarifying Concepts!@#@!Proceedings of the Fifth Asia Pacific Software Engineering Conference!@#@!Defining concept before developing theory must be a fundamental requirement of any sciences. In this paper, we show that this requirement, though seemingly trivial, is to a large extent not respected in software measurement research. Many basic software quality concepts are used ambiguously without a clear definition and consequently their measures, though growing in number, have no serious scientific foundation and risk to be misleading in further research. We demonstrate the differences between concept and measure, show the risks to develop measures without clarifying concepts, and underline the paramount importance of concept clarification and definition for the development of software measures.
index422!@#@!1997!@#@!Control Mechanism for Software Pipelining on Nested Loop!@#@!APDC!@#@!ILSP (Interlaced inner and outer Loop Software Pipelining) is an efficient algorithm of optimizing operations in the nested loops. To ensure the ILSP has a good time efficiency and a good space efficiency, there must be an efficient nested control mechanism to support the algorithm. Our control mechanism is realized by hardware, it avoid to add many extra instructions and make the II(Initialization Interval) of each loop in the nested loop least. Cooperate with the compiler, our nested loop control mechanism can efficiently support the software pipelining of the nested loop, and can ensure the ILSP has a high speedup and a low space cost.
index423!@#@!1996!@#@!Motivating the Design for a Computer Assisted Environment for Writers in a Second Language!@#@!Proceedings of the Third International Conference on Computer Aided Learning and Instruction in Science and Engineering!@#@!null
index424!@#@!2002!@#@!Genetic algorithms vs. greedy algorithms in the optimization of course scheduling!@#@!Journal of Computing Sciences in Colleges!@#@!Genetic algorithms are a recent addition to the computing paradigm and with their arrival, comes the idea that they may be able to replace currently used methods. This is an experiment to determine if genetic algorithms can produce a course schedule and if the algorithm compares to a greedy algorithm in response time.
index425!@#@!1990!@#@!Robuste und effiziente Erkennung von 3D Objekten mittels Hypergraph-Homomorphismen!@#@!Mustererkennung 1990, 12. DAGM-Symposium,!@#@!null
index426!@#@!1997!@#@!VLSI Architecture for the Embedded Extraction of Dominant Points on Object Contours!@#@!CAMP!@#@!This paper presents a special-purpose VLSI architecture for dominant point extraction along 2D contours. Such dominant points carry useful information for shape analysis and pattern recognition applications since they represent a local shape property and segment object contours into piecewise linear segments and circular arcs. The proposed architecture implements an algorithm based on the Curvature Primal Sketch. It consists of a set of 1D systolic FIR filters performing a multiresolution analysis of the scene's object contours, a set of finite-state-machines extracting zero-crossings and extrema of the filtered data, and a set of scale-space integration cells combining the accurate locations provided by the finest filters with the noise rejection properties of the coarsest ones in order to reliably extract relevant dominant points with accurate localization. The overall architecture has been successfully implemented and integrated to a custom machine vision system with real-time edge-extraction and edge-tracking capabilities. Some experimental results obtained using this system will be presented and discussed. Performance issues will also be addressed.
index427!@#@!1994!@#@!Merging Ada 9X and C++ in a Graphics System Software Architecture!@#@!Proceedings of the First International Eurospace - Ada-Europe Symposium on Ada in Europe!@#@!null
index428!@#@!2000!@#@!A Lower Bound for the Split Delivery Vehicle Routing Problem!@#@!Operations Research!@#@!In this paper we consider the Split Delivery Vehicle Routing Problem (SDVRP), a relaxation of the known Capacitated Vehicle Routing Problem (CVRP) in which the demand of any client can be serviced by more than one vehicle. We define a feasible solution of this problem, and we show that the convex hull of the associated incidence vectors is a polyhedron ( PSDVRP), whose dimension depends on whether a vehicle visiting a client must service, or not, at least one unit of the client demand. From a partial and linear description ofPSDVRP and a new family of valid inequalities, we develop a lower bound whose quality is exhibited in the computational results provided, which include the optimal resolution of some known instances--one of them with 50 clients. This instance is, as far as we know, the biggest one solved so far.
index429!@#@!2002!@#@!Pointer cache assisted prefetching!@#@!International Symposium on Microarchitecture!@#@!Data prefetching effectively reduces the negative effects of long load latencies on the performance of modern processors. Hardware prefetchers employ hardware structures to predict future memory addresses based on previous patterns. Thread-based prefetchers use portions of the actual program code to determine future load addresses for prefetching.This paper proposes the use of a pointer cache, which tracks pointer transitions, to aid prefetching. The pointer cache provides, for a given pointer's effective address, the base address of the object pointed to by the pointer. We examine using the pointer cache in a wide issue superscalar processor as a value predictor and to aid prefetching when a chain of pointers is being traversed. When a load misses in the L1 cache, but hits in the pointer cache, the first two cache blocks of the pointed to object are prefetched. In addition, the load's dependencies are broken by using the pointer cache hit as a value prediction.We also examine using the pointer cache to allow speculative precomputation to run farther ahead of the main thread of execution than in prior studies. Previously proposed thread-based prefetchers are limited in how far they can run ahead of the main thread when traversing a chain of recurrent dependent loads. When combined with the pointer cache, a speculative thread can make better progress ahead of the main thread, rapidly traversing data structures in the face of cache misses caused by pointer transitions.
index430!@#@!2001!@#@!Programming Skills of Software Engineering Students: What is required?!@#@!Proceedings of the 14th Conference on Software Engineering Education and Training!@#@!null
index431!@#@!2003!@#@!Neumann problem for elliptic equation in Sobolev power weighted spaces!@#@!Mathematics and Computers in Simulation!@#@!The Neumann problem for an elliptic equation in a bounded domain Ω ⊂ RN and for external forces with degenerations or singularities relating to the m-dimensional variety M ⊂ δ Ω are considered. The underlying ideas of proof of the existence of the considered problem solution are given for the remaining cases of N - m = 1 and N - m =2.
index432!@#@!1998!@#@!High Performance Distributed Objects Using Distributed Shared Memory and Remote Method Invocation!@#@!Proceedings of the Thirty-First Annual Hawaii International Conference on System Sciences-Volume 7 - Volume 7!@#@!null
index433!@#@!2003!@#@!Context-Aware Communication!@#@!Computer!@#@!null
index434!@#@!1995!@#@!Re-Vision: a methodology and tool for parallel computations!@#@!Proceedings of the 28th Hawaii International Conference on System Sciences!@#@!Describes Re-Vision, a software engineering methodology and a supporting computer environment for parallel computations based on the behaviour-oriented formalism. A key feature provided by the environment is support for multiple views of the problem. Two levels of data transformation are supported: metamodeling and modeling. At the metamodeling level, methods used to construct different views of a given problem are specified. At the modeling level, tools to build different models for a given problem are introduced. In the Re-Vision environment, a set of computerized tools support data transformations from methods to metamodels and models. The Re-Vision environment thus provides a complexity reduction of the data transformation and user interfaces between different tools for the design and analysis of parallel computations.
index435!@#@!1995!@#@!Decision aids for asset-to-objective allocation!@#@!ASILOMAR!@#@!Mathematical mechanisms have been proposed to address large scale optimization problems in which optimal or nearly optimal allocations of a hierarchically organized collection of assets to a hierarchically organized set of objectives are to be identified. This paper describes an a automated decision aid that uses the extended dependency model (EDM) for evaluation of costs and benefits within hierarchical structures and a genetic algorithm (GA) for optimization. Design of a graphical user interface to support user formulation of asset allocation problems involving complex hierarchical structures of assets and objectives is described, and examples involving tasking of aircraft assets in tactical scenarios are presented.
index436!@#@!1996!@#@!Query processing in Distributed PIOS!@#@!Proceedings of the 7th International Workshop on Database and Expert Systems Applications!@#@!An approach to query processing in object oriented distributed database systems is proposed. Distributed PIOS is a server that supports an object-oriented data model, physical data independence (i.e. different strategies for storing class hierarchies, grouping, horizontal and vertical partitioning of objects), and fragmentation transparency (i.e. transactions are not aware of the distribution of database fragments on several nodes of a computer network). The problem of the optimization of distributed queries (i.e. determining which data must be accessed at which site and which data must be transmitted among sites) is the focus of the paper.
index437!@#@!2002!@#@!The Michelson-Morley Experiment: A Case Study in Validation!@#@!Computing in Science and Engineering!@#@!The author uses the Michelson-Morley experiment as a case study in validation based on current knowledge. He uses standard mathematical concepts of error analysis to develop measures of merit. In order to fully understand the case study, he reviews philosophical concepts, focusing on scientific confirmation to understand which formal logical concepts can be used. He then proposes a logical foundation for scientific validation and give two research directions.
index438!@#@!2003!@#@!Powers in Sturmian sequences!@#@!European Journal of Combinatorics!@#@!We consider Sturmian sequences and explicitly determine all the integer powers occurring in them. Our approach is purely combinatorial and is based on canonical decompositions of Sturmian sequences and properties of their building blocks.
index439!@#@!2000!@#@!A Spatially Coherent Discrete Wavelet Transform - Accessing the Localization Property for Data Compression!@#@!Proceedings of the Conference on Data Compression!@#@!Wavelets intrinsically give us the capability of localized signal decomposition and analysis in space and frequency. However, the popular Fast Wavelet Transform (FWT) that is typically used as an ¿off the shelf¿ component in most wavelet based compression algorithms like the Embedded Zerotree (EZW) organizes the intermediate coefficients only by frequency, and not by space. We present the Recursive Merge Filter (RMF) discrete wave-let transform (DWT) algorithm that organizes intermediate coefficients with respect to both space and frequency. This allows close coupling and pipelining with the encoder, fine grained coding, and ¿cheap growing¿ of larger DWTs from smaller ones in a constant number of filter operations. The RMF algorithm computes the DWT of an array of length N in a bottom-up fashion, by successively ¿merging¿ two smaller DWTs (four in 2-D), and applying the wavelet filter only on the ¿smooth¿ or DC coefficients (Figure 1).
index440!@#@!1997!@#@!A Hybrid Web-Based Toolkit for Human Modeling!@#@!Proceedings of the Conference on Scientific Visualization!@#@!Modern web-based Scientific Visualization applications try to overcome common limitations imposed by limited internet bandwidth, server bottlenecks or network latency. A further aspect is the desire to gain platform independence by solely using instruments which are platform independent by conception: the programming language Java, the Virtual Reality Modeling Language (VRML), or the 3D API Java3D.We present a prototype of a hybrid web-based Scientific Visualization system which makes use of the increasing computational power of modern desktop workstations and personal computers on the client side, and the superior performance provided by a powerful machine on the server side. In order to achieve high interaction rates and to balance computational load the user can dynamically assign selected tasks to his client or to the server.Within the scientific field of human modeling we have implemented a hybrid web-based toolkit for the modeling of human muscles and skin. Our application allows the on-line generation and manipulation of three-dimensional implicit muscle models in a heterogeneous network and it offers various parameters to adjust computation and response time versus rendering quality.
index441!@#@!2001!@#@!Termination of on-demand rewriting and termination of OBJ programs!@#@!International Conference on Principles and Practice of Declarative Programming!@#@!Declarative languages such as OBJ, CafeOBJ, and Maude use syntactic annotations to introduce replacement restrictions aimed at improving termination or efficiency of computations. Unfortunately, there is a lack of formal techniques for proving such benefits. We show that context-sensitive rewriting and on-demand rewriting provide a suitable framework to address this problem. We provide methods to analyze termination of on-demand rewriting and apply them to analyze termination of OBJ, CafeOBJ, and Maude programs.
index442!@#@!2002!@#@!The Search for Design in Electrical Engineering Education!@#@!DELTA!@#@!The importance of design in engineering education is well established and a cornerstone of most new engineering curricula as well as accreditation criteria. Electrical and computer engineering (ECE) programs view many elements of design in ways similar to other engineering disciplines. However, in some respects other disciplines within engineering, such as Mechanical Engineering (ME), view design in broader terms, and perhaps gain value that electrical and computer engineering educators may miss. This paper describes how design is typically viewed in ECE programs, how it's viewed in other engineering areas, particularly ME, and suggests some new possibilities for enhancing design education within ECE programs. To illustrate these possibilities, an experimental subject in which entering freshmen build a sophisticated electronic device is described.
index443!@#@!2002!@#@!Introduction!@#@!Virtual space: spatiality in virtual inhabited 3D worlds!@#@!null
index444!@#@!1996!@#@!A Timing-Constrained Incremental Routing Algorithm for Symmetrical FPGAs!@#@!Proceedings of the 1996 European conference on Design and Test!@#@!In this paper we present a timing-constrained routing algorithm for symmetrical FPGAs which embodies a novel incremental routing strategy that combines global and detailed routing, and a routing resource allocation algorithm that takes into account both the characteristics of the routing resources and timing information. Experimental results confirm that the algorithm reduces delay along the longest path in the circuit, uses routing resources efficiently, and requires low CPU time.
index445!@#@!2003!@#@!Nonterminal complexity of programmed grammars!@#@!Theoretical Computer Science!@#@!We show that, in the case of context-free programmed grammars with appearance checking working under free derivations, three nonterminals are enough to generate every recursively enumerable language. This improves the previously published bound of eight for the nonterminal complexity of these grammars. This also yields an improved nonterminal complexity bound of four for context-free matrix grammars with appearance checking. Moreover, we establish an upperbound of four on the nonterminal complexity of context-free programmed grammars without appearance checking working under leftmost derivations of type 2. We derive nonterminal complexity bounds for context-free programmed and matrix grammars with appearance checking or with unconditional transfer working under leftmost derivations of types 2 and 3, as well. More specifically, a first nonterminal complexity bound for context-free programmed grammars with unconditional transfer (working under leftmost derivations of type 3) which depends on the size of the terminal alphabet is proved.
index446!@#@!2001!@#@!Focus on Authors!@#@!Marketing Science!@#@!null
index447!@#@!2001!@#@!A security model for distributed computing!@#@!Journal of Computing Sciences in Colleges!@#@!This paper presents a multi-tier model for secure computing as a teaching method platform. The security model is based on establishing the trustworthiness and role of each component in a distributed computing environment: trusted users, trusted servers, trusted administrators, untrusted client, untrusted communication media and intermediate systems, etc. The model provides a basis for teaching and for program system design. The security dimensions (both social and technical) can be considered in computer science curriculum in general. The model as a teaching method was experimented in some senior student software projects.
index448!@#@!1996!@#@!The Influence of External Variables on Information Technology Usage Behavior!@#@!Proceedings of the 29th Hawaii International Conference on System Sciences Volume 4: Organizational Systems and Technology!@#@!The Technology Acceptance Model (TAM) predicts the user acceptance of end-user applications by specifying causal relationships among external variables, belief and attitudinal constructs, and actual usage behavior. Although the perceived usefulness and perceived ease of use constructs have received much recent attention in the MIS literature, few studies have attempted to validate the full TAM model with all of the original constructs. Furthermore, the many published TAM studies are characterized by the use of different measurement factors to assess the belief constructs. This study validates TAM using the original constructs and assesses the effects of TAM variables on two measures of usage behavior. Results are largely consistent with previous TAM studies. However, the impact of external variables is not fully mediated by the TAM constructs.
index449!@#@!2002!@#@!A New Efficient Data Cleansing Method!@#@!Proceedings of the 13th International Conference on Database and Expert Systems Applications!@#@!null
index450!@#@!2001!@#@!Improving Repetitive Manufacturing Systems: Model and Insights!@#@!Operations Research!@#@!We consider a manufacturing system that is controlled by a fixed-cycle smoothed production policy. This policy, which is becoming increasingly common in repetitive manufacturing environments, is characterized by a production rate that is updated on a periodic basis. We model the system as a stochastic process that includes parameters for vendor responsiveness, plant responsiveness, randomness in production yield rates, nonstationarity and randomness in market demand, demand forecast error, operating cost rates, and safety stock. Properties of the model expose structural relationships between expected system performance and system parameters.
index451!@#@!2003!@#@!The Business Rule Approach!@#@!Computer!@#@!null
index452!@#@!2003!@#@!Invention: it's a mod, mod world!@#@!IEEE Spectrum!@#@!null
index453!@#@!2003!@#@!Parallel implementation of the split-step and the pseudospectral methods for solving higher KdV equation!@#@!Mathematics and Computers in Simulation!@#@!Numerical simulations show that higher order KdV equation under certain conditions has a self-focusing singularity, which means that the solution of the equation blows up in finite time. In this paper, two numerical schemes: the split-step Fourier transform and the pseudospectral methods are used to investigate this self-focusing singularity problem. Parallel algorithms for the proposed schemes are designed and implemented. FFTW-MPI algorithm designed by Matteo Frigo and Steven Johnson is used for parallel implementation of the discrete Fourier transform (DFT). The parallel algorithms are implemented on an SGI Origin 2000 multiprocessor computer and experiments show that a considerable speedup is attained.
index454!@#@!2003!@#@!CC--MPI: a compiled communication capable MPI prototype for ethernet switched clusters!@#@!Principles and Practice of Parallel Programming!@#@!Compiled communication has recently been proposed to improve communication performance for clusters of workstations. The idea of compiled communication is to apply more aggressive optimizations to communications whose information is known at compile time. Existing MPI libraries do not support compiled communication. In this paper, we present an MPI prototype, CC--MPI, that supports compiled communication on Ethernet switched clusters. The unique feature of CC--MPI is that it allows the user to manage network resources such as multicast groups directly and to optimize communications based on the availability of the communication information. CC--MPI optimizes one--to--all, one--to--many, all--to--all, and many--to--many collective communication routines using the compiled communication technique. We describe the techniques used in CC--MPI and report its performance. The results show that communication performance of Ethernet switched clusters can be significantly improved through compiled communication.
index455!@#@!1999!@#@!Dartmouth Workshop on Transportable Agents (DWTA) Announcement!@#@!Proceedings of the First International Symposium on Agent Systems and Applications Third International Symposium on Mobile Agents!@#@!null
index456!@#@!2001!@#@!Book Reviews!@#@!Interfaces!@#@!The range of books reviewed is wide, covering theory and applications in operations research, statistics, management science, econometrics, mathematics, computers, and information systems (no software is reviewed). In addition, we include books in other fields that emphasize technical applications. Publishers who wish to have their books reviewed should send them to Professor Benjamin Lev. We list the books received; not all books received can be reviewed because space and time are limited. Those who would like to review books are urged to send me their names, addresses, and specific areas of expertise. We commission all reviews and do not accept unsolicited book reviews. Readers are encouraged to suggest books that might be reviewed or to ask publishers to send me copies of such books.
index457!@#@!1997!@#@!Shocks from images: propagation of orientation elements!@#@!CVPR!@#@!The extraction of figure symmetry from image contours faces a number of fundamental difficulties: object symmetries are distorted due to (i) gaps in the bounding contour of a shape due to figure-ground blending, weak contrast edges, highlights, noise, etc.; (ii) an introduction of parts and occluders, and (iii) spurious edge elements due to surface markings, texture, etc. A framework for extracting such symmetries from real images is proposed based on the propagation of contour orientation information and the detection of four types of singularities (shocks) arising from the collision of propagating elements. In this paper, we show that an additional labeling of shocks based on whether the colliding wavefronts carry true orientation information (regular vs. rarefaction waves) allows a division of shocks into three sets: regular shocks are the partial shocks of partial contours as they remain invariant to the completion of the contour; semi-degenerate and degenerate shocks depict potential parts and gaps. Finally, shocks altered due to spurious edges, occlusion, and gaps are recovered via a simulation of inter-penetrating waves generated at select shock groups which with the aid of the above shock labels leads to second and further generations of shocks.
index458!@#@!2000!@#@!Load Balancing across Near-Homogeneous Multi-Resource Servers!@#@!Proceedings of the 9th Heterogeneous Computing Workshop!@#@!An emerging model for computational grids interconnects similar multi-resource servers from distributed sites. A job submitted to the grid can be executed by any of the servers; however, resource size or balance may be different across servers. One approach to resource management for this grid is to layer a global load distribution system on top of the local job management systems at each site. Unfortunately, classical load distribution policies fail on two aspects when applied to a multi-resource server grid. First, simple load indices may not recognize that a resource imbalance exists at a server. Second, classical job selection policies do not actively correct such a resource imbalanced state. We show through simulation that new policies based on resource balancing perform consistently better than the classical load distribution policies.
index459!@#@!1995!@#@!Implementation and testing of an automated EST processing and similarity analysis system!@#@!Proceedings of the 28th Hawaii International Conference on System Sciences!@#@!Expressed sequence tag (EST) sequencing projects are being undertaken in an effort to identify the function of as many genes as possible from entire genomes. Putative function can be determined by analyzing the similarity of the ESTs to sequences in the public databases. We are involved in a long-term project to research and develop database technology to store and analyze ESTs for Arabidopsis thaliana. The massive amounts of ESTs being produced through automated sequencing technologies necessitates the automated processing and similarity analysis of the ESTs. This paper describes a complete software system that takes ESTs from a sequencing machine, analyzes them for quality, and searches in public databases of previously known sequences. Automating the processing and analysis of the several thousand ESTs produced to date by the Michigan State University, Arabidopsis cDNA Sequencing Project has improved the quality of the EST data and the speed at which ESTs can be entered in the public databases.
index460!@#@!1997!@#@!Analysis of an ATM Multiplexer with Prioritized Service!@#@!Proceedings of the IFIP TC6 WG6.3/WG6.4 Fifth International Workshop on Performance Modelling and Evaluation of ATM Networks: Performance Analysis of ATM Networks!@#@!null
index461!@#@!1999!@#@!A Comparison of Structural CSP Decomposition Methods!@#@!Proceedings of the Sixteenth International Joint Conference on Artificial Intelligence!@#@!We compare tractable classes of constraint satisfaction problems (CSPs). We first give a uniform presentation of the major structural CSP decomposition methods. We then introduce a new class of tractable CSPs based on the concept of hypertree decomposition recently developed in Database Theory. We introduce a framework for comparing parametric decomposition-based methods according to tractability criteria and compare the most relevant methods. We show that the method of hypertree decomposition dominates the others in the case of general (nonbinary) CSPs.
index462!@#@!1991!@#@!Seven Lessons to Teach Design!@#@!Proceedings of the SEI Conference on Software Engineering Education!@#@!null
index463!@#@!1997!@#@!A Variant of Early Parsing!@#@!Proceedings of the 5th Congress of the Italian Association for Artificial Intelligence on Advances in Artificial Intelligence!@#@!null
index464!@#@!1997!@#@!Dynamic Appearance-Based Recognition!@#@!CVPR!@#@!We describe a hierarchical appearance-based method for learning, recognizing, and predicting arbitrary spatiotemporal sequences of images. The method, which implements a robust hierarchical form of the Kalman filter derived from the Minimum Description Length (MDL) principle, includes as a special case several well-known object encoding techniques including eigenspace methods for static recognition. Successive levels of the hierarchical filter implement dynamic models operating over successively larger spatial and temporal scales. Each hierarchical level predicts the recognition state at a lower level and modifies its own recognition state using the residual error between the prediction and the actual lower-level state. Simultaneously, on a longer time scale, the filter learns an internal model of input dynamics by adapting its generative and state transition matrices at each level to minimize prediction errors. The resulting prediction/learning scheme thereby implements an on-line form of the well-known Expectation-Maximization (EM) algorithm from statistics. We present experimental results demonstrating the method's efficacy in mediating robust spatiotemporal recognition in a variety of scenarios containing varying degrees of occlusions and clutter.
index465!@#@!2002!@#@!The virtual web-based supply chain!@#@!Managing virtual web organizations in the 21st century: issues and challenges!@#@!The virtual Web-based supply chain is emerging as a new form of industrial organization. This paper discusses the concept as a juncture of three forces: the virtual organization, Web-based communication and the application service provider (ASP). The virtual organization is a familiar concept in many industries, even without electronic connections. Web-based communication provides access and networks with new institutions. The ASP makes rapid change and flexible connections feasible. Together they establish focus, flexibility and rapid response to change in demand and customer requirements. Casting it in a strategic framework of structure, process and organization provides a basis for projecting its future.
index466!@#@!1996!@#@!Semantics of Normal Logic Programs and Contested Information!@#@!Proceedings of the 11th Annual IEEE Symposium on Logic in Computer Science!@#@!We propose C4, a four-valued semantics for normal, logic programs. Using this semantics, we define two types of entailment: strong and weak. We show that a normal, logic program strongly entails a sentence under C4 if, and only if, the program entails that sentence under the well founded semantics and it weakly entails a sentence if, and only if, the program entails that sentence under the two-valued stable model semantics. We argue that this shows that the difference between the well founded semantics and the stable model semantics can be characterized in terms of their attitude to what we call contested information. We use this insight to propose a general theory of contested reasoning.
index467!@#@!1986!@#@!Memory Conflicts in MIMD-Computers - A Performance Analysis!@#@!Conference on Algorithms and Hardware for Parallel Processing!@#@!null
index468!@#@!2001!@#@!Co-integration and error correction: representation, estimation, and testing!@#@!Essays in econometrics: collected papers of Clive W. J. Granger!@#@!The relationship between co-integration and error correction models, first suggested in Granger (1981), is here extended and used to develop estimation procedures, tests, and empirical examples.If each element of a vector of time series xt first achieves stationarity after differencing, but a linear combination α'xt, is already stationary, the time series xt are said to be co-integrated with co-integrating vector α. There may be several such co-integrating vectors so that α becomes a matrix. Interpreting α'xt, = 0 as a long run equilibrium, co-integration implies that deviations from equilibrium are stationary, with finite variance, even though the series themselves are nonstationary and have infinite variance.The paper presents a representation theorem based on Granger (1983), which connects the moving average, autoregressive, and error correction representations for co-integrated systems. A vector autoregression in differenced variables is incompatible with these representations. Estimation of these models is discussed and a simple but asymptotically efficient two-step estimator is proposed. Testing for co-integration combines the problems of unit root tests and tests with parameters unidentified under the null. Seven statistics are formulated and analyzed. The critical values of these statistics are calculated based on a Monte Carlo simulation. Using these critical values, the power properties of the tests are examined and one test procedure is recommended for application.In a series of examples it is found that consumption and income are co-integrated, wages and prices are not, short and long interest rates are, and nominal GNP is co-integrated with M2, but not M1, M3, or aggregate liquid assets.
index469!@#@!2003!@#@!Additional Reviewers!@#@!Proceedings of the 18th Annual IEEE Symposium on Logic in Computer Science!@#@!null
index470!@#@!2003!@#@!Faculty development initiative: acquisition and support of course management software!@#@!Journal of Computing Sciences in Colleges!@#@!This paper provides details on an initiative that includes acquisition of course management software (CMS) and a central server for use by faculty and students at eight colleges in central Kansas. The paper places the activities within the context of both national trends and a statewide faculty development initiative supported by the Kansas Independent College Association (KICA), a statewide organization whose members include 18 private institutions of higher education in Kansas. The paper provides information on implementation, usage statistics, and concludes by comparing what occurred against common recommendations for similar projects.
index471!@#@!2001!@#@!From the Editor!@#@!INFORMS Journal on Computing!@#@!null
index472!@#@!2002!@#@!We Need Assurance!@#@!EH!@#@!null
index473!@#@!1999!@#@!Enhancing Data Warehousing with Fuzzy Technology!@#@!Proceedings of the 10th International Conference on Database and Expert Systems Applications!@#@!null
index474!@#@!1999!@#@!Reusing Use Case Descriptions for Requirements Specification: Towards Use Case Patterns!@#@!Proceedings of the Sixth Asia Pacific Software Engineering Conference!@#@!This paper presents reusable patterns appearing in use case based requirements analysis processes. In the processes, analysts have interview and questionnaires to the stakeholders to get information of their problems, and then they compose the requirements specifications that are readable to the stakeholders. In this paper, we adopt use case approach to specify the requirements. We abstract the requirements descriptions written in use cases into patterns, so that we can reuse the experiences in requirements analysis. From a case study of a simple example problem, we design questionnaire forms and a set of patterns of reusable structured use cases.
index475!@#@!2002!@#@!Preface!@#@!Fuzzy Sets and Systems!@#@!null
index476!@#@!1988!@#@!3D-Vermessung mit mehreren geeichten Kameras!@#@!Mustererkennung 1988, 10. DAGM-Symposium!@#@!null
index477!@#@!2003!@#@!Message from the Workshops Chair!@#@!Proceedings of the 3st International Symposium on Cluster Computing and the Grid!@#@!null
index478!@#@!2001!@#@!Stocking Retail Assortments Under Dynamic Consumer Substitution!@#@!Operations Research!@#@!We analyze a single-period, stochastic inventory model (newsboy-like model) in which a sequence of heterogeneous customers dynamically substitute among product variants within a retail assortment when inventory is depleted. The customer choice decisions are based on a natural and classical utility maximization criterion. Faced with such substitution behavior, the retailer must choose initial inventory levels for the assortment to maximize expected profits.Using a sample path analysis, we analyze structural properties of the expected profit function. We show that, under very general assumptions on the demand process, total sales of each product are concave in their own inventory levels and possess the so-calleddecreasing differences property, meaning that the marginal value of an additional unit of the given product is decreasing in the inventory levels of all other products. For a continuous relaxation of the problem, we then show, via counterexamples, that the expected profit function is in general not even quasiconcave. Thus, global optimization may be difficult. However, we propose and analyze a stochastic gradient algorithm for the problem, and prove that it converges to a stationary point of the expected profit function under mild conditions. Finally, we apply the algorithm to a set of numerical examples and compare the resulting inventory decisions to those of some simpler, naive heuristics. The examples show that substitution effects can have a significant impact on an assortment's gross profits. The examples also illustrate some systematic distortions in inventory decisions if substitution effects are ignored. In particular, under substitution one should stock relatively more of popular variants and relatively less of unpopular variants than a traditional newsboy analysis indicates.
index479!@#@!1996!@#@!Initial Effects of Software Process Improvement on an Experienced Software Development Team!@#@!Proceedings of the 29th Hawaii International Conference on System Sciences Volume 1: Software Technology and Architecture!@#@!This paper discusses the initial stages of a long-term case study designed to examine the efforts of an experienced software development team in moving to a more process-driven software development environment. This team has previously produced software that has met functional, schedule, and cost criteria as specified by their customers. The software development manager, as directed by an organizational mandate, has initiated efforts to move this team into a more structured, formalism-based development and testing environment. The Capability Maturity Model (CMM) developed by the Software Engineering Institute (SEI) is being used as the model for this effort. The group dynamic and team development aspects of this effort are being carefully monitored to determine possible sources of resistance to change and to develop intervention "just-in-time" training sessions that can address identified problem areas, particularly those that may directly affect productivity, quality, and schedule. This paper discusses initial findings in this area and addresses them within the CMM framework.
index480!@#@!1996!@#@!Conference Organization!@#@!Proceedings of the 9th IEEE workshop on Computer Security Foundations!@#@!null
index481!@#@!2002!@#@!Degree or certification: what do faculty think?!@#@!Journal of Computing Sciences in Colleges!@#@!null
index482!@#@!2003!@#@!Combining KADS with ZEUS to Develop a Multi-Agent E-Commerce Application!@#@!Electronic Commerce Research!@#@!A KADS based requirement analysis for the management of stock trading portfolios is presented. This provides a theoretical foundation for a stock trading system. This system is designed around portfolio management tasks that include eliciting user profiles, collecting information on the user's portfolio position, monitoring the environment on behalf of the user, and making decision suggestions to meet the user's investment goals. The requirement analysis defines a framework for a Multi-Agent System for Stock Trading (MASST). Experiments in task decomposition and agent interaction using a partially implemented system are described.
index483!@#@!1995!@#@!Fast algorithms for finding O(congestion+dilation) packet routing schedules!@#@!Proceedings of the 28th Hawaii International Conference on System Sciences!@#@!Leighton, Maggs and Rao (1988) showed that for any network and any set of packets whose paths through the network are fixed and edge-simple, there exists a schedule for routing the packets to their destinations in O(c+d) steps using constant-size queues, where c is the congestion of the paths in the network, and d is the length of the longest path (the dilation). The proof, however, used the Lova/spl acute/sz (1975) local lemma and was not constructive. In this paper, we show how to find such a schedule in O(NE+Elog/sup /spl epsiv//E) time, for any fixed /spl epsiv/
index484!@#@!1997!@#@!Arithmetic Coding with Improved Solution for the Carry-Over Problem!@#@!Proceedings of the  Conference on Data Compression!@#@!null
index485!@#@!1987!@#@!Linsenfehlerkorrigierte Eichung von Halbleiterkameras mit Standarobjektiven f&uuml;r hochgenaue 3D-Messungen in Echtzeit!@#@!Mustererkennung 1987, 9. DAGM-Symposium!@#@!null
index486!@#@!1998!@#@!GLS-VLSI '98 Program Committee!@#@!Proceedings of the Great Lakes Symposium on VLSI '98!@#@!null
index487!@#@!2003!@#@!Complex Low-Pass Filters!@#@!Analog Integrated Circuits and Signal Processing!@#@!Zero-if transceivers suffer from the imbalance of the I and Q paths. By using a complex low-pass filter topology instead of a conventional pair of real low-pass filters, this imperfection can be reduced. Both analytical and numerical analysis show that the proposed technique is significantly more robust to circuit imperfections than the traditional architecture.
index488!@#@!2001!@#@!A Framework for Aspect-Oriented Multiparty Coordination!@#@!Proceedings of the IFIP TC6 / WG6.1 Third International Working Conference on New Developments in Distributed Applications and Interoperable Systems!@#@!null
index489!@#@!2000!@#@!Task-Role Based Access Control (T-RBAC): An Improved Access Control Model for Enterprise Environment!@#@!Proceedings of the 11th International Conference on Database and Expert Systems Applications!@#@!null
index490!@#@!2002!@#@!Design and Experimental Evaluation of Mobile Wireless Control Load Protocol!@#@!Proceedings of the 27th Annual IEEE Conference on Local Computer Networks!@#@!In wireless networks,as in many areas of engineering,simulation has been the de-factostandard for testing,dimensioning and analyzing mobile protocols.Emulation, which presentsa lower cost, more accurate,yet more complex engineering alternative to simulation, has notbeen widely used in mobile computing studies.RAMON is a software/hardware emulatortailored to mimic the realistic characteristics of wireless networks.RAMON is especiallydesigned to study how mobile protocols cope with high vehicular speeds.The main advantageof RAMON is the rapid, cost-effective and accurate testing it provides.This ranges fromproper identification of protocol bottlenecks, to testing of newly available wireless networksand hardware and software devices.Keywords:Network emulation,rapid-mobility,RAMON,Mobile-IP,wireless LAN,simulation.
index491!@#@!1998!@#@!Proceedings of the Fourth Symposium on Human Interaction with Complex Systems!@#@!HICS!@#@!null
index492!@#@!1996!@#@!An Error Monitoring Algorithm for ATM Signalling Links!@#@!Proceedings of the Sixth IFIP WG6.3 Conference on Performance of Computer Networks: Data Communications and their Performance!@#@!null
index493!@#@!2003!@#@!A framework of web-based conceptual design!@#@!Computers in Industry!@#@!A web-based conceptual design prototype system is presented. The system consists of four parts which interpret on-line sketches as 2D and 3D geometry, extract 3D hierarchical configurations, allow editing of component behaviours, and produce VRML-based behavioural simulations for design verification and web-based application. In the first part, on-line freehand sketched input is interpreted as 2D and 3D geometry, which geometrically represents conceptual design. The system then infers 3D configuration by analysing 3D modelling history. The configuration is described by a parent-child hierarchical relationship and relative positions between two geometric components. The positioning information is computed with respect to the VRML97 specification. In order to verify the conceptual design of a product, the behaviours can be specified interactively on different components. Finally, the system creates VRML97 formatted files for behavioural simulation and collaborative design application over the Internet. The paper gives examples of web-based applications. This work forms a part of a research project into the design and establishing of modular machines for automation manufacture. A consortium of leading automotive companies is collaborating on the research project.
index494!@#@!2002!@#@!Using Floating-Point Arithmetic on FPGAs to Accelerate Scientific N-Body Simulations!@#@!Proceedings of the 10th Annual IEEE Symposium on Field-Programmable Custom Computing Machines!@#@!This paper investigates the usage of floating-point arithmetic on FPGAs for N-Body simulation in natural science. The common aspect of these applications is the simple computing structure where forces between a particle and its surrounding particles are summed up. The role of reduced precision arithmetic is discussed, and our implementation of a floating-point arithmetic library with parameterized operators is presented. On the base of this library, implementation strategies of complex arithmetic units are discussed. Finally the realization of a fully pipelined pressure force calculation unit consisting of 60 floating-point operators with a resulting performance of 3.9 Gflops on an off the shelf FPGA is presented.
index495!@#@!2003!@#@!Multiple agent-based autonomy for satellite constellations!@#@!Artificial Intelligence!@#@!Multiple, highly autonomous, satellite systems are envisioned in the near future because they are capable of higher performance, lower cost, better fault tolerance, reconfigurability and upgradability. This paper presents an architecture and multi-agent design and simulation environment that will enable agent-based multi-satellite systems to fulfill their complex mission objectives, termed ObjectAgentTM. Its application is shown for a distributed aperture radar mission, although its applicability spans many types of missions. Required spacecraft functions, software agents, and multi-agent organisations are described for the radar mission, as well as their implementation. Agent-based simulations of mission case studies show the autonomous operation of the multi-agent architecture, which can then be used to build, evaluate and compare autonomous software architectures for multiple satellite systems.
index496!@#@!1996!@#@!Finite element meshes by means of voxels!@#@!Proceedings of the 6th International Workshop on Discrete Geometry for Computer Imagery!@#@!null
index497!@#@!2000!@#@!PPS-A Parallel Partition Sort Algorithm for Multiprocessor Database Systems!@#@!Proceedings of the 11th International Workshop on Database and Expert Systems Applications!@#@!A new algorithm, parallel partition sort (PPS), is proposed which is an improved range partition sort algorithm to handle the problem of workload imbalance, especially partition imbalance and heterogeneous imbalance, in a shared-nothing multiprocessor database environment. The new algorithm partitions the key range into a number of range intervals, then a fast internal sorting method is applied on each range interval combined with a dynamic mechanism to handle different interval sizes. A dynamic mathematical model approach is used to balance the workload among processing nodes by estimating data distribution during the sorting process. Experimental results demonstrate that the new algorithm performs better than existing parallel range partition sorting algorithms in a shared-nothing database environment for a wide degree of skew.
index498!@#@!2000!@#@!From the Editor!@#@!INFORMS Journal on Computing!@#@!null
index499!@#@!1997!@#@!A Technique for Mapping Sparse Matrix Computations into Regular Processor Arrays!@#@!Proceedings of the Third International Euro-Par Conference on Parallel Processing!@#@!null
index500!@#@!2002!@#@!Bayesian methods!@#@!Fuzzy logic and probability applications: bridging the gap!@#@!The use of Bayesian methods as both an information combination scheme and an updating tool has become widespread, combining or updating prior information with existing information about events. Bayesian methods stem from the application of Bayes' theorem in probability. As will be noted in this chapter, not only do these methods provide ways of handling various kinds of uncertainties, but they also can serve as a link between subjective-based probability theory and fuzzy logic.In the Bayesian paradigm, uncertainty is quantified in terms of a personal or subjective probability following the axioms of probability theory (see Chapter 3, section 3.2.5), The probability of an event X is denoted P (X; H), where H represents the assessor's information, often called the prior information. Prior refers to the knowledge that exists prior to the acquisition of information about event X. Uncertainties combine via rules of probability that stem from the axiomatic behavioristic interpretation of probability (see Chapter 3, section 3.1). The fundamental Bayesian philosophy is that prior information, H, is valuable and can be mathematically combined with information about X and, with such combination, uncertainties can be reduced.Understanding the uses of Bayesian methods begins with the historical development of the theory.
index501!@#@!1987!@#@!Resolution in Computerized Tomography!@#@!Aachener Symposium f&uuml;r Signaltheorie: Mehrdimensionale Signale und Bildverarbeitung!@#@!null
index502!@#@!2003!@#@!A distance-regular graph with bipartite geodetically closed subgraphs!@#@!European Journal of Combinatorics!@#@!Let Γ be a distance-regular graph of diameter d , and t be an integer with 2 ≤ t ≤ d - 1 such that a t -1 = 0. For any pair (u, v) of vertices, let Π(u, v) be the subgraph induced by the vertices lying on shortest paths between u and v . We prove that if Π(u, v) is a bipartite geodetically closed subgraph for some pair (u, v) of vertices at distance t , then Π(x, y) is a bipartite geodetically closed subgraph for any pair (x, y) of vertices at distance less than or equal to t . In particular, Π(x, y) is either a path, an ordinary polygon, a hyper cube or a projective incidence graph.
index503!@#@!2003!@#@!Attribute grammars and automatic complexity analysis!@#@!Advances in Applied Mathematics!@#@!Attribute grammars provide a concise way to describe traits of a wide family of structures. Structures defined by context-free grammars have been well studied by Delest, Fédou, and more recently by Duchon. One of the principle benefits of this approach is the easy access to multivariate generating function equations from which average and higher moments are easily accessible. This work extends these notions to a wider class of structures and considers the application to algorithm analysis.
index504!@#@!2003!@#@!Building bridges between convex regions!@#@!Computational Geometry: Theory and Applications!@#@!In the Euclidean traveling salesman and buyers problem (TSBP), we are given a set of convex regions in d-dimensional space, and we wish to find a minimum-cost tour that visits all the regions. The cost of a tour depends on the length of the tour itself and on the distance that buyers within each region need to travel to meet the salesman. We show that constant-factor approximations to the TSBP and several similar problems ,can be obtained by visiting the centers of the smallest enclosing spheres of the regions.
index505!@#@!2003!@#@!Congestion control!@#@!Proceedings of the 2003 ACM SIGMETRICS international conference on Measurement and modeling of computer systems!@#@!null
index506!@#@!1998!@#@!Incorporating Methods and Encapsulation into Deductive Object-Oriented Database Languages!@#@!Proceedings of the 9th International Conference on Database and Expert Systems Applications!@#@!null
index507!@#@!1995!@#@!A Weakest Precondition Semantics for Conditional Planning!@#@!Proceedings of the 4th Congress of the Italian Association for Artificial Intelligence on Topics in Artificial Intelligence!@#@!null
index508!@#@!2003!@#@!Stochastic Vehicle Routing with Random Travel Times!@#@!Transportation Science!@#@!We consider stochastic vehicle routing problems on a network with random travel and service times. A fleet of one or more vehicles is available to be routed through the network to service each node. Two versions of the model are developed based on alternative objective functions. We provide bounds on optimal objective function values and conditions under which reductions to simpler models can be made. Our solution method embeds a branch-and-cut scheme within a Monte Carlo sampling-based procedure.
index509!@#@!2000!@#@!Optimization of Knots for the Multi Curve B-Spline Approximation!@#@!Proceedings of the Geometric Modeling and Processing 2000!@#@!This article presents a method for multi curve approximation with B-spline. The approximation is formulated as a constrained optimization problem with the least squares error as the objective function and the knot vector as the variables. The method presented in this article is designed to eliminate the well-known lethargic behavior and to maintain the accuracy of control points. The method for fitting skeletal curves was tested on a single-section case and a multi-section case. The tests showed that the method reduces the objective function significantly. The proposed method has potential applications in the shape design of wings, turbine blades, and automotive body panels.
index510!@#@!2002!@#@!An adaptive noise mechanism for walkSAT!@#@!Eighteenth national conference on Artificial intelligence!@#@!Stochastic local search algorithms based on the WalkSAT architecture are among the best known methods for solving hard and large instances of the propositional satisfiability problem (SAT). The performance and behaviour of these algorithms critically depends on the setting of the noise parameter, which controls the greediness of the search process. The optimal setting for the noise parameter varies considerably between different types and sizes of problem instances; consequently, considerable manual tuning is typically required to obtain peak performance. In this paper, we characterise the impact of the noise setting on the behaviour of WalkSAT and introduce a simple adaptive noise mechanism for WalkSAT that does not require manual adjustment for different problem instances. We present experimental results indicating that by using this self-tuning noise mechanism, various WalkSAT variants (including WalkSAT/SKC and Novelty<sup>+</sup>) achieve performance levels close to their peak performance for instance-specific, manually tuned noise settings.
index511!@#@!2003!@#@!Birth-death processes and associated polynomials!@#@!Journal of Computational and Applied Mathematics!@#@!We consider birth-death processes on the nonnegative integers and the corresponding sequences of orthogonal polynomials called birth-death polynomials. The sequence of associated polynomials linked with a sequence of birth-death polynomials and its orthogonalizing measure can be used in the analysis of the underlying birth-death process in several ways. We briefly review the known applications of associated polynomials, which concern transition and first-entrance time probabilities, and establish some new results in this vein. In particular, our findings indicate how the prevalence of recurrence or α-recurrence in a birth-death process can be recognized from certain properties of the orthogonalizing measure for the associated polynomials.
index512!@#@!2003!@#@!Calendar of meetings!@#@!Computational Statistics &amp; Data Analysis!@#@!null
index513!@#@!1981!@#@!Ein Algorithmus zur Ermittlung der kosteng&uuml;nstigsten Anzahl von Bildschirmger&auml;ten!@#@!Organisation und Betrieb von Rechenzentren, Fachgespr&auml;ch der GI!@#@!null
index514!@#@!2001!@#@!On the Evaluation of Path-Oriented Queries in Document Databases!@#@!Proceedings of the 12th International Conference on Database and Expert Systems Applications!@#@!null
index515!@#@!2000!@#@!Teaching Scientific Method for Real-Time Software Engineering!@#@!Proceedings of the 13th Conference on Software Engineering Education & Training!@#@!In examining the literature on software engineering, we have noticed that the prevalent opinion is that people being hired today to develop software have little or no training in scientific methods. The result of this phenomenon is that developers often do not know how to systematically develop software that is reliable and of high quality. This factor is especially important in the engineering of real-time embedded software, where "shoot from the hip" software development can lead to devastating failures.We feel that understanding the process of science is key to ensuring quality and reliability in all systems, especially critical ones. This premise is founded on the belief that by understanding the scientific process, the practice of software engineering would be greatly enhanced and strengthened. Our intent is to demonstrate how the software engineering process and the scientific process are similar, and how university programs can benefit from adding scientific method instruction to their curriculums.
index516!@#@!1986!@#@!Synchroner Datenflu&szlig;rechner zur Echtzeitbildverarbeitung!@#@!Mustererkennung 1986, 8. DAGM-Symposium!@#@!null
index517!@#@!1978!@#@!Ein hierarchisches Textur-Modell!@#@!Bildverarbeitung und Mustererkennung, DAGM Symposium!@#@!null
index518!@#@!2002!@#@!SAFE: secure agent roaming for e-commerce!@#@!Computers and Industrial Engineering!@#@!The development of the Internet has made a powerful impact on the concept of commerce. E-commerce, a new way to conduct business, is gaining more and more popularity. Despite its rapid growth, there are limitations that hinder the expansion of e-commerce. The primary concern for most people when talking about online shopping is security. Due to the open nature of the Internet, personal financial details necessary for online shopping can be stolen if sufficient security mechanism is not put in place. How to provide the necessary assurance of security to consumers remains a question mark despite various past efforts. Another concern is the lack of intelligence. The Internet is an ocean of information depository. It is rich in content but lacks the necessary intelligent tools to help one locate the correct piece of information. Intelligent agent, a piece of software that can act on behalf of its owner intelligently, is designed to fill this gap. However, no matter how intelligent an agent is, if it remains on its owner's machine and does not have any roaming capability, its functionality is limited. With the roaming capability, more security concerns arise. In response to these concerns, SAFE, secure roaming agent for e-commerce, is designed to provide secure roaming capability to intelligent agents (Guan and Yang, 1999).
index519!@#@!2000!@#@!An integrated framework with UML and Object-Z for developing a precise and understandable specification: the light control case study!@#@!Proceedings of the Seventh Asia-Pacific Software Engineering Conference!@#@!Presents a framework that integrates a graphical specification technique (UML) with a formal specification technique (Object-Z) to support requirements elicitation and analysis activities. Various UML diagrams are used to specify the system from different concerns during the early requirements elicitation and analysis stage. The information captured in the diagrams is used to develop a complete Object-Z specification. This paper presents a semantic translation from statechart diagrams to Object-Z specifications. Finally, based on information captured in sequence diagrams and use case diagrams, a functional model of the whole system is formally defined. The case study used in this paper is a real-time, interactive and embedded system: a light control system.
index520!@#@!2002!@#@!Spain!@#@!E-commerce law in Europe and the USA!@#@!null
index521!@#@!2002!@#@!Array Force Display for Hardness Distribution!@#@!Proceedings of the 10th Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems!@#@!This paper describes design of array force display for presentation of hardness distribution in an elastic object. The array force display is composed of an elastic plate and a linear actuator array. It provides a spatially continuous surface on which users can effectively touch virtual objects using any part of their bare hand. The elastic plate is made of rubber and sponge. When the actuator pushes the plate, its hardness increases. The user feels as if hard object is submerged in a soft object. The device is evaluated through experim ents for palpation performance.
index522!@#@!2002!@#@!Reliable Blast UDP: Predictable High Performance Bulk Data Transfer!@#@!CLUSTER!@#@!High speed bulk data transfer is an important part of many data-intensive scientific applications. This paper describes an aggressive bulk data transfer scheme, called Reliable Blast UDP (RBUDP), intended for extremely high bandwidth, dedicated- or Quality-of-Service-enabled networks, such as optically switched networks. This paper also provides an analytical model to predict RBUDP's performance and compares the results of our model against our implementation of RBUDP. Our results show that RBUDP performs extremely efficiently overhigh speed dedicated networks and our model is able to provide good estimates of its performance.
index523!@#@!2003!@#@!A unifying framework for intelligent DNS management!@#@!International Journal of Human-Computer Studies!@#@!The Domain Name System (DNS) is a special kind of distributed directory service for people to create and access the network information systems by (1) allowing local control of its segments and (2) making each segment's data available on the Internet using a client-server scheme. However, few administrators have the expertise to do the jobs well since this distributed mechanism is a double-edged sword; it allows DNS not only to scale to Internet size but also allows for incredible mis-configurations. The presented study is an analysis of what problems and difficulties most DNS administrators might encounter and provides the insights into how various DNS assistant sub-systems could be designed and deployed to solve the complex problems or alleviate these DNS administration job loadings. Ontologies become an important mechanism to build information systems. The role of ontologies is to capture domain knowledge and provide a commonly agreed upon understanding of a domain. The advantages include the sharing and re-use of knowledge, and the better engineering of knowledge-based systems with respect to acquisition, verification and maintenance. In this paper, we propose a unifying framework (e.g. including configuration, outstanding traffic monitoring and analysis, planning and management, tutoring, etc.) for supporting intelligent DNS management using web interface and expert system technology to help inexperienced administrators in insuring the smooth operation of their DNS systems. To help extract knowledge, we propose an efficient DNS Ontology Construction Algorithm to fast conceptualize DNS domain knowledge through a hybrid method of brainstorming and use cases modeling. While some sub-systems are still under development, others have been prototyped and deployed for everyday use. As our experience with a first simple prototype has shown, the paradigm of using DNS ontology to build a unifying framework for intelligent DNS management works good and effective. It is supposed that all these might become an integral part of the DNS administration activities of an organization in the near future.
index524!@#@!2002!@#@!Enhanced word clustering for hierarchical text classification!@#@!International Conference on Knowledge Discovery and Data Mining!@#@!In this paper we propose a new information-theoretic divisive algorithm for word clustering applied to text classification. In previous work, such "distributional clustering" of features has been found to achieve improvements over feature selection in terms of classification accuracy, especially at lower number of features [2, 28]. However the existing clustering techniques are agglomerative in nature and result in (i) sub-optimal word clusters and (ii) high computational cost. In order to explicitly capture the optimality of word clusters in an information theoretic framework, we first derive a global criterion for feature clustering. We then present a fast, divisive algorithm that monotonically decreases this objective function value, thus converging to a local minimum. We show that our algorithm minimizes the "within-cluster Jensen-Shannon divergence" while simultaneously maximizing the "between-cluster Jensen-Shannon divergence". In comparison to the previously proposed agglomerative strategies our divisive algorithm achieves higher classification accuracy especially at lower number of features. We further show that feature clustering is an effective technique for building smaller class models in hierarchical classification. We present detailed experimental results using Naive Bayes and Support Vector Machines on the 20 Newsgroups data set and a 3-level hierarchy of HTML documents collected from Dmoz Open Directory.
index525!@#@!2002!@#@!Evolving Vision-Based Flying Robots!@#@!Proceedings of the Second International Workshop on Biologically Motivated Computer Vision!@#@!null
index526!@#@!2002!@#@!Book reviews of "introduction to graphical modelling" by Edwards, Davis, New York, Springer Verlag!@#@!Computational Statistics &amp; Data Analysis!@#@!null
index527!@#@!1995!@#@!Measuring proteins and voids in proteins!@#@!Proceedings of the 28th Hawaii International Conference on System Sciences!@#@!Common geometric models for proteins and other molecules are the space filling diagram, the solvent accessible surface, and the molecular surface. We describe software that computes metric properties of these models, including volume and surface area. It also measures voids or empty space enclosed by the protein, and it keeps track of surface area contributions of individual atoms. The software is based on 3-dimensional alpha complexes and on inclusion-exclusion formulas with terms derived from the simplices in this complex.
index528!@#@!2002!@#@!Mature woman seeks to study computer science!@#@!Journal of Computing Sciences in Colleges!@#@!This panel will discuss the challenges faced by adult women students in college-level Computer Science programs. The panelists include three women who have survived such programs and will talk about their experiences first-hand. These women have recently earned degrees in Computer Science and are now employed either in academia or industry.
index529!@#@!1996!@#@!Dimensioning the Continuous State Leaky Bucket for Geometric Arrivals!@#@!Proceedings of the Sixth IFIP WG6.3 Conference on Performance of Computer Networks: Data Communications and their Performance!@#@!null
index530!@#@!1998!@#@!Proceedings of the Thirty-First Annual Hawaii International Conference on System Sciences-Volume 6 - Volume 6!@#@!HICSS!@#@!null
index531!@#@!1987!@#@!Design Issues in High Performance Fault-Tolerant Multicomputers!@#@!Fehlertolerierende Rechensysteme / Fault-Tolerant Computing Systems, 3. Internationale GI/ITG/GMA-Fachtagung!@#@!null
index532!@#@!1998!@#@!Modeling, Indexing and Retrieving Images Using Conceptual Graphs!@#@!Proceedings of the 9th International Conference on Database and Expert Systems Applications!@#@!null
index533!@#@!2002!@#@!Automated Design of Analog Circuits Using Cell-Based Structure!@#@!EH!@#@!An automated synthesis for analog computational circuits in transistor-level configuration aiming for non-linear analog circuits is presented. A cell-based structure based on PTA (Programmable Transistor Array) cell [5] is introduced to place moderate constraints on the MOSFET circuit topology. Synthesis objectives are analog high-speed non-linear circuits since they play important roles in today's analog circuits and difficult to design. In addition to the PTA structure, explicit feedback path are forbidden and current sources are introduced aiming to keep the circuits stable. A genetic algorithm is applied to search circuit topologies and transistor sizes that satisfy given specifications. Synthesis capabilities are demonstrated through examples of three types of computational circuits, such as absolute value, squaring, and cubing functions by using computer simulations and real hardware.
index534!@#@!1999!@#@!Debugging Techniques for Dynamically Reconfigurable Hardware!@#@!Proceedings of the Seventh Annual IEEE Symposium on Field-Programmable Custom Computing Machines!@#@!Testing dynamically reconfigurable systems imposes new challenges which require special treatment. We present tools and techniques we developed for debugging a dynamically reconfigurable system that performs run-time constant propagation optimizations. An application for monitoring the effect of run-time specialization is presented and we show how we adapted standard testability techniques to evaluate the performance of specialized circuits. We also outline how HDLs that capture reconfiguration at a high level can assist with debugging.
index535!@#@!2000!@#@!Questions about Developing a Postgraduate Software Engineering Program!@#@!Proceedings of the 13th Conference on Software Engineering Education & Training!@#@!Carroll College has successfully offered an undergraduate degree in Computer Science for nearly 20 years. In 1998 we began to investigate the possibility of offering a Master's program in Software Engineering. The program will be for professionals with industry experience who would attend part-time. A proposal was developed and has been approved by the necessary internal bodies and, once approval is obtained from the North Central Accrediting agency, we will be able to go ahead and offer the degree. This academic year, Carroll is beginning to offer some of the introductory courses for the degree on a diploma basis.We regard this workshop as an opportunity to see what other people are doing in the area of graduate software education and come to it not with a 'position paper' per se but with a list of questions and topics on which we are eager to hear others' positions.
index536!@#@!2002!@#@!Back to Pascal: retro but not backwards!@#@!Journal of Computing Sciences in Colleges!@#@!The debate over which language to use when teaching beginning programming has persisted for decades. One institution has elected to give Pascal a second chance. The rationale for this change and some early experiences are outlined. The difficulties experienced when this institution used C++ are described and the requirements for a first language are listed. Pascal satisfies most of the requirements as specified. Opposition to the change was noted and countered. Now, after the first semester of use, some clear advantages as well as disadvantages are evident.
index537!@#@!2001!@#@!Mobile & wireless technology: keeping PDAs in sync!@#@!Network Computing!@#@!null
index538!@#@!2002!@#@!The privacy paradox!@#@!Ubiquity!@#@!A national biometric database in place of our current flawed identification systems could prevent the loss of liberty and autonomy.
index539!@#@!2003!@#@!Modeling Cellular Behavior with Hybrid Automata: Bisimulation and Collapsing!@#@!Proceedings of the First International Workshop on Computational Methods in Systems Biology!@#@!null
index540!@#@!2002!@#@!Association news & notes: JASAG news & notes!@#@!Simulation and Gaming!@#@!null
index541!@#@!2000!@#@!Hardware Accelerator for Subgraph Isomorphism Problems!@#@!Proceedings of the 2000 IEEE Symposium on Field-Programmable Custom Computing Machines!@#@!Many applications can be modeled as subgraph isomorphism problem, which is generally NP-complete. This paper presents an algorithm that is suited for hardware implementation. The prototype accelerator that operates at 16.5 MHz on Lucent ORCA 2C15A FPGA outperforms the software implementation of Ullmann's algorithm on 400 MHz Pentium II by 10 times in the best case.
index542!@#@!2002!@#@!Dimension Reduction in the \ell _1 Norm!@#@!Proceedings of the 43rd Symposium on Foundations of Computer Science!@#@!The Johnson-Lindenstrauss Lemma shows that any set of n points in Euclidean space can be mapped linearly down to O0({{(\log n)} \mathord{\left/ {\vphantom {{(\log n)} {\varepsilon ^2 }}} \right. \kern-\nulldelimiterspace} {\varepsilon ^2 }}) dimensions such that all pairwise distances are distorted by at most 1 + \varepsilon. We study the following basic question: Does there exist an analogue of the Johnson-Lindenstrauss Lemma for the \ell _1 norm?Note that Johnson-Lindenstrauss Lemma gives a linear embedding which is independent of the point set. For the \ell _1 norm, we show that one cannot hope to use linear embeddingsas a dimensionality reduction tool for general point sets, even if the linear embedding is chosen as a function of the given point set. In particular, we construct a set of O(n) points in n\ell _1^n such that any linear embedding into \ell _1^d must incur a distortion of \Omega (\sqrt {{n \mathord{\left/ {\vphantom {n d}} \right. \kern-\nulldelimiterspace} d}}). This bound is tight up to a log n factor. We then initiate a systematic study of general classes of \ell _1 embeddable metrics that admit low dimensional, small distortion embeddings. In particular, we show dimensionality reduction theorems for tree metrics, circular-decomposable metrics, and metrics supported on K2,3-free graphs, giving embeddings into \ell _1 withconstant distortion. Finally, we also present lower bounds on dimension reduction techniques for other \ell _p norms.Our work suggests that the notion of a stretch-limited embedding, where no distance is stretched by more than a factor d in any dimension, is important to the study of dimension reduction for \ell _1. We use such stretch limited embeddings as a tool for proving lower bounds for dimension reduction and also as an algorithmic tool for proving positive results.
index543!@#@!1995!@#@!Interactive Composite Hypothesis Testing with Enhanced Audio!@#@!ASILOMAR!@#@!This paper describes a unique method and system for decomposing a composite acoustic observation into a consistent set of sources. Unlike many current approaches, the emphasis in this method is to maximize the human auditory system's unparalleled ability to associate signal components in a cluttered environment. Visual and audio tools are combined to allow rapid evaluation of decomposition hypotheses and to record statistical results. The technique and system has been applied to various applications.
index544!@#@!2002!@#@!A graphical criterion for the identification of causal effects in linear models!@#@!Eighteenth national conference on Artificial intelligence!@#@!This paper concerns the assessment of direct causal effects from a combination of: (i) non-experimental data, and (ii) qualitative domain knowledge. Domain knowledge is encoded in the form of a directed acyclic graph (DAG), in which all interactions are assumed linear, and some variables are presumed to be unobserved. The paper establishes a sufficient criterion for the identifiability of all causal effects in such models as well as a procedure for estimating the causal effects from the observed covariance matrix.
index545!@#@!2003!@#@!A non-smooth variational approach to differential problems: a case study of non-resonance under the first eigenvalue for a strongly nonlinear elliptic problem!@#@!Nonlinear Analysis: Theory, Methods &amp; Applications!@#@!null
index546!@#@!2002!@#@!Data mining tasks and methods: Classification: multicriteria classification!@#@!Handbook of data mining and knowledge discovery!@#@!In this article we consider multicriteria classification, which differs from usual classification problems since it takes into account preference orders in the description of objects by condition and decision attributes. The well-known methods of knowledge discovery do not use information about preference orders in multicriteria classification. It is worthwhile, however, to take this information into account as many practical problems involve evaluation of objects on preference-ordered domains. To deal with multicriteria classification we propose to use a dominance-based rough set approach (DRSA). This approach is different from the classical rough set approach (CRSA) because it takes into account preference orders in the domains of attributes and in the set of decision classes. Given a set of objects partitioned into predefined and preference-ordered classes, the new rough set approach is able to approximate this partition by means of dominance relations (instead of indiscernibility relations used in the CRSA). The rough approximation of this partition is a starting point for induction of "if..., then..." decision rules. The syntax of these rules is adapted to represent preference orders. The DRSA keeps the best properties of the CRSA: it only analyzes facts present in data and possible inconsistencies are not corrected. Moreover, the new approach does not need any prior discretization of continuous-valued attributes. The usefulness of the DRSA and its advantages over the CRSA are presented in a real study of evaluation of the risk of business failure.
index547!@#@!1995!@#@!Invariant Standrad Positions of Ordered Sets of Points!@#@!Proceedings of the 6th International Conference on Computer Analysis of Images and Patterns!@#@!null
index548!@#@!2003!@#@!Corrigendum to: self-consistent modeling of turbulence and transport!@#@!Journal of Computational Physics!@#@!null
index549!@#@!2003!@#@!Low Complexity Multiplication in a Finite Field Using Ring Representation!@#@!IEEE Transactions on Computers!@#@!Elements of a finite field, GF(2^m ), are represented as elements in a ring in which multiplication is more time efficient. This leads to faster multipliers with a modest increase in the number of XOR and AND gates needed to construct the multiplier. Such multipliers are used in error control coding and cryptography. We consider rings modulo trinomials and 4-term polynomials. In each case, we show that our multiplier is faster than multipliers over elements in a finite field defined by irreducible pentanomials. These results are especially significant in the field of elliptic curve cryptography, where pentanomials are used to define finite fields. Finally, an efficient systolic implementation of a multiplier for elements in a ring defined by x^n + x + 1 is presented.
index550!@#@!1997!@#@!Automatic Programming of a Time-Optimal Robot Controller and an Analog Electrical Circuit to Implement the Robot Controller by Means of Genetic Programming!@#@!Proceedings of the 1997 IEEE International Symposium on Computational Intelligence in Robotics and Automation!@#@!Genetic programming is an automatic programming technique that evolves computer programs to solve, or approximately solve, problems. This paper presents two examples in which genetic programming creates a computer program for controlling a robot so that the robot moves to a specified destination point in minimal time. In the first approach, genetic programming evolves a computer program composed of ordinary arithmetic operations and conditional operations to implement a time- optimal control strategy. In the second approach, genetic programming evolves the design of an analog electrical circuit consisting of transistors, diodes, resistors, and power supplies to implement a near-optimal control strategy.
index551!@#@!2003!@#@!Towards numerical procedures for those technical phenomena whose mathematical models lead to non-standard conservation laws a survey!@#@!Mathematics and Computers in Simulation!@#@!An introduction to modelling of physical phenomena by conservation laws will be given, particularly in case of phenomena for which the conservation-law-models do not show the standard properties usually assumed to be fulfilled in order to prove theoretical or numerical results. Numerical procedures for this sort of non-standard conservation laws (NSCL) are not yet available in the literature. An abstract theorem for the convergence of discretisation procedures in case of problems whose solutions are uniquely determined by inequalities will be presented. First steps towards numerical methods for solving NSCL-problems could be successfully done by means of this general theory and will be presented in this paper.
index552!@#@!2002!@#@!Face Reconstruction from Partial Information Based on a Morphable Face Model!@#@!Proceedings of the Second International Workshop on Biologically Motivated Computer Vision!@#@!null
index553!@#@!1995!@#@!A fault-tolerant architecture based on autonomous replicated objects!@#@!Proceedings of the 28th Hawaii International Conference on System Sciences!@#@!The paper proposes an architecture for the replication of program modules enabling them to behave in accordance with their own local knowledge, without any influence by not only their location, replication degree and fault-tolerant mechanism but also system level modules. In the proposed architecture, program modules are implemented as objects and communication among them is carried out by a total ordering broadcast protocol, enabling individual objects to behave autonomously. Therefore, individual objects can choose the most suitable replication degree and fault-tolerant mechanism in accordance with their own required reliability and execution efficiency without the need to change programs or for the object location to be influenced.
index554!@#@!1996!@#@!Filling driven by contour marching!@#@!Proceedings of the 6th International Workshop on Discrete Geometry for Computer Imagery!@#@!null
index555!@#@!1994!@#@!Obstacles to transparent heterogeneity in a distributed programming environment!@#@!Proceedings of the 1994 conference of the Centre for Advanced Studies on Collaborative research!@#@!Distributed parallel (DP) programming is a cost effective way of obtaining supercomputer performance. One inherent problem with DP programming is the connection of heterogeneous processor types and file systems. It is becoming increasingly important that the environment transparently handle all communication and I/O connections.This paper looks at some of the obstacles and possible solutions to providing transparent heterogeneity within Enterprise -- an environment for developing distributed memory parallel programs on a network of workstations. Enterprise, using templates and a precompiler, constructs a software layer around the user's application. The user is shielded from the tiresome low-level details of hand crafting the distributed communication portion of the application. In fact, Enterprise programs are transparent to the communication package.One of the tenets of Enterprise is that the user develops programs using only the familiar sequential C programming language. There are no extensions to the language, nor are there any special library calls. However, issues like message and file transparencies are problematic, since they involve user knowledge and dynamic run-time information to create an efficient program. This paper examines the issues of transparently encapsulating and preserving the sequential semantics of the user's code running on a heterogeneous network of workstations and file systems.
index556!@#@!1998!@#@!Complexity Classes and Rewrite Systems with Polynomial Interpretation!@#@!Proceedings of the 12th International Workshop on Computer Science Logic!@#@!null
index557!@#@!2003!@#@!News track!@#@!Communications of the ACM!@#@!null
index558!@#@!2000!@#@!Optimizing Restoration Capacity in the AT&T Network!@#@!Interfaces!@#@!To ensure high network reliability, AT&amp;T employs two basic approaches: preventing failures and responding quickly when failures occur. For AT&amp;T to quickly reroute traffic in the event of a network failure, the network must contain sufficient restoration capacity to carry the displaced demand. A team of AT&amp;T OR experts, network planners, and managers developed a method for determining the appropriate quantity and location of restoration capacity required to restore the demand during any single link failure. The approach centers on a linear programming model to minimize the cost of the restoration network and uses column generation to generate new restoration paths as needed. In about 10 months, the team converted the methodology into a tool to optimize the allocation of restoration capacity. This tool was then extended to plan for the recovery of a switching-center disaster and to reoptimize the entire restoration network. It has contributed to AT&amp;T's achieving high-quality service, while saving valuable resources. It resulted in hundreds of millions of dollars in cost savings and increased revenues.
index559!@#@!2003!@#@!An Eulerian method for computation of multimaterial impact with ENO shock-capturing and sharp interfaces!@#@!Journal of Computational Physics!@#@!A technique is presented for the numerical simulation of high-speed multimaterial impact. Of particular interest is the interaction of solid impactors with targets. The computations are performed on a fixed Cartesian mesh by casting the equations governing material deformation in Eulerian conservation law form. The advantage of the Eulerian setting is the disconnection of the mesh from the boundary deformation allowing for large distortions of the interfaces. Eigenvalue analysis reveals that the system of equations is hyperbolic for the range of materials and impact velocities of interest. High-order accurate ENO shock-capturing schemes are used along with interface tracking techniques to evolve sharp immersed boundaries. The numerical technique is designed to tackle the following physical phenomena encountered during impact: (1) high velocities of impact leading to large deformations of the impactor as well as targets; (2) nonlinear wave-propagation and the development of shocks in the materials; (3) modeling of the constitutive properties of materials under intense impact conditions and accurate numerical calculation of the elasto-plastic behavior described by the models; (4) phenomena at multiple interfaces (such as impactor-target, target-ambient and impactor-ambient), i.e. both free surface and surface-surface dynamics. Comparison with Lagrangian calculations is made for the elasto-plastic deformation of solid material. The accuracy of convex ENO scheme for shock capturing, with the Mie-Gruneisen equation of state for pressure, is closely examined. Good agreement of the present finite difference fixed grid results is obtained with exact solutions in 1D and benchmarked moving finite element solutions for axisymmetric Taylor impact.
index560!@#@!1984!@#@!Gestaltungsanforderungen an die Mensch-Rechner-Schnittstellen aufgrund der Erkenntnisse &uuml;ber die menschliche Informationsverarbeitung!@#@!Proze&szlig;rechner 1984, Proze&szlig;datenverarbeitung im Wandel, 4. GI/GMR/KfK-Fachtagung!@#@!null
index561!@#@!1995!@#@!A General Framework for Building Patient Monitoring Systems!@#@!Proceedings of the 5th Conference on Artificial Intelligence in Medicine in Europe: Artificial Intelligence Medicine!@#@!null
index562!@#@!2000!@#@!The support tool for highly reliable component-based software development!@#@!Proceedings of the Seventh Asia-Pacific Software Engineering Conference!@#@!We discuss a support tool for highly reliable component-based software development. The tool assures the high reliability of the output by verifying refinement and by generating connectors. The advantages of the tool are automated refinement verification and automated connector generation. As a software architecture for component-based software, we select the tree architecture, in which components are represented by a projection-style behavioral specification. The input of the tool is: (a) a requirement specification of the target software, (b) a refined specification specifying how to combine the components, and (c) the components themselves. (a) and (b) are projection-style behavioral specifications, while (c) are JavaBeans. The output of the tool is JavaBeans that are obtained by combining (c) and the generated connectors.
index563!@#@!1999!@#@!Applying the Davis-Putnam Procedure to Non-clausal Formulas!@#@!Proceedings of the 6th Congress of the Italian Association for Artificial Intelligence on Advances in Artificial Intelligence!@#@!null
index564!@#@!1994!@#@!Semantic Tableaux with Ordering Restrictions!@#@!Proceedings of the 12th International Conference on Automated Deduction!@#@!null
index565!@#@!2002!@#@!Haptic Volume Interaction with Anatomic Models at Sub-Voxel Resolution!@#@!Proceedings of the 10th Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems!@#@!In this paper, a new approach for haptic volume interaction with high resolution voxel-based anatomic models is presented. The haptic rendering is based on a multi-point collision detection approach which provides realistic tool interaction with the models. Both haptics and graphics are rendered at sub-voxel resolution, which leads to a high level of detail and enables the exploration of the models at any scale. Forces are calculated at an update rate of 6000 Hz and sent to a 3-Degree-of-Freedom (3-DOF) force-feedback device. Compared to point-based haptic rendering, the unique approach of the multi-point collision detection in combination with sub-voxel rendering provides more realistic and very detailed haptic sensations. As a main application, a simulator for petrous bone surgery was developed. With a simulated drill, bony structure can be removed and the access path to the middle ear can be studied.
index566!@#@!2000!@#@!User-Interface Design for Medical Informatics: A Case Study of Kaiser Permanente!@#@!Proceedings of the 33rd Hawaii International Conference on System Sciences-Volume 5 - Volume 5!@#@!User interfaces (Uis) for client-server-and Web-based products and services must enable users around the world to access complex data and functions. Solutions to successful user-interface design, including information visualization, consist of partially universal and partially local solutions to the design of metaphors, mental models, navigation, appearance, and interaction. By managing the user's experience of familiar structures and processes, the user-interface designer can achieve compelling forms that enable the user interface to be more usable and acceptable to a wider range of users. The user will be more productive and satisfied with the product in many different locations globally. This article presents some guidelines for UI design and reviews the design of prototypes for Kaiser Permanente's Clinical Information System, with an emphasis on navigation and appearance improvements.
index567!@#@!2000!@#@!A Method for Trading off Test Time, Area and Fault Coverage in Datapath BIST Synthesis!@#@!Proceedings of the IEEE European Test Workshop!@#@!This paper presents a method for deriving a BIST specification from the initial specification of datapaths. This method minimizes BIST area overhead under test time constraint while guaranteeing a user chosen fault coverage. The designer can thus explore a wide range of solutions and keep the one that best fits with design constraints. Results show great improvements over lower level techniques.
index568!@#@!2003!@#@!Analytical solution of the Schrödinger equation for an electron confined in a triangle-shaped quantum well!@#@!Microelectronic Engineering!@#@!For the triangular-shaped quantum well, the electron wave functions and energy values are found by analytical solution of the Shrödinger equation. In approximation of impenetrable walls, two sets of solutions are obtained, one corresponding to the symmetric, and the other to antisymmetric wave functions. The distributions of the probability density give a clear picture of standing waves in a triangular-shaped plate. The comparison of the system energy levels with those obtained for quasi-periodic boundary conditions give reasonable coincidence. The results obtained proved to be useful in explanation of electronic optical absorption spectra of some of the organic colorants, on the basis of FEMO approach (free electron molecular orbitals); it could be used for other nanosystems with particles of triangular shape.
index569!@#@!1993!@#@!Projecting Sub-symbolic Onto Symbolic Representations in Artificial Neural Networks!@#@!Proceedings of the Third Congress of the Italian Association for Artificial Intelligence on Advances in Artificial Intelligence!@#@!null
index570!@#@!1998!@#@!Automated synthesis of large phase shifters for built-in self-test!@#@!Proceedings of the 1998 IEEE International Test Conference!@#@!The paper introduces a new algorithm for the automatedsynthesis of phase shifters - circuits used to remove effectsof structural dependencies featured by two-dimensionaltest generators. The algorithms presented in the papersynthesize in a time-efficient manner very large and fastphase shifters for built-in self-test environment, with guaranteedminimal phaseshifts between scan chains, and verylow delay and area of virtually one 2-way XOR gate perchannel.
index571!@#@!1993!@#@!Model Calculations of Protein-Water Systems anf of Long time Dynamics of Proteins!@#@!Informatik in den Biowissenschaften, 1. Fachtagung der GI-FG 4.0.3 "Informatik in den Biowissenschaften"!@#@!null
index572!@#@!2003!@#@!Statistical information approaches for the modelling of the epileptic brain!@#@!Computational Statistics &amp; Data Analysis!@#@!First, the theory of random process is linked with the statistical description of epileptic human brain process. A statistical information approach to the adaptive analysis of the electroencephalogram (EEG) is proposed. Then, the problem of time window recognition of the global stochastic model based upon Bayesian estimation and the use of global optimization for restricted experimental data are proposed. A robust algorithm for estimating unknown parameters of stochastic models is considered. The ability of nonlinear time-series analysis to extract features from brain EEG signal for detecting epileptic seizures is evaluated.
index573!@#@!1997!@#@!Test synthesis for DC test of switched-capacitors circuits!@#@!Proceedings of the 1997 European conference on Design and Test!@#@!Built-In Self Test (BIST) consists of integrating totally or partially a Test Pattern Generator (TPG) and/or a Response Analyzer (RA) in the same chip with the Circuit Under Test (CUT). Generally, an efficient analog test requires the monitoring of several performances by applying different frequencies as test stimuli. For BIST application, the integration of a frequency TPG and RA can not be economically viable for most applications because of their corresponding area overhead and complexity. BIST techniques based on frequency analysis are very expensive for the silicon area. On the other hand, BIST solutions based on a DC test remain poor concerning the fault coverage. This is true if no Design For Testability (DFT) elements are used in conjunction with a DC BIST to eliminate this problem. Exactly, our approach consists of using some DFT means so as all defects of SC circuits become detectable in the DC domain. Then a DC stimulus as an existing voltage source Vdd, Gnd and Vss corresponds to a simple TPG while the RA is a small window comparator. Finally, the addition of these DFT elements allows to decrease considerably the DC BIST hardware and corresponds in fact to a tradeoff between BIST complexity and DFT resources. With this mixed BIST/DFT technique we obtain a comparable fault coverage than frequency based approaches and this for a lower hardware cost.
index574!@#@!2003!@#@!A model for housing allocation of a homeless population due to a natural disaster!@#@!Nonlinear Analysis: Real World Applications!@#@!In the present work we derive and analyze a model considering housing allocation of homeless families due to a natural disaster; we use data from the earthquake of September 1999, in Athens, Greece. We derive a non-linear system of ordinary differential equations and analyze the stability of this system. Also we find an approximate solution of the model for a case study as well as and a numerical solution. Finally we consider possible extensions and improvements of the model making it more realistic.
index575!@#@!2003!@#@!In the News!@#@!IEEE Intelligent Systems!@#@!This issue offers two reports: "E-Voting: Should We Pull the Lever?" by Adam Stone and "Globalization Drives Changes in Software Careers" by Terry Costlow.
index576!@#@!2003!@#@!Augmented reality for manufacturing planning!@#@!Proceedings of the workshop on Virtual environments 2003!@#@!The shortening of development cycles demand for efficient methods and tools for the planning of complex production systems. Recently immersive Virtual Reality technologies have been introduced to the manufacturing planning functions. This has lead to a decrease in planning times as well as to the improvement of the quality of planning results. The introduction of various virtual planning tools is targeting the complete integration of all planning tasks and demands an intuitive interaction with complex computer models of machinery, factory-layouts etc. Known methods and tools are limited to a purely virtual representation of planning objects and thus require the complete modeling of the production system. The high costs reduce the possible benefits of these tools and this technology in general. New potential for the improvement of the industrial planning process are offered by the AR-technology. Using AR-techniques an physically existing production environment can be superimposed with virtual planning objects. Planning tasks can thus be validated without modeling the surrounding environment of the production site. In this contribution we discuss the support of manufacturing planning tasks with the Augmented Reality technology. We present potential benefits and describe the development of an prototypical AR-System for the support of planning tasks.
index577!@#@!2002!@#@!Career coach!@#@!Network Computing!@#@!null
index578!@#@!2002!@#@!Abstracts for the 2001 Transportation Science Section Dissertation Prize Competition!@#@!Transportation Science!@#@!null
index579!@#@!1999!@#@!Accelerating an IR Automatic Target Recognition Application with FPGAs!@#@!Proceedings of the Seventh Annual IEEE Symposium on Field-Programmable Custom Computing Machines!@#@!This two-page paper briefly describes the acceleration of an infrared automatic target recognition (IR ATR) application with an FPGA co-processor board, a Giga Operations' G900 board. The application of the IR ATR program which contains multiple rounds of computation is to locate and identify ground vehicles based on a single IR image frame. An FPGA design is developed for the first round which is the most time consuming part. The design explores parallelism at several levels. The achieved performance is reported and analyzed at the end.
index580!@#@!2003!@#@!The Web services debate: J2EE vs. .NET!@#@!Communications of the ACM!@#@!As the articles in this section attest, the future of Web services is as certain as it is unclear. That is, the Web services arena is most certainly the next technological wave; what is not so clear is what direction (of many) that wave will flow. The challenge of selecting the tools to successfully pull all the components together is particularly daunting.
index581!@#@!2002!@#@!Numerical solution of dynamic optimization problems with flexible inequality constraints by iterative dynamic programming!@#@!Fuzzy Sets and Systems!@#@!A solution strategy for optimizing the dynamic systems with flexible inequality constraints is proposed. To apply fuzzy inference in solution, the flexible portion in the problem is treated as fuzzy constraints. After functional values are bounded in a region, the objective function of this problem can also be fuzzified easily. When the problem is formulated as a fuzzy dynamic optimization problem, the iterative dynamic programming integrated with fuzzy inference is adopted to find the solution. Two examples are employed, demonstrating the facility of the proposed algorithm.
index582!@#@!1998!@#@!Vision and Graphics in Producing Mixed Reality Worlds!@#@!CVVRHC!@#@!This paper introduces prominent topics of our Mixed Reality (MR) project and states what kind of role computer vision and graphics play in the project. MR is a part of VR in broader sense, but it treats the physical space as well as the virtual space created in computers. Here we use the term "mixed reality" instead of often used "augmented reality (AR)." This is because MR is not only the mixture of real world and virtual world but also the mixture of AR and "augmented virtuality (AV)." In that sense, we first describe that there is no clear distinction between AR and AV, then introduce some research results at the early stage of our MR project.
index583!@#@!1997!@#@!Some Pitfalls of LK-to-LJ Translations and How to Avoid Them!@#@!Proceedings of the 14th International Conference on Automated Deduction!@#@!null
index584!@#@!2003!@#@!Clock-tree power optimization based on RTL clock-gating!@#@!Proceedings of the 40th annual Design Automation Conference!@#@!As power consumption of the clock tree in modern VLSI designs tends to dominate, measures must be taken to keep it under control. This paper introduces an approach for reducing clock power based on clock gating. We present a methodology that, starting from an RTL description, automatically generates a set of constraints for driving the construction of the clock tree by the clock synthesis tool. The methodology has been fully integrated into an industry-strength design flow, based on Synopsys DesignCompiler (front-end) and Cadence Silicon Ensemble (back end). The power savings achieved on some industrial examples show that, when the size of the circuits is significant, savings on the power consumption of the clock tree are up to 75% larger than those achieved by applying traditional clock gating at the clock inputs of the RTL modules of the designs.
index585!@#@!1997!@#@!An Optimal-Joint-Coordinate Block Matching Algorithm for Motion-Compensated Coding!@#@!Proceedings of the  Conference on Data Compression!@#@!null
index586!@#@!2002!@#@!Visual Clustering of Trademarks Using the Self-Organizing Map!@#@!Proceedings of the International Conference on Image and Video Retrieval!@#@!null
index587!@#@!2002!@#@!Micro-architecture design and control speculation for energy reduction!@#@!Power aware computing!@#@!Conventional wisdom states that the best way to design an energy-efficient microprocessor is to design it for high performance, since a high performance processor will complete a task quicker than an energy-conscious design. However, our research group has found ways to reduce energy without impacting performance by controlling the amount of speculation used by the processor in its quest for performance.
index588!@#@!1995!@#@!Software Process Improvement Paradigms for IT Industry: Why the Bottom-Up Approach Fits Best!@#@!Proceedings of the Second Asia Pacific Software Engineering Conference!@#@!null
index589!@#@!1998!@#@!Process Capability in the Australian Software Industry - Results from the SPICE Trials!@#@!Proceedings of the Australian Software Engineering Conference!@#@!null
index590!@#@!1995!@#@!Performance analysis and FTF version of the generalized sliding window recursive least-squares (GSWRLS) algorithm!@#@!ASILOMAR!@#@!We derive a new RLS algorithm: the generalized sliding window RLS (GSWRLS) algorithm and its fast numerically stabilized version: the GSW SFTF algorithm. The generalised window used consists of an exponential decay with base /spl lambda/ for the first L lags, a decrease by a factor 1-/spl alpha/ at lag L, and a further exponential decay with base /spl lambda/ beyond lag L. The exponential and rectangular windows are special cases of the generalized window. We analyze the steady-state excess mean squared error components due to the estimation noise and lag noise with different models for the time-varying optimal filter coefficients. This analysis shows that the exponential window performs better than the rectangular window, but also that the optimal generalized windows performs even better.
index591!@#@!1999!@#@!Tractable Average-Case Analysis of Naive Bayesian Classifiers!@#@!Proceedings of the Sixteenth International Conference on Machine Learning!@#@!null
index592!@#@!1991!@#@!Erkennen von Ger&auml;uschmustern mittels Neuronaler Netze!@#@!Mustererkennung 1991, 13. DAGM-Symposium!@#@!null
index593!@#@!1992!@#@!Fast Read-Only Transactions in Replicated Databases!@#@!Proceedings of the Eighth International Conference on Data Engineering!@#@!null
index594!@#@!2002!@#@!Embedded Software: How To Make It Efficient?!@#@!Proceedings of the Euromicro Symposium on Digital Systems Design!@#@!This paper stresses the importance of designing efficient embedded software and it provides a global view of some of the techniques that have been developed to meet this goal. These techniques include high-level transformations, compiler optimizations reducing the energy consumption of embedded programs and optimizations exploiting architectural features of embedded processors. Such optimizations lead to significant reductions of the execution time, the required energy and the memory size of embedded applications. Despite this, they can hardly be found in any available compiler.
index595!@#@!2003!@#@!Stationary Distributions of GI/M/c Queue with PH Type Vacations!@#@!Queueing Systems: Theory and Applications!@#@!We study a GI/M/c type queueing system with vacations in which all servers take vacations together when the system becomes empty. These servers keep taking synchronous vacations until they find waiting customers in the system at a vacation completion instant.The vacation time is a phase-type (PH) distributed random variable. Using embedded Markov chain modeling and the matrix geometric solution methods, we obtain explicit expressions for the stationary probability distributions of the queue length at arrivals and the waiting time. To compare the vacation model with the classical GI/M/c queue without vacations, we prove conditional stochastic decomposition properties for the queue length and the waiting time when all servers are busy. Our model is a generalization of several previous studies.
index596!@#@!2002!@#@!Evidence of predictability in financial markets!@#@!Neural networks and the financial markets: predicting, combining and portfolio optimisation!@#@!null
index597!@#@!2002!@#@!Legal aspects of KDD: privacy!@#@!Handbook of data mining and knowledge discovery!@#@!The concept of privacy encompasses various claims by individuals over whether information about them is communicated to others. Knowledge discovery is extending these claims to whether such information is even created. Privacy statutes can be divided into context-specific laws (more common in the United States), often aimed at specific technologies or industries, and omnibus legislation (more common elsewhere), usually based on the principles of fair information practices. Some of these principles may conflict with goals for data mining projects. Such projects should be guided by a coherent privacy strategy maintained by the organization.
index598!@#@!1992!@#@!Eine Methode zur schnellen Segmentierung von Tiefenbildern in planare Regionen!@#@!Mustererkennung 1992, 14. DAGM-Symposium!@#@!null
index599!@#@!2002!@#@!A Stochastic Optimal Control Approach to Real-time, Incident-Responsive Traffic Signal Control at Isolated Intersections!@#@!Transportation Science!@#@!Real-time, incident-responsive traffic control and management is vital to development of advanced incident management systems in ITS. More importantly, it provides, from an academic point of view, the linkages between incident detection, incident management, and traffic signal control. This study explores the application of a stochastic optimal control approach to real-time, incident-responsive traffic control at isolated intersections. In the methodology development, time-varying lane traffic state variables and control variables are specified to characterize sectionwide interlane and intralane traffic states under conditions of lane-blocking incidents. Following specification of system states, we formulated a discrete-time nonlinear stochastic model that comprises four types of equations, namely (1) recursive equations, (2) measurement equations, (3) incident-induced delay equations, and (4) boundary constraints. From the proposed stochastic model we then developed a stochastic optimal control algorithm to update the time-varying control variables and lane traffic state variables in real-time with lane-blocking incidents at isolated intersections. To generate traffic data used in model tests efficiently, we employed an advanced microscopic traffic simulator, Paramics, Version 3.0, which is developed to model and analyze ITS traffic flow conditions. The preliminary test results indicate that the proposed method can accomplish the goal of real-time, incident-responsive traffic signal control. In addition to proposing a new methodology, we hope that this study can initiate investigation into real-time, incident-responsive traffic control and management to achieve the final goal of networkwide incident-responsive, traffic-optimal control for incident management.
index600!@#@!1992!@#@!Programming with Equations: A Framework for Lazy Parallel Evaluation!@#@!Proceedings of the 11th International Conference on Automated Deduction: Automated Deduction!@#@!null
index601!@#@!1992!@#@!M(DM): An Open Framework for Interoperation of Multimodel Multidatabase Systems!@#@!Proceedings of the Eighth International Conference on Data Engineering!@#@!null
index602!@#@!2000!@#@!Learning response time for WebSources using query feedback and application in query optimization!@#@!The VLDB Journal &mdash; The International Journal on Very Large Data Bases!@#@!The rapid growth of the Internet and support for interoperability protocols has increased the number of Web accessible sources, WebSources. Current wrapper mediator architectures need to be extended with a wrapper cost model (WCM) for WebSources that can estimate the response time (delays) to access sources as well as other relevant statistics. In this paper, we present a Web prediction tool (WebPT), a tool that is based on learning using query feedback from WebSources. The WebPT uses dimensions time of day, day, and quantity of data, to learn response times from a particular WebSource, and to predict the expected response time (delay) for some query. Experiment data was collected from several sources, and those dimensions that were significant in estimating the response time were determined. We then trained the WebPT on the collected data, to use the three dimensions mentioned above, and to predict the response time, as well as a confidence in the prediction. We describe the WebPT learning algorithms, and report on the WebPT learning for WebSources. Our research shows that we can improve the quality of learning by tuning the WebPT features, e.g., training the WebPT using a logarithm of the input training data; including significant dimensions in the WebPT; or changing the ordering of dimensions. A comparison of the WebPT with more traditional neural network (NN) learning has been performed, and we briefly report on the comparison. We then demonstrate how the WebPT prediction of delay may be used by a scrambling enabled optimizer. A scrambling algorithm identifies some critical points of delay, where it makes a decision to scramble (modify) a plan, to attempt to hide the expected delay by computing some other part of the plan that is unaffected by the delay. We explore the space of real delay at a WebSource, versus the WebPT prediction of this delay, with respect to critical points of delay in specific plans. We identify those cases where WebPT overestimation or underestimation of the real delay results in a penalty in the scrambling enabled optimizer, and those cases where there is no penalty. Using the experimental data and WebPT learning, we test how good the WebPT is in minimizing these penalties.
index603!@#@!1998!@#@!The Impact of Joint Venture Status on the Longevity of Japanese Stakes in U.S. Manufacturing Affiliates!@#@!Organization Science!@#@!A number of well-known studies report that between one-third and two-thirds of international joint ventures eventually break up. While many generalizations, explanations, and prescriptions have been based on these statistics, their meaning is unclear. First, all foreign affiliates are subject to normal business risk, and to the risk that they will be divested by parents for strategic or financial reasons. Are these risks higher for joint ventures than for wholly-owned subsidiaries? Second, joint ventures may be shorter lived not because of their joint venture status, but because affiliates which are joint ventured have other characteristics that make them more likely to exit. To know whether joint ventures are shorter lived, one must control for the other factors that affect the longevity of affiliates, whether wholly owned or joint ventured. Third, many joint ventures contracts contain clauses that allow partners to sell their stakes to one another at specific intervals. Because they make exit easier, joint ventures should have shorter lives, but these shorter lives should only be due to sell-offs, not to liquidations. It is therefore important to see whether the supposedly higher termination rate of joint ventures stakes is due to a higher rate of selloffs or to a higher rate of liquidations. In this paper we (1) compare the longevity of stakes in joint ventures versus those in wholly-owned subsidiaries (2) while controlling for other factors that affect the longevity of such stakes and (3) while distinguishing between two types of exit, those through sale and those through liquidation. While past authors have addressed these three issues in piecemeal fashion, we believe we are the first to address them simultaneously. We analyze the factors that affect the longevity of 355 Japanese stakes in U.S. manufacturing affiliates. Controlling for all the factors that affect exit rates, we find that Japanese parents are more likely to terminate their stakes in U.S. joint ventures than in wholly-owned subsidiaries. This higher termination rate of joint venture stakes is explained by a higher probability of selling them, but not of liquidating them. Most of the other factors that have been found significant in explaining gross divestment of foreign affiliates do in fact only affect exits through sales, but not exits through liquidations. Hence it is true that joint ventures have shorter lives, but dangerous to interpret this finding as necessarily meaning that they are more likely to "fail".
index604!@#@!1998!@#@!Conceptual Design of Data Warehouses from E/R Schema!@#@!Proceedings of the Thirty-First Annual Hawaii International Conference on System Sciences-Volume 7 - Volume 7!@#@!Data warehousing systems enable enterprise managers to acquire and integrate information from heterogeneous sources and to query very large databases efficiently. Building a data warehouse requires adopting design and implementation techniques completely different from those underlying information systems. In this paper we present a graphical conceptual model for data warehouses, called Dimensional Fact model, and propose a semi-automated methodology to build it from the pre-existing Entity/Relationship schemes describing a database. Our conceptual model consists of tree-structured fact schemes whose basic elements are facts, attributes, dimensions and hierarchies; other features which may be represented on fact schemes are the additivity of fact attributes along dimensions, the optionality of dimension attributes and the existence of non-dimension attributes. Compatible fact schemes may be overlapped in order to relate and compare data. Fact schemes may be integrated with information of the conjectured workload, expressed in terms of query patterns, to be used as the input of a design phase whose output are the logical and physical schemes of the data warehouse.
index605!@#@!2001!@#@!Performance Evaluation of an Agent-Based Resource Management Infrastructure for Grid Computing!@#@!Proceedings of the 1st International Symposium on Cluster Computing and the Grid!@#@!Resource management is an important infrastructure in the grid computing environment. Scalability and adaptability are two key challenges in the implementation of such complex software systems. In this work we introduce a new model for resource management in a metacomputing environment using a hierarchy of homogeneous agents that has the capability of service discovery. The performance of the agent system can be improved using different combinations of optimisation strategies. A modelling and simulation environment has been developed in this work that enables the performance of the system to be investigated. A simplified model of the resource management infrastructure is given as a case study and simulation results are included that show the impact of the choice of performance optimisation strategies on the overall system performance.
index606!@#@!2001!@#@!Facial Expression Recognition Approach For Performance Animation!@#@!Proceedings of the Second International Workshop on Digital and Computational Video!@#@!We attempt a performance animation approach that makes use of facial expression recognition technique.Our approach consists of two steps.First,we identify the performer's facial expressions from the input image sequence,using a method that is modified from the well-known eigenface method but here not for recognizing face but for recognizing expression.Second,we use the recognition result to initiate the change of facial expressions in the animated character.Since eigen-method based system requires only the intensity maps not distinct features on the images to work,the intrusive makeup of the human performer and the feature extraction process needed in the current performance animation approaches are no longer needed.The implicity in matching the input images with the database images for various facial expressions allows the system to be suitable for near-real-time application.In addition,in contrast with the current approaches that map facial dynamics directly from the human performer to the animated character,our approach could be used to drive any animated character,human-like or not.
index607!@#@!1995!@#@!30-ns 55-b Radix 2 Division and Square Root Using a Self-Timed Circuit!@#@!ARITH!@#@!A shared radix 2 division and square root implementation using a self-timed circuit is presented. The same execution time for division and square root is achieved by using an on-the-fly digit decoding and a root multiple generation technique. Most of the hardware is shared, and only several multiplexers are required to exchange a divisor multiple and a root multiple. Moreover, quotient selection logic is accelerated by a new algorithm using a 3-b carry propagation adder. The implementation of the shared division and square root unit is realized by assuming 0.3um CMOS technology. The wiring capacitance and other parasitic parameters are taken into account. The execution time of floating point 55-b full mantissa division and square root is expected to be less than 30ns in the worst case of an input vector determined by an intensive circuit simulation.
index608!@#@!1997!@#@!Is the Apparent Self-Similarity of the Broadband Traffic Due to Non Stationarity?!@#@!Proceedings of the IFIP TC6 WG6.3/WG6.4 Fifth International Workshop on Performance Modelling and Evaluation of ATM Networks: Performance Analysis of ATM Networks!@#@!null
index609!@#@!2002!@#@!Corrigendum: New Selection Procedures!@#@!Operations Research!@#@!null
index610!@#@!2002!@#@!Science: gene expression analysis!@#@!Handbook of data mining and knowledge discovery!@#@!Every cell contains all the information necessary to grow, divide, and respond correctly to its environment. The DNA sequence that holds this information is already known for many organisms, and a canonical draft DNA sequence was known for humans by the end of 2000. With this sequence information, biology is poised to enter an era of massively accelerated data collection to elucidate the mechanisms of life and the ailments that result when these mechanisms fail. High-throughput gene expression detection and analysis depends on this genomic information and yields unprecedented amounts of data about the molecular mechanisms that regulate a cell's behavior. Thus, gene expression analysis exemplifies how knowledge discovery techniques are being applied to gene discovery in biology and pharmacological research. This case study will describe what gene expression is, ways in which this data is currently analyzed, and the challenges remaining for effectively deriving biological knowledge from large sets of gene expression data.
index611!@#@!2002!@#@!Evaluation of a decision support system for the useful application of hazardous wastes with means of immobilisation-techniques!@#@!Development and application of computer techniques to environmental studies!@#@!In the Netherlands, dumping of hazardous wastes on a landfill is discouraged. On the other hand, the Building Material Decree set standards to building materials in order to protect surface-, groundwater and soil from the leaching of hazardous components. Moreover, the government intends to minimise the use of primary materials. Therefore, new applications of hazardous wastes are needed. The most promising is Stabilisation/Solidification, sometimes called immobilisation.Immobilisation-techniques are defined as changing the physical and chemical state of a hazardous wastes in order to reduce the leaching of hazardous components. Despite financial incentives, few applications of immobilised wastes are known. Therefore, a Decision Support System (DSS) is necessary to calculate the impact of the immobilised waste on the environment. A DSS has been developed and evaluated for a case with contaminated soil and residues from inorganic industry.The first criterion of the DSS is called long term behaviour and aims at minimising the release of hazardous compounds in relation to external influences and material properties. The second criterion, environmental load focuses at consumption of (non)renewable natural resources. The third criterion is financial consequences, which calculates the overall costs and incomes during the life cycle with respect to all stakeholders.
index612!@#@!1997!@#@!Learning noisy perceptrons by a perceptron in polynomial time!@#@!Proceedings of the 38th Annual Symposium on Foundations of Computer Science!@#@!Learning perceptrons (linear threshold functions) from labeled examples is an important problem in machine learning. We consider the problem where labels are subjected to random classification noise. The problem was known to be PAC learnable via a hypothesis that consists of a polynomial number of linear thresholds (due to A. Blum, A. Frieze, R. Kannan, and S. Vempala (1996)). The question of whether a hypothesis that is itself a perceptron (a single threshold function) can be found in polynomial time was open. We show that indeed, noisy perceptrons are PAC learnable with a hypothesis that is a perceptron.
index613!@#@!2002!@#@!GuiGen: a toolset for creating customized interfaces for grid user communities!@#@!Future Generation Computer Systems!@#@!GuiGen is a comprehensive set of tools for creating customized graphical user interfaces (GUIs). It draws from the concept of computing portals, which are here seen as interfaces to application-specific computing services for user communities. While GuiGen was originally designed for the use in computational grids, it can be used in client/server environments as well.Compared to other GUI generators, GuiGen is more versatile and more portable. It can be employed in many different application domains and on different target platforms. With GuiGen, application experts (rather than computer scientists) are able to create their own individually tailored GUIs.
index614!@#@!2000!@#@!A Management Framework for Accelerating Change!@#@!Proceedings of the 1st Austin Workshop On Engineering Management In Technology-Base Organizations!@#@!The petrochemical industry has been characterized by a rapid evolution of technology.This includes production technology such as new catalyst and unit operations as well as the support systems such as advanced simulators, business-wide optimization, ande-commerce linkages.Overlaid on these advance are the people changes induced by merger and restructuring.Traditional organizational conflicts such as short versus long term tradeoffs and creativity versus control and discipline are aggravated. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player
index615!@#@!1999!@#@!Adaptive Target Recognition!@#@!Proceedings of the IEEE Workshop on Computer Vision Beyond the Visible Spectrum: Methods and Applications!@#@!Target recognition is a multi-level process requiring a sequence of algorithms at low, intermediate and high levels. Generally, such systems are open loop with no feedback between levels and assuring their performance at the given Probability of Correct Identification (PCI) and Probability of False Alarm (Pf) is a key challenge in computer vision and pattern recognition research. In this paper a robust closed-loop system for recognition of SAR images based on reinforcement learning is pre- sented. The parameters in the model-based SAR target recognition are learned. The method meets performance specifications by using PCI and Pf as feedback for the learning system. It has been experimentally validated by learning the parameters of the recognition system for SAR imagery, successfully recognizing articulated targets, targets of different configuration and targets of different depression angles.
index616!@#@!2002!@#@!Complex Data: Mining Using Patterns!@#@!Proceedings of the ESF Exploratory Workshop on Pattern Detection and Discovery!@#@!null
index617!@#@!1991!@#@!An Efficient Context-Free Parsing Algorithm with Semantic Actions!@#@!Proceedings of the 2nd Congress of the Italian Association for Artificial Intelligence on Trends in Artificial Intelligence!@#@!null
index618!@#@!2002!@#@!Introduction to parallel processing!@#@!Practical parallel rendering!@#@!null
index619!@#@!1996!@#@!A Multi-Level Transformation Approach to HW/SW Codesign: A Case Study!@#@!Proceedings of the 4th International Workshop on Hardware/Software Co-Design!@#@!This reported work applies a transformational synthesis approach to hardware/software codesign. In this approach, the process of algorithm design is coupled early on with hardware design to allow for a complete design space exploration. Both the specification and the transformation mechanisms are encoded in a functional notation, called form, which facilitates algorithmic derivation, structural transformation and verification. In the algorithmic derivation phase, possible computational schedules for a given application function are generated from a partial specification of the target architecture. At the hardware level, structural transformations are applied to explore possible datapath designs, where different designs yield different performance and cost. Other design metrics such as interface buffer size, software code size and data size etc. are also included to determine analytically a hardware/ software partition.
index620!@#@!1981!@#@!Hierarische Kombination eines strukturellen und numerischen Verfahrens zur Erkennung und Lagebestimmmung &uuml;berlappender Werkst&uuml;cke!@#@!Modelle und Strukturen, DAGM Symposium!@#@!null
index621!@#@!2001!@#@!Time in Connectionist Models!@#@!Sequence Learning - Paradigms, Algorithms, and Applications!@#@!null
index622!@#@!1999!@#@!Preface!@#@!Automated Software Engineering!@#@!This special double issue of Mathematical Structures in Computer Science is in honour of Roger Hindley and is devoted to the topic of lambda-calculus and logic.It is a great pleasure for us to greet Roger Hindley on the occasion of his retirement from the University of Wales, Swansea, and his 60th birthday. We have known Roger for many years and we have had the chance to collaborate with him and appreciate his intellectual standard, his remarkable mathematical rigor, and his inexhaustible sense of humour. This has enabled Roger to step back critically even in the face of a difficult mathematical task and help to solve it by a new way of looking at it.Roger Hindley's dissertation concerned the Church&ndash;Rosser Theorem and was a significant contribution to the topic. His subsequent work spanned many aspects of lambda-calculus, covering both its models and applications. To mention just a few, he produced work on axioms for Curry's strong (eta) reduction, comparing lambda and combinatory reductions (and models), models for type assignment, and formulas as types for some nonstandard systems (intersection types, BCK systems, etc.).Roger Hindley collaborated with Jonathan Seldin on two well-known introductory books on the subject (Bruce Lercher also collaborated as an author on the first of these). More recently, he has published an introduction to type assignment. He was also co-author with H. B. Curry and J. Seldin on Combinatory Logic, vol. II, which is an important research publication on the subject.Roger has played an important role in the lambda-calculus community over the years as that community has grown; in particular, he has been an active organiser of many conferences on the topic. In fact, his success in disseminating knowledge about the lambda calculus, particularly in the United Kingdom, means that Roger may be considered a &lsquo;Godfather&rsquo; of ML and its type system.(In preparing this special issue of Mathematical Structures in Computer Science, we have been fortunate enough to receive too many excellent papers for one double issue. As a result, additional papers by colleagues who wish to honour Roger will appear in future issues of this journal.)
index623!@#@!2003!@#@!Delay Performance Analysis for the Buffered Crossbar Switch!@#@!Proceedings of the 17th International Conference on Advanced Information Networking and Applications!@#@!The buffered crossbar switch is a combination of crossbar-based switch architecture and combined input and output queueing scheme. It is promising to achieve good performance without complex implementation. In this paper, we apply network calculus technique to study the delay performance of the buffered crossbar switch. We setup a service curve-based model for the path through which a flow traverses the buffered crossbar switch. Based on thismodel, we develop a technique that can determine the end-to-end service curve guaranteed to a flow and calculate the delay upper bound of this flow. Then we analyze the determining factors of this delay bound performance.
index624!@#@!2000!@#@!History based distributed filtering - a tagging approach to network-level access control!@#@!Proceedings of the 16th Annual Computer Security Applications Conference!@#@!Discusses a network-level access control technique that applies the non-discretionary access control model to individual data packets that are exchanged between hosts or subnets. The proposed technique examines the incoming data's integrity properties to prevent applications within a node or subnetwork from so-called subversive channels. It checks outgoing data's secrecy requirements before transmission. Security labels are used to identify data packets as members of different categories and security levels. Additional tags store context information to validate the trustworthiness of a packet's content. Labels and tags of a data packet reflect events that may be relevant to access control throughout its life. As opposed to stateful filtering, which is based on the history of a flow of packets, our approach works on the history of an individual packet. Any state information is part of the packet rather than being stored in all the nodes inspecting the packet; i.e. nodes do not need to create and maintain state information.
index625!@#@!2003!@#@!The AAAI-2002 mobile Robot competition and exhibition!@#@!AI Magazine!@#@!The Eleventh Annual AAAI Robot Competition and Exhibition was held at the National Conference on Artificial Intelligence in Edmonton, Alberta, Canada, in August 2002. This article describes each of the events that were held: Robot Challenge, Robot Exhibition, Robot Host, and Robot Rescue.
index626!@#@!1996!@#@!A Model for Professional Training and Education within a Software Engineering Organization!@#@!Proceedings of the 9th Conference on Software Engineering Education!@#@!null
index627!@#@!1996!@#@!Using learned extraction patterns for text classification!@#@!Connectionist, Statistical, and Symbolic Approaches to Learning for Natural Language Processing!@#@!null
index628!@#@!1996!@#@!New Software Components with an Autonomous Changing Mechanism!@#@!Proceedings of the Third Asia-Pacific Software Engineering Conference!@#@!This paper presents software components, which are called ``active components'', with a mechanism for automatically and dynamically changing their codes. To create new programs, users must frequently modify software components because conventional components are fixed in libraries and user requirements are continuously changing. The active components can modify themselves into source codes that meet new requirements and that correspond to the characteristics of their existing libraries. The new mechanism provides two kinds of changes by: i) decomposing the functions of active components based on program slicing, and ii) partially exchanging their functions with modification histories in the libraries based on labeled graph matching for program dependence graphs. With this mechanism, the active components do not require many user modifications to create new programs, and not all components need to be prepared in the libraries whose characteristics are not specified. This paper also demonstrates the effects of this mechanism by describing experimental results obtained with the active components.
index629!@#@!2001!@#@!Higher-order unification and matching!@#@!Handbook of automated reasoning!@#@!null
index630!@#@!1996!@#@!Lexical Access using Minimum Message Length Encoding!@#@!Proceedings of the 4th Pacific Rim International Conference on Artificial Intelligence: Topics in Artificial Intelligence!@#@!null
index631!@#@!1993!@#@!Network Technology and Organizational Control: A Case Study of Decision Making and Industrial Relations in a Privatized Public Enterprise!@#@!Proceedings of the IFIP WG9.1 Working Conference on NetWORKing!@#@!null
index632!@#@!2001!@#@!Diagnosis of the Dynamics within an Organization by Trace Checking of Behavioural Requirements!@#@!Revised Papers and Invited Contributions from the Second International Workshop on Agent-Oriented Software Engineering II!@#@!null
index633!@#@!2003!@#@!A High Efficiency Equalization Used in OFDM!@#@!Proceedings of the 17th International Conference on Advanced Information Networking and Applications!@#@!In OFDM (Orthogonal Frequency Division Multiplexin) system, if the length of its cyclic prefixis larger than the delay spread of channel, we can get a simple frequency equalizer to demodulate OFDM signal. However, the use of cyclic prefix degrades the efficiency of transmission reatly. So, we give a new equalizing structure, which improve the efficiency oftransmission of OFDM system.
index634!@#@!2003!@#@!Inclusion in an electronic classroom: courseware accessibility design and implementation!@#@!Design and implementation of web-enabled teaching tools!@#@!Providing educational opportunities within online environments, while beneficial, also has the potential to exclude a significant portion of the population. Those who are learning and physically disabled may be prevented from accessing online learning environments due to problems in the design of the technology, as well as with the pedagogy directing the use of this technology. Inclusion in an Electronic Classroom was funded by the Office of Learning Technologies (OLT) and examined accessibility within various courseware platforms in order to better assess both the technological and pedagogical issues associated with the general educational shift toward providing learning opportunities within online learning networks. This paper presents a summary of the results of this study alongside recommendations for ensuring equitable access within online, courseware-enabled, networked learning. The study data are placed within a framework that examines the technical and pedagogical ramifications of accessibility issues and online learning environments, specifically, courseware environments currently used in today's online educational market. The findings are compared with the associated guidelines and checkpoints in the Web Content Accessibility Guidelines published by the Web Accessibility Initiative (WAI) of the World Wide Web Consortium (W3C) and provide a useful framework for consideration of the current challenges and the opportunities at hand for courseware authoring tool developers.
index635!@#@!2003!@#@!Multivariate nonparametric tests in a randomized complete block design!@#@!Journal of Multivariate Analysis!@#@!In this paper multivariate extensions of the Friedman and Page tests for the comparison of several treatments are introduced. Related unadjusted and adjusted treatment effect estimates for the multivariate response variable are also found and their properties discussed. The test statistics and estimates are analogous to the traditional univariate methods. In test constructions, the univariate ranks are replaced by multivariate spatial ranks (J. Nonparam. Statist. 5 (1995) 201). Asymptotic theory is developed to provide approximations for the limiting distributions of the test statistics and estimates. Limiting efficiencies of the tests and treatment effect estimates are found in the multivariate normal and t distribution cases. The tests are rotation invariant only, but affine invariant versions can be easily constructed. The theory is illustrated by an example.
index636!@#@!2003!@#@!Minimal sensor integrity: measuring the vulnerability of sensor grids!@#@!Information Processing Letters!@#@!Given the increasing importance of optimal sensor deployment for battlefield strategists, the converse problem of reacting to a particular deployment by an enemy is equally significant and not yet addressed in a quantifiable manner in the literature. We address this issue by modeling a two stage game in which the opponent deploys sensors to cover a sensor field and we attempt to maximally reduce his coverage at minimal cost. In this context, we introduce the concept of minimal sensor integrity which measures the vulnerability of any sensor deployment. We find the best response by quantifying the merits of each response. While the problem of optimally deploying sensors subject to coverage constraints is NP-complete [Chakrabarty et al., IEEE Trans. Comput., to appear], in this paper we show that the best response (i.e., the maximum vulnerability) can be computed in polynomial time for sensors with arbitrary coverage capabilities deployed over points in any dimensional space. In the special case when sensor coverages form an interval graph (as in a linear grid), we describe a better O(min(M2, NM)) dynamic programming algorithm.
index637!@#@!2003!@#@!c-Extensions of the F4(2)-building!@#@!Discrete Mathematics!@#@!We construct four geometries E1,...,E4 with the diagram such that any two elements of type 1 are incident to at most one common element of type 2 and three elements of type 1 are pairwise incident to common elements of type 2 if and only if they are incident to a common element of type 5. The automorphism group Ei of Ei is flag-transitive, isomorphic to 2E6(2) : 2, 3.2 E6(2):2, 226 :F4(2) and E6(2):2, for i = 1, 2, 3 and 4. We calculate the suborbit diagram of the collinearity graph of Ei with respect to the action of Ei. By considering the elements in Ei fixed by a subgroup Ti of order 3 in Ei we obtain four geometries J1,...,j4 with the diagram on which CE i(Ti) induces flag-transitive action, isomorphic to U6(2):2, 3.U6(2):2, 214 :Sp6(2) and L6(2):2 for i = 1,2,3 and 4. Next, by considering the elements fixed by a subgroup Si of order 7 in Ei we obtain four geometries with the diagram on which CEi(Si) induces flag-transitive action isomorphic to L3(4):2, 3 .L3(4):2, 28 :L3(2) and (L3(2) × L3(2)):2, for i = 1,2,3 and 4.
index638!@#@!2000!@#@!Low Cost Concurrent Test Implementation for Linear Digital Systems!@#@!Proceedings of the IEEE European Test Workshop!@#@!An implementation of a low-cost, time-extended invariant-based concurrent test scheme for linear digital systems is presented. Both feedback and non-feedback systems are analyzed to identify gate and RT level implementation requirements for high on-line fault coverage. Simulation results on implementations satisfying the outlined requirements indicate that low latency, 100% on-line fault coverage is attained within hardware costs comparable to those of scan insertion.
index639!@#@!2003!@#@!Fusion of multiple classifiers for intrusion detection in computer networks!@#@!Pattern Recognition Letters!@#@!The security of computer networks plays a strategic role in modern computer systems. In order to enforce high protection levels against threats, a number of software tools have been currently developed. Intrusion Detection Systems aim at detecting intruders who elude "first line" protection. In this paper, a pattern recognition approach to network intrusion detection based on the fusion of multiple classifiers is proposed. Five decision fusion methods are assessed by experiments and their performances compared. The potentialities of classifier fusion for the development of effective intrusion detection systems are evaluated and discussed.
index640!@#@!1999!@#@!Minimizing the Number of Programming Steps for Diagnosis of Interconnect Faults in FPGAs!@#@!Proceedings of the 8th Asian Test Symposium!@#@!This paper presents a procedure to diagnose single faults in SRAM Based FPGAs. The procedure is non-adaptive and requires six programming steps to give the ex-act position and type of any single fault in a FPGA. It is proved that the number of programming steps required for the procedure is minimal for a non-adaptive procedure with the given interconnect model.
index641!@#@!2000!@#@!Layering boundary protections: an experiment in information assurance!@#@!Proceedings of the 16th Annual Computer Security Applications Conference!@#@!The DARPA Information Assurance Program has the aim of developing and executing experiments that test specific hypotheses about defense in depth and dynamic defense capabilities. This paper describes the development and execution of an experiment in layering. The basic hypothesis was that layers of defense, when added in a careful and systematic way to a base system lead to increased protection against attacks on the system. For the particular experiment, a mission and broad policy were defined and a base system was developed to support the mission and the policy. The boundary controller for the system was designed and developed as a series of layers; these elements became the main focus of experimentation on layering. The results tended to confirm the experimental hypothesis that layers have a cumulative effect on protection against outside attacks. However, there are often other opportunities for attackers to go around the layers or avoid them altogether. A broader methodological result was that the entire process of developing experiments needs to be carefully thought through. In addition, the experimental data resulting from this experiment provide only a limited corroboration for the given experimental hypothesis.
index642!@#@!1997!@#@!Characterizing Images Based on Lines for Image Indexing!@#@!Computer Graphics International!@#@!Recent advances in multimedia has necessitated us to look for an effective search method of images. Most of the contemporary indexing methods are based on color distribution in the images. When the users do not remember the colors clearly, however, it has been difficult to retrieve the desired images. The paper proposes an indexing method based on shapes contained in an image. We characterize an image by the half planes that contain the objects in it. We also propose a method to characterize images by the vanishing points of parallel lines contained in an image. The vanishing points represent how three dimensional (3D) objects are projected onto the 2D image.
index643!@#@!2002!@#@!Proceedings of the 10th Symposium on Haptic Interfaces for Virtual Environment and Teleoperator Systems!@#@!HAPTICS!@#@!null
index644!@#@!1995!@#@!On the use of machine-assisted knowledge discovery to analyze and reengineer measurement frameworks!@#@!Proceedings of the 1995 conference of the Centre for Advanced Studies on Collaborative research!@#@!We call the set of metrics, data collection mechanisms, and measurement models used by organizations in running their businesses a Measurement Framework. This paper [1] describes how a knowledge discovery technique called Attribute Focusing (AF) can be combined with a measurement planning approach called the Goal/Question/Metric Paradigm (GQM) to analyze and reengineer the Measurement Framework of an organization. The GQM Paradigm is widely used by the software engineering community to handle Measurement Frameworks in a top-down, goal-oriented fashion. The AF technique is a machine-assisted knowledge discovery technique which has been widely used to help domain experts search for knowledge in a database of measurement (attribute-valued) data. Using our experience analyzing Software Customer Satisfaction survey data at IBM, we illustrate how the AF Technique can be combined with GQM to improve a Measurement Framework. We argue that this may be a good approach to reengineering and improving existing Measurement Frameworks.
index645!@#@!2003!@#@!Trust-Based Facilitator: Handling Word-of-Mouth Trust for Agent-Based E-Commerce!@#@!Electronic Commerce Research!@#@!This paper proposes a facilitator which finds capable and trustworthy partners on behalf of client users (agents), which helps agents form and maintain e-partnerships for electronic commerce. Unlike existing capability-based facilitators or matchmakers, the facilitator collects and maintains private &ldquo;word-of-mouth&rdquo; trust information as well as capabilities from each agent and uses the information for personalized trust-based facilitation for each agent, which is performed through the facilitation protocols and trust propagation mechanism. Compared to other existing trust mechanisms, the characteristics of trust which this facilitator handles are personalized-collaborative-subjective-qualitative-private. The facilitator is implemented as a JATLite multi-agent system and a FIPA-OS based multi-agent system, and is evaluated in terms of the complexity and characteristics. The example of usage is shown in the area of construction supply-chain coordination.
index646!@#@!2002!@#@!A Multi-agent Q-learning Framework for Optimizing Stock Trading Systems!@#@!Proceedings of the 13th International Conference on Database and Expert Systems Applications!@#@!null
index647!@#@!1991!@#@!Logical Semantics of Modularisation!@#@!Proceedings of the 5th Workshop on Computer Science Logic!@#@!null
index648!@#@!1996!@#@!Constructive Analysis of Cyclic Circuits!@#@!Proceedings of the 1996 European conference on Design and Test!@#@!Traditionally, circuits with combinational loops are found only in asynchronous designs. However, combinational loops can also be useful for synchronous circuit design. Combinational loops can arise from high-level language behavioral compiling, and can be used to reduce circuit size. We provide a symbolic algorithm that detects if a sequential circuit with combinational loops exhibits standard synchronous behavior, and if so, produces an equivalent circuit without combinational loops. We present applications to hardware and software synthesis from the Esterel synchronous programming language.
index649!@#@!2001!@#@!A Knowledge-Based Neurocomputing Approach to Extract Refined Linguistic Rules from Data!@#@!Proceedings of the 7th Congress of the Italian Association for Artificial Intelligence on Advances in Artificial Intelligence!@#@!null
index650!@#@!1991!@#@!Lernen in einem antagonistischen Neuronalen Netzwerk!@#@!Mustererkennung 1991, 13. DAGM-Symposium!@#@!null
index651!@#@!1995!@#@!A unified model for co-simulation and co-synthesis of mixed hardware/software systems!@#@!Proceedings of the 1995 European conference on Design and Test!@#@!This paper presents a methodology for a unified co-simulation and co-synthesis of hardware-software systems. This approach addresses the modeling of communication between the hardware and software modules at different abstraction levels and for different design tools. The main contribution is the use of a multi-view library concept in order to hide specific hardware/software implementation details and communication schemes. A system is viewed as a set of communicating hardware (VHDL) and software (C) sub-systems. The same C, VHDL descriptions can be used for both co-simulation and hardware-software co-synthesis. This approach is illustrated by an example.
index652!@#@!2000!@#@!Dimension in Complexity Classes!@#@!Proceedings of the 15th Annual IEEE Conference on Computational Complexity!@#@!A theory of resource-bounded dimension is developed using gales, which are natural generalizations of martin-gales. When the resource bound \math (a parameter of the theory) is unrestricted, the resulting dimension is precisely the classical Hausdorff dimension (sometimes called ¿fractal dimension¿). Other choices of the parameter \math yield internal dimension theories in E, E2, ESPACE, and other complexity classes, and in the class of all decidable problems.In general, if C is such a class, then every set X of languages has a dimension in C, which is a real number dim\math. Along with the elements of this theory, two preliminary applications are presented: 1. For every real number \math , the set FREQ(\math), consisting of all languages that asymptotically contain at most \math of all strings, has dimension H(\math) - the binary entropy of \math -in E and in E2. 2. For every real number \math, the set SIZE(\math), consisting of all languages decidable by Boolean circuits of at most \math gates, has dimension \math in ESPACE.
index653!@#@!1997!@#@!An Interpolation Subspline Scheme Related to B-Spline Techniques!@#@!Computer Graphics International!@#@!We construct (integral) interpolating subspline curves for given data points and the knot vector. The algorithm is very close to B spline approximation. The idea is to blend interpolating Lagrangian splines using B spline techniques. Everything is connected in an affinely invariant way with the control points and the knot vector. We are able to show that our scheme produces high quality subsplines, which include known procedures like Overhauser or quintic interpolation schemes. In addition we may sweep to B splines and return in a very lucid way. Examples show the power of the method. The given procedure allows generalisations to rational subsplines and to tensor product interpolating surfaces.
index654!@#@!1999!@#@!Monokulare Rekonstruktion unter Orthogonalit&auml;tsvoraussetzungen!@#@!Mustererkennung 1999, 21. DAGM-Symposium!@#@!null
index655!@#@!1998!@#@!Open Architecture for Natural Language Distributed Systems!@#@!Proceedings of the 9th International Conference on Database and Expert Systems Applications!@#@!null
index656!@#@!1995!@#@!A Machine Learning Approach to the Analysis of Large Image Databases!@#@!Proceedings of the 11th Conference on Artificial Intelligence for Applications!@#@!null
index657!@#@!1997!@#@!Vision-based Line Tracking and Navigation in Structured Environments!@#@!Proceedings of the 1997 IEEE International Symposium on Computational Intelligence in Robotics and Automation!@#@!This paper describes a vision-based, low-cost line-tracking system suitable for robot or AGV navigation in structured environments. Vehicle navigation takes advantage of the visual information provided by artificial or pre-existing landmarks, specifically lines and signs. This information is efficiently processed using specialized perceptual behaviors, including neural networks and focus of attention techniques, with the help of a multi-threaded real-time control architecture. Attained system performance is compatible with present requirements and practices for typical AGV applications.
index658!@#@!2003!@#@!Coarse-grained stochastic processes and Monte Carlo simulations in lattice systems!@#@!Journal of Computational Physics!@#@!In this paper we present a new class of coarse-grained stochastic processes and Monte Carlo simulations, derived directly from microscopic lattice systems and describing mesoscopic length scales. As our primary example, we mainly focus on a microscopic spin-flip model for the adsorption and desorption of molecules between a surface adjacent to a gas phase, although a similar analysis carries over to other processes. The new model can capture large scale structures, while retaining microscopic information on intermolecular forces and particle fluctuations. The requirement of detailed balance is utilized as a systematic design principle to guarantee correct noise fluctuations for the coarse-grained model. We carry out a rigorous asymptotic analysis of the new system using techniques from large deviations and present detailed numerical comparisons of coarse-grained and microscopic Monte Carlo simulations. The coarse-grained stochastic algorithms provide large computational savings without increasing programming complexity or the CPU time per executed event compared to microscopic Monte Carlo simulations.
index659!@#@!1998!@#@!Incentive Effects Favor Nonconsolidating Queues in a Service System: the Principal-Agent Perspective!@#@!Management Science!@#@!In this paper, we study a service network in which an agency is responsible for satisfying a constraint on the expected waiting and service time experienced by customers. However, the agency does not render the actual service. Instead, it serves to coordinate independently operated facilities. The coordinating agency must devise a strategy for allocating compensation and customers to the self-interested operators in order to minimize its own costs. For a network of two facilities, we model the facilities' self-interested capacity decisions as the solution to a game. Using this analytical framework, we compare two types of customer allocation: one from a common queue, and one from separate queues. Our analysis shows that it can be in the best interest of the coordinating agency to adopt a separate queue allocation scheme instead of one based on a common queue. Although doing so sacrifices risk-pooling benefits, these can be more than offset by the stronger incentives that are created for the independent facilities.
index660!@#@!1996!@#@!On the Subject Reduction Property for Algebraic Type Systems!@#@!Selected Papers from the10th International Workshop on Computer Science Logic!@#@!null
index661!@#@!2001!@#@!The Dynamic and Stochastic Knapsack Problem with Random Sized Items!@#@!Operations Research!@#@!A resource allocation problem, called the dynamic and stochastic knapsack problem (DSKP), is studied. A known quantity of resource is available, and demands for the resource arrive randomly over time. Each demand requires an amount of resource and has an associated reward. The resource requirements and rewards are unknown before arrival and become known at the time of the demand's arrival. Demands can be either accepted or rejected. If a demand is accepted, the associated reward is received; if a demand is rejected, a penalty is incurred. The problem can be stopped at any time, at which time a terminal value is received that depends on the quantity of resource remaining. A holding cost that depends on the amount of resource allocated is incurred until the process is stopped. The objective is to determine an optimal policy for accepting demands and for stopping that maximizes the expected value (rewards minus costs) accumulated. The DSKP is analyzed for both the infinite horizon and the finite horizon cases. It is shown that the DSKP has an optimal policy that consists of an easily computed threshold acceptance rule and an optimal stopping rule. A number of monotonicity and convexity properties are studied. This problem is motivated by the issues facing a manager of an LTL transportation operation regarding the acceptance of loads and the dispatching of a vehicle. It also has applications in many other areas, such as the scheduling of batch processors, the selling of assets, the selection of investment projects, and yield management.
index662!@#@!2002!@#@!Town Map System for Sharing Accessibility Information Using Card Data Structure!@#@!Proceedings of the IEEE Workshop on Knowledge Media Networking!@#@!This paper describes a town map system for sharing accessibility information. Our system's unique contribution is handling all information as a card data and associating those cards with a map. Using this system, users can share various information in a map-based unified way. Our system not only stores information from users, but also organizes them. Users can therefore easily make their own plan for going out by relating more than two stored cards. They can also efficiently search for necessary information. Furthermore, in order to provide reliable information, we incorporated a function in which users can give a card positive or negative comments. If a card is given a negative comment, then our system might make it invisible. Through evaluation of the prototype system, it was proved that our proposed system was effective for sharing accessibility information.
index663!@#@!2002!@#@!Challenges of teaching in a small computing department!@#@!Journal of Computing Sciences in Colleges!@#@!null
index664!@#@!2003!@#@!A new speculation technique to optimize floating-point performance while preserving bit-by-bit reproducibility!@#@!International Conference on Supercomputing!@#@!The bit-by-bit reproducibility of floating-point results, which is defined by the IEEE 754 standard, prohibits optimizations such as reassociation and the use of native operations such as fused multiply-add (FMA), and thus it significantly impairs floating-point performance. Recent network-oriented languages such as Java strictly conform to the standard, and thus their numerical computing performance becomes inherently lower than conventional languages.In this paper, we propose a new software technique, called floating-point (FP) speculation, to optimize floating-point performance while preserving the bit-by-bit reproducibility of the results. We execute the fast unsafe code and the slow verification code in parallel. The unsafe code does not wait for the verification code, and is immediately followed by the subsequent code that uses the probable result from the unsafe code assuming the speculation will succeed. The improvement from FP speculation results from this earlier start of the subsequent code.Unlike other speculation techniques, FP speculation does not require any special instructions or hardware support. Rather, it exploits unused floating-point registers and execution units. Therefore it is generally applicable for processor architectures that have sufficient floating-point resources.
index665!@#@!1993!@#@!Euclidean Reconstruction from Uncalibrated Views!@#@!Proceedings of the Second Joint European - US Workshop on Applications of Invariance in Computer Vision!@#@!null
index666!@#@!1998!@#@!Object Oriented ARM7 Coprocessor!@#@!Proceedings of the Thirty-First Annual Hawaii International Conference on System Sciences - Volume 3!@#@!This paper presents preliminary results on the design of an Object Coprocessor (OCP) cooperating with a RISC-architecture processor (ARM7, by Advanced RISC Machines Ltd.). This coprocessor implements in hardware some low-level processing and control steps required by the object-oriented model. The processor and the OCP constitute a processing architecture whose extended instruction set features "object" treatment capabilities. Some special coprocessor instruction codes ("Object Instructions") have been introduced. Concepts such as "Polymorphism" and "Virtual methods" are supported at the hardware level. Preliminary results using typical object-oriented sequences show a gain in speed over a pure software implementation, on the same RISC machine. The specific design presented here refers to a prototype implementation that is currently under development and supported by the European Union Esprit Project (7517 SUMIS).
index667!@#@!2001!@#@!It's All about Process: Project Oriented Teaching of Software Engineering!@#@!Proceedings of the 14th Conference on Software Engineering Education and Training!@#@!Process considerations are a central part of the material for a software engineering course; they are also central to accomplishing full-lifecycle, team-based systems development projects in such a course. This paper discusses the ways in which we have achieved an effective process structure within an academic context of full-year project courses. The key features are a kernel project plan and a process management mechanism. The project plan is a schedule including eight milestones with fixed due dates and quite explicit deliverables. The management is accomplished through an advanced full-year course, whose participants guide the project teams through the process.
index668!@#@!2002!@#@!Algorithmic transformation techniques for efficient exploration of alternative application instances!@#@!Proceedings of the tenth international symposium on Hardware/software codesign!@#@!Following the Y-chart paradigm for designing a system, an application and an architecture are modeled separately and mapped onto each other in an explicit design step. Next, a performance analysis for alternative application instances, architecture instances and mappings has to be done, thereby exploring the design space of the target system. Deriving alternative application instances is not trivially done. Nevertheless, many instances of a single application exist that are worth to be derived for exploration. In this paper, we present algorithmic transformation techniques for systematic and fast generation of alternative application instances that express task-level concurrency hidden in an application in some degree of explicitness. These techniques help a system designer to speedup significantly the design space exploration process.
index669!@#@!2003!@#@!Preface!@#@!Mathematics and Computers in Simulation!@#@!null
index670!@#@!1994!@#@!Modelling the reassembly buffer in a connectionless server!@#@!Proceedings of the Second IFIP Workshop on Performance Modelling and Evaluation of ATM Networks: ATM Networks, Performance Modelling and Analysis, Volume 1!@#@!null
index671!@#@!1997!@#@!Data Compression Using Text Encryption!@#@!Proceedings of the  Conference on Data Compression!@#@!null
index672!@#@!1999!@#@!Program Committee Members!@#@!Proceedings of the 14th Annual IEEE Symposium on Logic in Computer Science!@#@!null
index673!@#@!2003!@#@!Crosstalk noise in FPGAs!@#@!Proceedings of the 40th annual Design Automation Conference!@#@!In recent years, due to rapid advances in VLSI manufacturing technology capable of packing more and more devices and wires on a chip, crosstalk has emerged as a serious problem affecting circuit reliability. Even though FPGAs are more immune to crosstalk noise than their ASIC counterparts manufactured in the same technological process, we have reached the point where FPGAs have become affected by crosstalk as well. Because FPGAs have regular interconnect structures, crosstalk noise can be more easily controlled. In this paper, we investigate the crosstalk noise in FPGAs and propose new strategies to reduce its impact on delay. Our methods can reduce crosstalk noise by statistically significant amounts with no penalty in performance, power, or area.
index674!@#@!1997!@#@!The Chimaera reconfigurable functional unit!@#@!Proceedings of the 5th IEEE Symposium on FPGA-Based Custom Computing Machines!@#@!By strictly separating reconfigurable logic from their host processor, current custom computing systems suffer from a significant communication bottleneck. In this paper we describe Chimaera, a system that overcomes this bottleneck by integrating reconfigurable logic into the host processor itself with direct access to the host processor's register file, the system enables the creation of multi-operand instruction and a speculative execution model key to high performance, general-purpose reconfigurable computing. It also supports multi-output functions, and utilizes partial run-time reconfiguration to reduce reconfiguration time. Combined, this system can provide speedups of a factor of two or more for general-purpose computing, and speedups of 160 or more are possible for hand-mapped applications.
index675!@#@!2002!@#@!Mixed-initiative exception-based learning for knowledge base refinement!@#@!Eighteenth national conference on Artificial intelligence!@#@!null
index676!@#@!2000!@#@!Generating Test Data for Branch Coverage!@#@!Automated Software Engineering!@#@!Branch coverage is an important criteria used during the structural testing of programs. In this paper, we present a new program execution based approach to generate input data that exercises a selected branch in a program. The test data generation is initiated with an arbitrarily chosen input from the input domain of the program. A new input is derived from the initial in-put in an attempt to force execution through any of the paths through the selected branch. The method dynamically switches among the paths that reach the branch by refining the input. Using a numerical iterative technique that attempts to generate an input to exercise the branch, it dynamically selects a path that offers less resistance. We have implemented the technique and present experimental results of its performance for some programs. Our results show that our method is feasible and practical.
index677!@#@!1999!@#@!Identification of Redundant Crosspoint Faults in Sequential PLAs with Fault-Free Hardware Reset!@#@!Proceedings of the 8th Asian Test Symposium!@#@!We present a technique for identifying redundant crosspoint faults in sequential PLAs with fault-free hardware reset. This technique can find most redundant crosspoint faults efficiently. Experimental results show that about 7% of crosspoint fauls are redundant on an average in the sequential PLAs synthesized by a commercial design tool SYNARIO for MCNC LGSynth89 finite-state machine benchmarks.
index678!@#@!2003!@#@!Web search strategies and approaches to studying!@#@!Journal of the American Society for Information Science and Technology!@#@!This paper reports results from a project, which sought to investigate the relationship between study approaches and Web-based information seeking. Factor analyses were applied to data from over 500 queries submitting in response to three different search tasks to identify clusters of variables associated with three Web-based search strategies: Boolean, best-match, and combined. A consistent pattern emerged across the nine analyses in relation to a number of study approach variables. Boolean searching was consistently associated with a reproductive (as opposed to meaning-oriented) approach, anxiety (in the form of fear of failure), and high levels of active interest. Best-match was associated with the converse of all these measures. Combined searching was differentiated from both Boolean and best-match by being associated with poor time management. There was also some evidence of changes in strategy in relation to task complexity. A model is introduced which seeks to explain these results. This project was exploratory in nature, and the pattern of findings are proposed as prima facie evidence to support the notion that study approaches can influence choice of search strategies. The results are considered essentially as hypotheses for further systematic study, for which suggestions are made.
index679!@#@!2002!@#@!Adapting to Radical Change: Strategy and Environment in Piece-Rate Adoption During China's Transition!@#@!Organization Science!@#@!Adaptation to radical change is central to research in organization theory, and some of the most dramatic examples of environmental change have occurred recently in transition economies such as China. I take advantage of change during China's economic reform to study the relative importance of organizational and environmental factors in producing innovative managerial response. I find that strategic choice predicted innovation in the early stages of reform, but environmental factors increased in salience over time. Intrafirm support, Communist Party connections, and a market orientation produced innovation early in reform. Simple imitation of others was also salient in early years. As reform progressed, managers increasingly imitated other profitable firms and drew on their own experience. My results inform an understanding of both the process by which innovation occurs and firm behavior in transition economies.
index680!@#@!2003!@#@!Design of a Middleware System for Flexible Intercommunication Environment!@#@!Proceedings of the 17th International Conference on Advanced Information Networking and Applications!@#@!Using distributed multimedia system that can integrate various realtime and non-realtime media data, when the system users communicate with each other by realtime audio video data, the system must guarantee end-to-end QoS (quality of service) according to requirements from the system users and available resources. If the system can dynamically use translator or mixer functions defined by RTP, more flexible peer-to-peer communication is realized. In this paper, we design a new middleware system with transcoding functions for flexible intercommunication environment by relocatable decision.
index681!@#@!2003!@#@!On homoclinic bifurcation emanating from Takens-Bogdanov points in Hamiltonian systems!@#@!Zeitschrift f&uuml;r Angewandte Mathematik und Physik (ZAMP)!@#@!The paper is devoted to studying the bifurcation of periodic and homoclinic orbits in a 2n-dimensional Hamiltonian system with 1 parameter from a TB-point (Hamiltonian saddle node). In addition to the proof of existence, the paper gives an expansion formula of the bifurcating homoclinic orbits. With the help of center manifold reduction and a blow up transformation, the problem is focused on studying a planar Hamiltonian system, the proof for the perturbed homoclinic and periodic orbits is elementary in the sense that it uses only implicit function arguments. Two applications to travelling waves in PDEs are shown.
index682!@#@!2000!@#@!Using upper confidence bounds for online learning!@#@!Proceedings of the 41st Annual Symposium on Foundations of Computer Science!@#@!We show how a standard tool from statistics, namely confidence bounds, can be used to elegantly deal with situations which exhibit an exploitation/exploration trade-off. Our technique for designing and analyzing algorithms for such situations is very general and can be applied when an algorithm has to make exploitation-versus-exploration decisions based on uncertain information provided by a random process. We consider two models with such an exploitation/exploration trade-off. For the adversarial bandit problem our new algorithm suffers only O/spl tilde/(T/sup 1/2/) regret over T trials which improves significantly over the previously best O/spl tilde/(T/sup 2/3/) regret. We also extend our results for the adversarial bandit problem to shifting bandits. The second model we consider is associative reinforcement learning with linear value functions. For this model our technique improves the regret from O/spl tilde/(T/sup 3/4/) to O/spl tilde/(T/sup 1/2/).
index683!@#@!2003!@#@!Distributed Virtual Reality Environments Based on Rewriting Systems!@#@!IEEE Transactions on Visualization and Computer Graphics!@#@!Ideally, virtual worlds should be dynamic, mutable, and complex in order to be attractive for immersed users. As such worlds can be designed easily by rewriting techniques, we propose a distributed Virtual Reality (VR) system that is based on an interactive animation system using a rewriting technique for geometric and behavioral modeling. The emphasis is on concepts and extensions for the integration of user immersion, user interaction, and networking into a rewriting-based animation system. Finally, the modeling of a ball game with two immersed users, as well as a virtual park, serve as case studies to illustrate the proposed concepts and extensions.
index684!@#@!2002!@#@!Qualitative analysis on a chemotactic diffusion model for two species competing for a limited resource!@#@!Quarterly of Applied Mathematics!@#@!null
index685!@#@!2003!@#@!Tracking regions of human skin through illumination changes!@#@!Pattern Recognition Letters!@#@!New human computer interfaces are using computer vision systems to track faces and hands. A critical task in such systems is the segmentation. An often used approach is colour based segmentation, approximating the skin chromaticities with a statistical model, e.g. with mean value and covariance matrix. The advantage of this approach is that it is invariant to size and orientation and fast to compute. A disadvantage is that it is sensitive to changes of the illumination, and in particular to changes in the illumination colour.This paper investigates (1) how accurately the covariance matrix of skin chromaticities might be modelled for different illumination colours using a physics-based approach, (2) how this may be used as a feature to classify between skin and other materials. Results are presented using real image data taken under different illumination colours and from subjects with different shades of skin. The eigenvectors of the modelled and measured covariances deviate in orientation about 4°. The feature to distinguish skin from other surfaces is tested on sequences with changing illumination conditions containing hands and other materials. In most cases it is possible to distinguish between skin and other objects.
index686!@#@!1997!@#@!The Algorithmic Complexity of Chemical Threshold Testing!@#@!Proceedings of the Third Italian Conference on Algorithms and Complexity!@#@!null
index687!@#@!2003!@#@!Aspects of system description!@#@!Programming methodology!@#@!This paper discusses some aspects of system description that are important for software development. Because software development aims to solve problems in the world, rather than merely in the computer, these aspects include: the distinction between the hardware/software machine and the world in which the problem is located; the relationship between phenomena in the world and formal terms used in descriptions; the idea of a software model of a problem world domain; and an approach to the decomposition of problems and its consequences for the larger structure of software development descriptions.
index688!@#@!2003!@#@!&#x00B5;-DSMC: a general viscosity method for rarefield flow!@#@!Journal of Computational Physics!@#@!A modified DSMC method for rarefied flows is described, by which any viscosity law µ = µ(T) may be simulated. The method is simple to implement. The collision cross-section of a simple collision model, such as the hard sphere or variable hard sphere (VHS) is made to vary from cell to cell, based on the time-averaged cell temperature and the required viscosity at that temperature. The method is here demonstrated for two viscosity laws which fit experimental data better than does the hard sphere or variable hard sphere viscosity laws, but in principle the method can use the experimental data directly. The new method is tested in two different flows: high speed Couette flow and a plane 1D shock. For Couette flow, the shear stress and heat transfer, calculated from the velocity distribution, agree with the theoretical values calculated from the flow gradients and the theoretical transport coefficients. For the plane 1D shock, the new method is compared with the generalized hard sphere (GHS) model. The new method produces profiles of density and temperature within the shock which are generally indistinguishable from the GHS results except for a deviation in the Tx temperature component in a small region ahead of the shock. This deviation depends on the shock Mach number; for the worst case it is 4.6%. The deviation can be reduced by basing the imposed viscosity on the maximum component of kinetic temperature (in this case Tx) rather than the mean kinetic temperature. The new method is shown to be insensitive to the number of simulator particles used in each cell. Three translational degrees of freedom are considered here. However, because µ-DSMC is based on a hard sphere or VHS cross-section, it is compatible with the most commonly used Borgnakke-Larsen energy exchange model for translational-rotational energy exchange.
index689!@#@!1997!@#@!Model Checking LTL Using Constraint Programming!@#@!Proceedings of the 18th International Conference on Application and Theory of Petri Nets!@#@!null
index690!@#@!1991!@#@!Three-Level Decomposition with Application to PLDs!@#@!Proceedings of the 1991 IEEE International Conference on Computer Design on VLSI in Computer &amp; Processors!@#@!null
index691!@#@!2003!@#@!Erratum: computation of Lyapunov characteristic exponents for continuous dynamical systems!@#@!Zeitschrift f&uuml;r Angewandte Mathematik und Physik (ZAMP)!@#@!null
index692!@#@!2000!@#@!Editorial Review Board!@#@!Organization Science!@#@!null
index693!@#@!2002!@#@!Virtual Routers: A Tool for Emulating IP Routers!@#@!Proceedings of the 27th Annual IEEE Conference on Local Computer Networks!@#@!Setting up experimental networks of a sufficient size is acrucial element for the development of communication services.Unfortunately, the required equipment, like routersand hosts, is expensive and its availability is limited. On theother hand, simulations often lack interoperability to realsystems and scalability, which limits the scope and the validityof their results. Therefore, an intermediate approachbetween these two alternatives that allows for setting uptestbeds on a cluster of computers is needed. This paperpresents an intermediate approach based on the emulationof IP routers and evaluates the concept. In a first set of experimentsthe impact of various parameters on the packetdelay was investigated, while further experiments comparethe performance of Differentiated Services run on the networkemulator with the results obtained by the well knownnetwork simulator ns.
index694!@#@!1997!@#@!Homotopy in 2-dimensional Digital Images!@#@!Proceedings of the 7th International Workshop on Discrete Geometry for Computer Imagery!@#@!null
index695!@#@!2002!@#@!Extended Model-Based Testing toward High Code Coverage Rate!@#@!Proceedings of the 7th International Conference on Software Quality!@#@!null
index696!@#@!1998!@#@!CMOS Tapered Buffer Design for Small Width Clock/Data Signal Propagation!@#@!Proceedings of the Great Lakes Symposium on VLSI '98!@#@!null
index697!@#@!1991!@#@!Investigation of Finitary Calculus for a Discrete Linear Time Logic by means of Infinitary Calculus!@#@!Baltic Computer Science, Selected Papers!@#@!null
index698!@#@!1998!@#@!The TASTE-Model and the EPM-System: Conceptual Designs for Exploitation and Exploration of Aggregated Emission Inventory Information in Environmental Monitoring!@#@!Proceedings of the Thirty-First Annual Hawaii International Conference on System Sciences-Volume 7 - Volume 7!@#@!As responsibility for environmental policy in the Netherlands becomes more decentralized the need for environmental monitoring at lower governmental authority levels increases. Although conceptual perspectives on environmental monitoring are abundantly available, governmental authorities lack effective application of environmental monitoring and supporting information technology. In this paper the authors propose a solution for implementing generic environmental monitoring instruments. The solution presented consists of three components: First, environmental monitoring is positioned in an environmental science and information science framework. Second, a data model named TASTE (an acronym of Time, Area, Substance and human acTivity referenced Emission inventory) will be described. Third, a hybrid management support system named EPM (an acronym of Environmental Policy Monitor) will be described. We end the paper with a discussion of a project recently set up by the Inspectorate General for Environmental Protection in the Netherlands. This project, in which an emission inventory data warehouse will be developed, is relevant to the study presented as it will be based on the TASTE-model.
index699!@#@!2002!@#@!Superscalar microarchitecture!@#@!International Symposium on Microarchitecture!@#@!null
index700!@#@!2003!@#@!Time management for new faculty!@#@!ACM SIGMOD Record!@#@!In this article, we describe techniques for time management for new faculty members, covering a wide range of topics ranging from advice on scheduling meetings, email, to writing grant proposals and teaching.
index701!@#@!1999!@#@!Resistance against Differential Power Analysis for Elliptic Curve Cryptosystems!@#@!Proceedings of the First International Workshop on Cryptographic Hardware and Embedded Systems!@#@!null
index702!@#@!1997!@#@!Minimizing the Energy of the Alanine Dipeptide by Simulated Annealing!@#@!CBMS!@#@!This paper presents an approach for deriving 3-D structures of polypeptide chains which have minimum energy. The well-known optimization algorithms are usually applied on the model which contains hard constraints over coordinates of the atoms. The drawback of such strategies is an inefficient search for the optimal solution. Our approach proceeds in two steps: first, the standard model is transformed into an equivalent model without hard constraints, and second, the simulated annealing local search algorithm is performed. The empirical results demonstrate that simulated annealing on the proposed model outperforms traditional search algorithms especially with respect to running times.
index703!@#@!1998!@#@!Dowsing: A Tool Framework for Domain-Oriented Browsing of Software Artifacts!@#@!Automated Software Engineering!@#@!Program understanding relates a computer program to the goals and requirements it is designed to accomplish. Application-domain analysis is a source of information that can aid program understanding by guiding the source- code analysis and providing structure to its results. We use the term "dowsing" to describe the process of exploring software and the related documentation from an application-domain point of view. We have designed a tool framework to support dowsing and have populated it with a variety of commercial and research tools.
index704!@#@!1995!@#@!A Simple Model Construction for the Calculus of Constructions!@#@!Selected papers from the International Workshop on Types for Proofs and Programs!@#@!null
index705!@#@!2000!@#@!A Theory of Consistency for Modular Synchronous Systems!@#@!Proceedings of the Third International Conference on Formal Methods in Computer-Aided Design!@#@!null
index706!@#@!1996!@#@!Experimental assessment of parallel systems!@#@!FTCS!@#@!In the research reported in this paper, transient faults were injected in the nodes and in the communication subsystem (by using software fault injection) of a commercial parallel machine running several real applications. The results showed that a significant percentage of faults caused the system to produce wrong results while the application seemed to terminate normally, thus demonstrating that fault tolerance techniques are required in parallel systems, not only to assure that long-running applications can terminate but also (and more important) that the results produced are correct. Of the techniques tested to reduce the percentage of undetected wrong results only ABFT proved to be effective. For other simple error detection methods to be effective, they have to be designed in, and not added as an after thought. Faults injected in the communication subsystem proved the effectiveness of end-to-end CRCs on the data movements between processors.
index707!@#@!1999!@#@!A Greedy Router with Technology Targetable Output!@#@!Proceedings of the Ninth Great Lakes Symposium on VLSI!@#@!Our objective was to integrate an effective channel routing algorithmwith the Chip Design Language (CDL) algorithmic layout tool. CDL uses technology targetable layout techniques, so that the output of the routing algorithm can easily be ported to different technologies. We introduce the technology independent features of CDL and describe how a greedy router can be interfaced to it. Specific features of interest include mapping from the grid based router to the gridless CDL environment, and the automatic insertion of CDL feed-through cells in multi-channel applications.
index708!@#@!2003!@#@!Accurate numerical resolution of transients in initial-boundary value problems for the heat equation!@#@!Journal of Computational Physics!@#@!If the initial and boundary data for a PDE do not obey an infinite set of compatibility conditions, singularities will arise in the solution at the corners of the initial time-space domain. For dissipative equations, such as the 1-D heat equation or 1-D convection-diffusion equations, the impacts of these singularities are short lived. However, they can cause a very severe loss of numerical accuracy if we are interested in transient solutions. The phenomenon has been described earlier from a theoretical standpoint. Here, we illustrate it graphically and present a simple remedy which, with only little extra cost and effort, restores full numerical accuracy.
index709!@#@!1999!@#@!Creating Multimedia Presentation Based on Constraint Satisfaction Problems in Multimedia Databases!@#@!Proceedings of the 1999 International Symposium on Database Applications in Non-Traditional Environments!@#@!We have studied a mechanism for creating multimedia presentation from various multimedia objects such as video, image and text. The important points for creating multimedia presentation are specification and verification. Specification means representation for temporal relations among multimedia objects. Temporal relations specify the flow of multimedia presentation in space and time.As for verification, we should consider both syntactic and semantic aspects in creating multimedia presentation. Syntactic aspect means how multimedia objects are scheduled. Graph model visually indicates temporal relations between multimedia objects, and can simulate the multimedia presentation in advance. This simulation can detect contradictions between temporal relations and configuration errors. Semantic aspect corresponds to the presentation constraints. Presentation constraints can be detected when user-specified presentation is played out because users may have various requirements. In this paper, we propose the way to create multimedia presentation to satisfy the constraints between multimedia objects.
index710!@#@!1999!@#@!High Performance Distributed Objects Using Caching Proxies for Large Scale Applications!@#@!Proceedings of the International Symposium on Distributed Objects and Applications!@#@!Initial implementations of Middleware based on standards such as CORBA have concentrated on host and language transparency issues in order to demonstrate interoperability. They have largely adopted a No-Replication approach and have frequently neglected performance-at-scale issues. This has lead to a continuing deployment of either non-scalable Full-Replication approaches or ad-hoc messaging-based Middleware for applications such as Intelligent Networks, WWW applications and Collaborative Virtual Reality. These applications require millions of objects globally distributed across hundreds of hosts and demand a very high throughput of low-latency method invocations.Our main research aim is to be able to reason about the performance of such applications when using scalable Partial-Replication and Object-Oriented approaches to Middleware.Our approach is to use a simulator to explore potential design and implemention choices. Our current simulator-driven design, called "MinORB", has been fully implemented and tested. MinORB supports scaleable high-performance by a combination of techniques including weak and application-specified consistency and partial replication using fine-grained proxy caching.Experimental results show that our work compares very favorably with other leading implementations such as OmniORB. Scalability is unparalleled with up to 1,000,000,000 objects per address space, a maximum throughput of 42,000 invocations per second and service times as low as 4 microseconds.
index711!@#@!1996!@#@!K*BMDs: A New Data Structure for Verification!@#@!Proceedings of the 1996 European conference on Design and Test!@#@!Recently, two new data structures have been proposed in the area of Computer Aided Design (CAD), i.e. Ordered Kronecker Functional Decision Diagrams (OKFDDs) and Multiplicative Binary Moment Diagrams (*BMDs). OKFDDs are the most general ordered data structure for representing Boolean functions at the bit-level. *BMDs are especially applicable to integer valued functions. In this paper we propose a new data structure, called Kronecker Multiplicative BMDs (K*BMDs), that is a generalization of OKFDDs to the word-level. Using K*BMDs it is possible to represent functions efficiently, that have a good word-level description, since K*BMDs are a generalization of *BMDs. On the other hand they are also applicable to verification problems at the bit-level. We present experimental results to demonstrate the efficiency of our approach including a comparison of K*BMDs to several other data structures, like EVBDD, OKFDDs and *BMDs. Additionally, experiments on verification of fast multipliers, i.e. multipliers with worst case running time O(log(n)), are reported.
index712!@#@!2003!@#@!Monte Carlo simulation of quantum electron transport based on Wigner paths!@#@!Mathematics and Computers in Simulation!@#@!Advancements and improvements in the Wigner function (WF) approach to quantum electron transport are reviewed. The concept of Wigner paths allows the formulation of the Monte Carlo simulation in strict analogy with the one used in semiclassical transport theory.
index713!@#@!2002!@#@!Optimal-by-accuracy and optimal-by-order cubature formulae in interpolational classes!@#@!Journal of Computational and Applied Mathematics!@#@!In this paper the problem of optimal integration for fast oscillatory functions of two variables is solved constructively in the case where a priori information is limited. The connection of this problem with the problem of optimal recovery of a function from interpolational classes is analysed using properties of majorants and minorants for these functional classes.
index714!@#@!2003!@#@!A comparative experimental evaluation study of intrusion detection system performance in a gigabit environment!@#@!Journal of Computer Security!@#@!Intrusion detection systems' (IDS) effectiveness requires balancing characteristics and elements so they fit together in appropriate compromises to create good network security systems. One major gauge for IDS effectiveness is the ability to detect attacks within operational specifications. Gigabit IDS sensors as opposed to Megabit IDS sensors promise dramatic increase in component performance and functional opportunities, possibly leading to dramatically changed system balance and overall performance. The research described here examines the system benefits of using a single Gigabit IDS sensor instead of multiple Megabit sensors for a wide range of defined system attacks, network traffic characteristics, and for their contexts of operational concepts and deployment techniques. The experimental results are analyzed in the context of practical experiences in the operation of these IDS systems. The difference in architectural designs, deployment strategies and operational concepts that characterized their performance in exploiting the strengths of attack systems are discussed.
index715!@#@!1999!@#@!Dynamic Planar Convex Hull Operations in Near-Logarithmic Amortized Time!@#@!Proceedings of the 40th Annual Symposium on Foundations of Computer Science!@#@!We give a data structure that allows arbitrary insertions and deletions on a planar point set P and supports basic queries on the convex hull of P, such as membership and tangent-finding. Updates take O(log{1+eps}n) amortized time and queries take O(log n) time each, where n is the maximum size of P and eps is any fixed positive constant. For some advanced queries such as bridge-finding, both our bounds increase to O(log{3/2}n). The only previous fully dynamic solution was by Overmars and van Leeuwen from 1981 and required O(log2 n) time per update.
index716!@#@!1999!@#@!Metrics for Evaluating Database Selection Techniques!@#@!Proceedings of the 10th International Workshop on Database & Expert Systems Applications!@#@!The increasing availability of online databases and other information resources in digital libraries has created the need for efficient and effective algorithms for selecting databases to search. A number of techniques have been proposed for query routing or database selection. We have developed a methodology and metrics that can be used to directly compare competing techniques. They can also be used to isolate factors that influence the performance of these techniques so that we can better understand performance issues. In this paper we describe the methodology we have used to examine the performance of database selection algorithms such as gGlOSS and CORI. In addition we develop the theory behind a ``random'''' database selection algorithm and show how it can be used to help analyze the behavior of realistic database selection algorithms.
index717!@#@!2003!@#@!Drop-impact cushioning effect of electronics products formed by plates!@#@!Advances in Engineering Software!@#@!Most electronic devices suffer impact-induced failure in their usage. Drop/impact performance of these products is one of the important concerns in product design. It is often time and cost consuming and thus undesirable to conduct drop tests for every design to physically detect, any sign of failure and identify their drop behaviors. Finite element analysis provides a vital and powerful tool to solve the problems. The methodology of finite element modeling, simulation and basic experimental validation should be developed to effectively study the drop/impact effects.Modeling and transient drop analysis for a simplified model representing electronics products formed by plates is considered in this work. The model simplified by using an equivalent spring system significantly saves the computational time while achieving reasonable results. The impact analysis of the model placed inside the cushioning buffer hitting the rigid floor is also the main concern of this work. The model is created using Pro-E and the drop-impact analysis is carried out on an existing software package, PAM System. It is found that having a cushioning buffer reduces the level of shocks at the instant of impact and so protecting the products from damage. The effect of different loaded masses placed on the top plate is also studied in this work.
index718!@#@!2000!@#@!A Genetically Optimized Artificial Neural Network Structure for Feature Extraction and Classification of Vascular Tissue Fluorescence Spectrums!@#@!CAMP!@#@!The optimization of Neural Network structures for feature extraction and classification by employing Genetic Algorithms is addressed here. More precisely, a non-linear filter based on High Order Neural Networks (HONN) whose weights are updated by stable learning laws is used to extract the characteristic features of fluorescence spectrums correspond to human tissue samples of different stares. The process is optimized by a generic algorithm which maximizes the separability of different classes. The features are then classified with a Multi-Layer Perceptron (MLP). The high rates of success together with the small time needed to analyze the signals, proves our method very attractive for real time applications.
index719!@#@!2001!@#@!Fast Reduction of Ternary Quadratic Forms!@#@!Revised Papers from the International Conference on Cryptography and Lattices!@#@!null
index720!@#@!2002!@#@!Using narratives to convey knowledge in decision making support systems!@#@!Decision making support systems: achievements, trends and challenges for!@#@!Information systems, and specifically decision making support systems, present information to users in a variety of modes--raw data, tables, graphs, and others. Rarely, if ever, does an information system present information to users in a narrative or story-based format. The last three decades have seen a variety of research articles that have presented an argument, an example, or a reference to what can be termed narrative-based information systems (NBIS). This chapter traces this history as they contribute to the development of NBIS. This chapter traces this history as they contribute to the development of NBIS. Previous work has come from multiple disciplines and multiple streams within Information Systems. To date, there has been very little work done in this area, and it is hypothesized that the reason is in part due to the multi-disciplinary approach and the lack of a unified effort. In order to further the efforts of this area of research, a conceptual model of the history is developed. The paper concludes with areas for future research.
index721!@#@!1999!@#@!Emotionally Expressive Agents!@#@!Proceedings of the Computer Animation!@#@!The ability to express emotions is important for creating believable interactive characters. To simulate emotional expressions in an interactive environment, an intelligent agent needs both an adaptive model for generating believable responses, and a visualization model for mapping emotions into facial expressions. Recent advances in intelligent agents and in facial modeling have produced effective algorithms for these tasks independently. In this paper, we describe a method for integrating these algorithms to create an interactive simulation of an agent that produces appropriate facial expressions in a dynamic environment. Our approach to combining a model of emotions with a facial model represents a first step towards developing the technology of a truly believable interactive agent, which has a wide range of applications from designing intelligent training systems to video games and animation tools.
index722!@#@!1999!@#@!Monolithic Microprocessor and RF Transceiver in 0.25-micron FDSOI CMOS!@#@!Proceedings of the Ninth Great Lakes Symposium on VLSI!@#@!A monolithic RFIC in 0.25-micron fully-depleted SOI CMOS has been designed consisting of a microcoded 8-bit 33-MHz microprocessor, a 400-MHz 8-bit ASK-modulated RF transceiver, and two integrated dc-dc voltage converters for power management. This architecture exploits a low-power (sub 2-V) digital
index723!@#@!1996!@#@!Towards Analysing a Class of Object Petri Nets!@#@!Proceedings of the 1996 Australian Software Engineering Conference!@#@!The Petri net theory has been used to specify many systems, in particular, concurrent, distributed and non-deterministic. A class of high-level, object-based Petri nets, OBJSA nets, is being used to model the behaviour of a concurrent system - a priority queue. We propose a method of analysing its behaviour by examining its structure and its underlying subnet components according to the state machine paradigm. This is closely related to the liveness and safeness analysis of free-choice Condition/Event systems with simple or unstructured tokens in existing literature. By using these existing results and applying them to OBJSA nets with structured tokens, we are able to determine the liveness property of our priority queue example.
index724!@#@!2003!@#@!Electro-Rheological Fluidic Actuators for Haptic Vehicular Instrument Controls!@#@!HAPTICS!@#@!Force-feedback mechanisms have been designed to simplify and enhance the human-vehicle interface. The increase in secondary controls within vehicle cockpits has created a desire for a simpler, more efficient human-vehicle interface. By consolidating various controls into a single, haptic feedback control device, information can be transmitted to the operator, without requiring the driver's visual attention. In this paper Electro-Rheological Fluids (ERF) based actuated mechanisms are presented that provide haptic feedback. ERFs are liquids that respond mechanically to electric fields by changing their properties, such as viscosity and shear stress electroactively. Using the electrically controlled rheological properties of ERFs, we developed haptic devices that can resist human operator forces in a controlled and tunable fashion. The design of two types of ERF-based actuators and joystick is presented in detail. Their analytical model is derived, parametric analysis is performed, and experimental systems and data are presented.
index725!@#@!1990!@#@!Ein sprachverstehendes Dialogsystem zur Dattenbankabfrage - die Realisierung des SPICOS II-Prototypen!@#@!Mustererkennung 1990, 12. DAGM-Symposium,!@#@!null
index726!@#@!1998!@#@!Static Classification Schemes for an Object System!@#@!Proceedings of the Eleventh International Florida Artificial Intelligence Research Society Conference!@#@!null
index727!@#@!1978!@#@!Issues in Kernel Design!@#@!Operating Systems, An Advanced Course!@#@!null
index728!@#@!2002!@#@!Questions and answers!@#@!Sys Admin!@#@!null
index729!@#@!2003!@#@!Structure and stability number of chair-, co-P- and gem-free graphs revisited!@#@!Information Processing Letters!@#@!The P4 is the induced path with vertices a, b, c, d and edges ab, bc, cd. The chair (co-P, gem) has a fifth vertex adjacent to b (a and b, a, b, c and d, respectively). We give a complete structure description of prime chair-, co-P- and gem-free graphs which implies bounded clique width for this graph class. It is known that this has some nice consequences; very roughly speaking, every problem expressible in a certain kind of Monadic Second Order Logic (quantifying only over vertex set predicates) can be solved efficiently for graphs of bounded clique width. In particular, we obtain linear time for the problems Vertex Cover, Maximum Weight Stable Set (MWS), Maximum Weight Clique, Steiner Tree, Domination and Maximum Induced Matching on chair-, co-P- and gem-free graphs and a slightly larger class of graphs. This drastically improves a recently published O(n4) time bound for Maximum Stable Set on butterfly-, chair-, co-P- and gem-free graphs.
index730!@#@!1998!@#@!Author Index!@#@!Proceedings of the 22nd International Computer Software and Applications Conference!@#@!In this paper, the authors present interactive, graphical software for introducing speech coding in undergraduate and graduate courses on digital signal processing (DSP) and speech processing. The software facilitates students in understanding and experimentation for practical applications of signal processing concepts introduced in DSP courses. It consists of two complementary components. The first is a MATLAB-based graphical simulation of a state-of-the-art speech coder. This component of the software is designed to complement the theoretical aspects of speech coding with practical exposure to the algorithms using hands-on simulations. The second component is an application that provides a framework for evaluation of different speech coding algorithms for a variety of applications. With this tool, students can easily categorize the performance of different speech coding algorithms through objective measurements as well as subjective listening tests. These tools could be used in entry-level graduate courses in DSP and speech coding. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player
index731!@#@!2003!@#@!Managing single echelon inventories through demand aggregation and the feasibility of a correlation matrix!@#@!Computers and Operations Research!@#@!This paper examines the assertion that partial pooling of customers is sometimes favored over complete pooling on the sole basis of demand correlation. First, the management of inventory within a supply chain is discussed, with specific attention paid to risk-pooling. Then, the claim that partial pooling can dominate is theoretically discussed. The conditions under which previous research found that partial aggregation could, at times, be preferable are investigated next. From this, methods are proposed for checking correlation matrices to ensure their validity. It is concluded that partial pooling can never do better and that examples supporting partial aggregation are based on inconsistent correlation matrices.
index732!@#@!2003!@#@!Reachability problems for sequential dynamical systems with threshold functions!@#@!Theoretical Computer Science!@#@!A sequential dynamical system (SDS) over a domain D is a triple (G, F, π), where (i) G(V,E) is an undirected graph with n nodes with each node having a state value from D, (ii) F = {f1, f2,..., fn} is a set of local transition functions with fi denoting the local transition function associated with node vi and (iii) π is a permutation of (i.e., a total order on) the nodes in V. A single SDS transition is obtained by updating the states of the nodes in V by evaluating the function associated with each of them in the order given by π.We consider reachability problems for SDSs with restricted local transition functions. Our main intractability results show that the reachability problems for SDSs are PSPACE-complete when either of the following restrictions hold: (i) F consists of both simple-threshold-functions and simple-inverted-threshold functions, or (ii) F consists only of threshold-functions that use weights in an asymmetric manner. Moreover, the results hold even for SDSs whose underlying graphs have bounded node degree and bounded pathwidth. Our lower bound results also extend to reachability problems for Hopfield networks and communicating finite state machines.On the positive side, we show that when F consists only of threshold functions that use weights in a symmetric manner, reachability problems can be solved efficiently provided all the weights are strictly positive and the ratio of the largest to the smallest weight is bounded by a polynomial function of the number of nodes.
index733!@#@!2002!@#@!An integrated applied research utilising fluid-dynamic software as support to medical enquiry into health problems by air pollution!@#@!Development and application of computer techniques to environmental studies!@#@!In environmental matter a good tested fluid dynamic software is the right tool not only to detect the fallout trend of pollutant gases emitted by industrial plants but to give also reliable information to the medical-team both about probable sensible targets of pollution and maximal dose of possible inhalation for each people living in a considerable neighborhood of emission sources.Paper wants to show the results of an inquiry commissioned by CE.RI.CA (Research Center for Environment Conservation) to the aim to discover the relationship between the fallout of gaseous pollutant emitted by petrochemical plants into the urban area, and the checkable pathologies of resident population in Melilli town (Italy).The enquire has been developed in three steps: • The localization of high risk areas has been achieved making use of fluid dynamic ADREA-3D computer code. • The validation of data of pollution coming from numerical simulations of computer code has been done through comparison with data recorded by networks of environmental steady stations, that is: CIPA ( Industrial Consortium for Environmental Protection), District of Siracusa City and Enel networks. • The correlation between pollutant concentrations and respiratory pathologies and diseases has been carried out through " questionnaire method" by medical team.
index734!@#@!2002!@#@!Smarandache sequence of happy numbers!@#@!Smarandache notions!@#@!In this article, we present the results of investigation of Smarandache Concatenate Sequence formed from the sequence of Happy Numbers and report some primes and other results found from the sequence.
index735!@#@!1991!@#@!Teaching Software Engineering for Real-Time Design!@#@!Proceedings of the SEI Conference on Software Engineering Education!@#@!null
index736!@#@!2000!@#@!Texture Based Classification of Mass Abnormalities in Mammograms!@#@!CBMS!@#@!This paper presents a scheme for the classification of mass abnormalities in digitized or digital mammograms based on two novel images texture features. The first texture feature provides a measure of smoothness/denseness and is obtained by applying a morphological operator to maxima/minima image points. The second texture feature reflects a measure of architectural distortion and is derived from image gradients. A three-layer back propagation neural network is used as the classifier. The performance of the classification scheme is evaluated by carrying out a receiver operating characteristic (ROC) analysis. Classification of 150 biopsy proven masses into benign and malignant classes resulted in a ROC area of 0.91. The results obtained demonstrate the potential of using this scheme as an electronic second opinion to lower the number of unnecessary biopsies.
index737!@#@!2002!@#@!AURORA: an air quality model for urban regions using an optimal resolution approach!@#@!Development and application of computer techniques to environmental studies!@#@!For the assessment of air quality in cities, we developed an integrated model system, known as AURORA (Air quality modelling in Urban Regions using an Optimal Resolution Approach). This urban air quality management system has been designed for urban and regional policy support and reflects the state-of-the-art in air quality modelling, using fast and advanced numerical techniques. Modules for meteorological input data, emissions, advection, diffusion and chemistry have been designed, tested and coupled through a user interface. The model system is implemented in the cities Antwerp and Hasselt (B) and is being applied in various EU 5th framework projects (BUGS, DECADE).
index738!@#@!2003!@#@!The e-tailer's dilemma!@#@!ACM SIGMIS Database!@#@!The e-tailer's dilemma refers to the difficulty web-based retailers (or e-tailers) have experienced in achieving profitability. The problem centers on the need to increase effective (purchasing) visitors and on the increased costs associated with the electronic commerce infrastructure upgrades necessary to service these additional visitors. This may lead e-tailers into a cycle of achieving increased revenues that are merely offset by rising costs. There are ample examples where commonly employed metrics (unique visitors, page views, sales, etc.) suggest success while companies struggle to obtain profitability. This paper examines several aspects of this dilemma. The formalization of both the tangible and intangible aspects of an electronic commerce infrastructure is proposed. Next, an intuitive, utility-based model to help describe and interpret e-tail visitor dynamics is developed. Finally, a visitor function model of e-tail profitability incorporating necessary infrastructure improvements and visitor characteristics is developed.
index739!@#@!2000!@#@!Multiple Cues used in Model-Based Human Motion Capture!@#@!Proceedings of the Fourth IEEE International Conference on Automatic Face and Gesture Recognition 2000!@#@!Human motion capture has lately been the object of much attention due to commercial interests. A "touch free" computer vision solution to the problem is desirable to avoid the intrusiveness of standard capture devices. The object to be monitored is known a priori which suggest to include a human model in the capture process. In this paper we use a model-based approach known as the analysis-by-synthesis approach. This approach is powerful but has a problem with its potential huge search space. Using multiple cues we reduce the search space by introducing constraints through the 3D locations of salient points and a silhouette of the subject. Both data types are relatively easy to derive and only require limited computational effort so the approach remains suitable for real-time applications. The approach is tested on 3D movements of a human arm and the results show that we successfully can estimate the pose of the arm using the reduced search space.
index740!@#@!2003!@#@!Topology management in ad hoc networks!@#@!International Symposium on Mobile Ad Hoc Networking &amp; Computing!@#@!The efficiency of a communication network depends not only on its control protocols, but also on its topology. We propose a distributed topology management algorithm that constructs and maintains a backbone topology based on a minimal dominating set (MDS) of the network. According to this algorithm, each node determines the membership in the MDS for itself and its one-hop neighbors based on two-hop neighbor information that is disseminated among neighboring nodes. The algorithm then ensures that the members of the MDS are connected into a connected dominating set (CDS), which can be used to form the backbone infrastructure of the communication network for such purposes as routing. The correctness of the algorithm is proven, and the efficiency is compared with other topology management heuristics using simulations. Our algorithm shows better behavior and higher stability in ad hoc networks than prior algorithms.
index741!@#@!1990!@#@!Parallelrechner und physikalische Experimente!@#@!Architektur von Rechensystemen, Tagungsband, 11. ITG/GI-Fachtagung!@#@!null
index742!@#@!2003!@#@!On the Time-Continuous Mass Transport Problem and Its Approximation by Augmented Lagrangian Techniques!@#@!SIAM Journal on Numerical Analysis!@#@!In [J. D. Benamou and Y. Brenier}, Numer. Math., 84 (2000), pp. 375--393], a computational fluid dynamic approach was introduced for computing the optimal map occurring in the Monge--Kantorovich problem. Though the described augmented Lagrangian method involves a Hilbertian framework, the discussion was purely formal. Taking advantage of the recent progress in optimal transport theory [L. A. Caffarelli, Comm. Pure Appl. Math., 45 (1992), pp. 1141--1151], [L. A. Caffarelli, Ann. of Math. (2), 144 (1996), pp. 453--496], [D. Cordero-Erausquin, C. R. Acad. Sci. Paris Sér. I Math., 329 (1999), pp. 199--202], [R. J. McCann, Geom. Funct. Anal., 11 (2001), pp. 589--608] and despite the lack of coercivity of the Hilbertian problem, we establish an existence result. Then, under a reasonable assumption of positivity for the density, we prove the existence of saddle-points for both Lagrangians defined in Benamou and Brenier, and finally prove the convergence of the numerical method.
index743!@#@!2003!@#@!Grid high performance networking in the DataGRID project!@#@!Future Generation Computer Systems!@#@!This paper presents an overview of the high performance Grid networking activities in the DataGRID project. We examine the main issues raised at network level by the design and the development of a large-scale Grid Testbed. We present the application requirement studies, the underlying network infrastructure and the initial network monitoring architecture that is under development in the context of the project.
index744!@#@!1999!@#@!Mining Several Data Bases with an Ensemble of Classifiers!@#@!Proceedings of the 10th International Workshop on Database & Expert Systems Applications!@#@!The results of knowledge discovery in data bases could vary depending on the data mining method. There are several ways to select the most appropriate data mining method dynamically. One proposed method clusters the whole domain area into "competence areas" of the methods. A metamethod is then used to decide which data mining method should be used with each data base instance. However, when knowledge is extracted from sev-eral data bases knowledge discovery may produce conflicting results even if the separate data bases are consistent. At least two types of conflicts may arise. The first type is created by data inconsistency within the area of the intersection of the data bases. The second type of conflicts is created when the metamethod selects different data mining methods with inconsistent competence maps for the objects of the intersected part. We analyze these two types of conflicts and their combinations and suggest ways to handle them.
index745!@#@!2003!@#@!An affine scaling trust-region approach to bound-constrained nonlinear systems!@#@!Applied Numerical Mathematics!@#@!This paper presents an iterative method for solving bound-constrained systems of nonlinear equations. It combines ideas from the classical trust-region Newton method for unconstrained nonlinear equations and the recent interior affine scaling approach for constrained optimization problems. The method generates feasible iterates and handles the bounds implicitly. It reduces to a standard trust-region method for unconstrained problems when there are no upper or lower bounds on the variables. Global and local fast convergence properties are obtained. The numerical performance of the method is shown on a large number of test problems.
index746!@#@!2000!@#@!Guide to the internet!@#@!Ubiquity!@#@!No matter where on earth, it isn't hard to find creative individuals who see the advantages that technology can confer.
index747!@#@!2001!@#@!Probabilistic Discriminative Kernel Classifiers for Multi-class Problems!@#@!Proceedings of the 23rd DAGM-Symposium on Pattern Recognition!@#@!null
index748!@#@!1994!@#@!Failure isolation and recovery in composite multidatabases!@#@!Proceedings of the 1994 conference of the Centre for Advanced Studies on Collaborative research!@#@!Most concurrency control schemes for guaranteeing global serializability in composite multidatabase systems are susceptible to rollbacks. Conservative schemes generate rollbacks because of transaction timeouts, while those of optimistic schemes are caused by certification failures. Typically, rollbacks on any branch of a flat distributed transaction cause a global abort. Global aborts during multidatabase composition degrade performance because of a waste of resources and reductions in multidatabase and local transaction throughputs at component database sites.This paper proposes a failure isolation scheme, based on nested transaction semantics, that attempts to contain multidatabase cell failures to a single cell. Also, given that certain conditions hold, failed transactions may be recovered within a cell and resubmitted without violating global serializability. This recovery scheme is applied to a composite multidatabase prototype.
index749!@#@!2003!@#@!The cache behaviour of large lazy functional programs on stock hardware!@#@!ACM SIGPLAN Notices!@#@!Lazy functional programs behave differently from imperative programs and these differences extend to cache behaviour. We use hardware counters and a simple yet accurate execution cost model to analyse some large Haskell programs on the x86 architecture. The programs do not interact well with modern processors---L2 cache data miss stalls and branch misprediction stalls account for up to 60% and 32% of execution time respectively. Moreover, the program code exhibits little exploitable instruction-level parallelism.We then use simulation to pinpoint cache misses at the instruction level. With this information we apply prefetching to minimise the cost of write misses, speeding up Haskell programs by up to 22%. We conclude with more ideas for changing the Glasgow Haskell Compiler and its garbage collector to improve the cache performance of large programs.
index750!@#@!2002!@#@!Artificial intelligence: an investigation into critical systems and swarm theory!@#@!Journal of Computing Sciences in Colleges!@#@!null
index751!@#@!2003!@#@!Inference, Modeling and Simulation of Gene Networks!@#@!Proceedings of the First International Workshop on Computational Methods in Systems Biology!@#@!null
index752!@#@!1999!@#@!A Parallel Generation System of Compact IDDQ Test Sets for Large Combinational Circuits!@#@!Proceedings of the 8th Asian Test Symposium!@#@!This paper presents a high performance compact IDDQ test generation system for detecting bridging faults, targeting large circuits. This system is based on the iterative-improvement-based method. We use two-level parallel processing technique for speeding up the test generation significantly, and invoke the assist of a deterministic ATPG for attaining 100% fault efficiency. The experimental results demonstrate its effectiveness.
index753!@#@!2002!@#@!Enterprise frameworks: issues and research directions!@#@!Software&mdash;Practice &amp; Experience!@#@!Enterprise frameworks are a special class of application frameworks. They are distinguished from other application frameworks in terms of scale and focus. In terms of focus, application frameworks typically cover one particular aspect of an application, either a domain-dependent aspect (e.g., billing in a web-based customer-to-business ordering system), or a computational infrastructure aspect such as distribution, man-machine interface, or persistence, etc. Generally, an application framework alone delivers no useful end-user function. With infrastructure frameworks, we still have to plug in domain functionalities, while with domain frameworks, we need to set-up the infrastructure. In contrast, enterprise frameworks embody a reference architecture for an entire application, covering both the infrastructure aspects of the application, and much of the domain-specific functionality. Instantiating an enterprise framework is nothing short of application engineering, where the architecture and many of the components are reusable. While creativity and continual improvement may be the major ingredients for building a good application framework, anything related to enterprise frameworks, be it building, documenting, or instantiating them, is complex and requires careful design and planning. In this paper, we identify the issues involved in building, using, and maintaining enterprise frameworks, both from research and practical perspective.
index754!@#@!1998!@#@!The Globus Project: A Status Report!@#@!Proceedings of the Seventh Heterogeneous Computing Workshop!@#@!null
index755!@#@!2001!@#@!Armada: A Parallel File System for Computational Grids!@#@!Proceedings of the 1st International Symposium on Cluster Computing and the Grid!@#@!High-performance distributed computing appears to be shifting away from tightly-connected supercomputers to "computational grids" composed of heterogeneous systems of networks, computers, storage devices, and various other devices that collectively act as a single geographically distributed "virtual" computer. One of the great challenges for this environment is providing efficient parallel data access to remote distributed datasets. In this paper, we discuss some of the issues associated with parallel I/O and computatational grids and describe the design of a flexible parallel file system that allows the application to control the behavior and functionality of virtually all aspects of the file system.
index756!@#@!2000!@#@!A Bit-Serial Implementation of the International Data Encryption Algorithm IDEA!@#@!Proceedings of the 2000 IEEE Symposium on Field-Programmable Custom Computing Machines!@#@!A high-performance implementation of the International Data Encryption Algorithm (IDEA) is presented in this paper. Using a novel bit-serial architecture to perform multiplication modulo 216 + 1, the implementation occupies a minimal amount of hardware. The bit-serial architecture enabled the algorithm to be deeply pipelined to achieve a system clock rate of 125MHz. An implementation on a Xilinx Virtex XCV300-4 was successfully tested, delivering a throughput of 500Mb/sec. With an XCV1000-6 device, the estimated performance is 2.35Gb/sec, three orders of magnitude faster than a software implementation on a 450MHz Intel Pentium II. This design is suitable for applications in on-line encryption for high-speed networks.
index757!@#@!1996!@#@!Design for Testability of Gated-Clock FSMs!@#@!Proceedings of the 1996 European conference on Design and Test!@#@!Gated clocks allow significant power savings in synchronous systems, but are generally considered an unsafe design practice because they decrease testability. In this paper we present two methodologies that guarantee full single-stuck-at testability for gated-clock finite-state machines. The first technique, increased observability, can be used in conjunction with redundancy-removal techniques to obtain fully-testable gated clock FSMs with high performance. The second technique, increased observability and controllability, is applicable to large FSMs for which redundancy removal is not possible and produces fully-testable gated-clock FSMs with a moderate decrease in performance.
index758!@#@!2002!@#@!Web-based analysis of data mining and decision support education!@#@!AI Communications!@#@!This note discusses some aspects of the international offer of machine learning, data mining and decision support education, based on investigations of the materials available on the world-wide web. The aim of this investigation was to provide starting points for an analysis that could be used to enhance the educational offer in this area in general, and knowledge transfer from academia to industry and business sector in particular. In addition to general findings concerning the collected materials such as contents, target audience, and teaching materials, we discuss issues such as connections with real-world problems. The work has been done as part of the activities of SolEuNet, a network of expert teams from academia and business sponsored by the European Commission, offering tools and expertise designed to meet customized data mining and decision support needs. For SolEuNet, the aim of the analysis of educational programs was to enhance its own educational offer by finding prospective market niches and by identifying useful guidelines for seminar and courses design. In this paper we report on these investigations with the aim of providing readers with insight into state of the art and trends of education in machine learning, data mining and decision support as reflected on the web, and to give useful links to materials that could help when designing and preparing courses.
index759!@#@!1991!@#@!Aliasing Probability in Multiple Input Linear Signature Automata for Q-ary Symmetric Errors!@#@!Proceedings of the 1991 IEEE International Conference on Computer Design on VLSI in Computer &amp; Processors!@#@!null
index760!@#@!2002!@#@!Managing tacit knowledge in knowledge-intensive firms: is there a role for technology?!@#@!Knowledge management in the sociotechnical world: the graffiti continues!@#@!null
index761!@#@!2000!@#@!Simulated Patient for Orthognathic Surgery!@#@!Proceedings of the International Conference on Computer Graphics!@#@!Orthognathic surgery corrects a wide range of minor and major facial and jaw irregularities. This surgery will improve the patients' ability to chew, speak and breathe. In many cases, a better appearance will also result. With the recent advances in virtual reality (VR) and three-dimensional (3D) medical imaging technology, orthognathic surgery simulations typically requires costly volumetric data acquisition modalities such CT or MRI imaging for patient modeling. In this paper, we present an approach for constructing 3D hard and soft tissue models of a patient based on color portraits and conventional radiographs. This allows patient modeling to be done efficiently on low-cost platforms. Specifically, we extend the techniques developed by the author in [2] to hard tissue modeling. The extended technique employs a user-assisted approach to obtain the 3D coordinates of the feature points of the human face and jaw respectively from conventional photographs and radiographs. Then correspondence matching and interpolation against a generic head model and jawbone model compute the displacement vectors of the feature points. The resulting combined hard and soft tissue models can be used for orthognathic surgical planning on a low-cost, PC-based platform.
index762!@#@!1995!@#@!Gibbs Sampler and Maximum Likelihood Estimation for Unsupervised Image Segmentations!@#@!Invited Session Papers from the Second Asian Conference on Computer Vision: Recent Developments in Computer Vision!@#@!null
index763!@#@!1986!@#@!Bestimmung globaler Bewegungsgr&ouml;&szlig;en von Objekten in Bildfolgen durch Auswertung lokaler Texturmerkmale angewandt auf spektrale Zellbildsequenzen!@#@!Mustererkennung 1986, 8. DAGM-Symposium!@#@!null
index764!@#@!1999!@#@!An Object-Oriented Formal Model for Software Project Management!@#@!Proceedings of the Sixth Asia Pacific Software Engineering Conference!@#@!An object-oriented OOPM model for project management and control is proposed in this paper. It employs object-oriented features, together with utilizing extended Petri net techniques, to provide for an sound specification of hierarchical structures of the software development process. In the model, object types specify the project activities and their accessed process components with a textual representation as well as a graphical representation; the generalization-specialization and whole-part features are utilized particularly in the hierarchical structure of object types to provide project managers at different levels with respective abstract levels of information about the project progress. With the specification of object types, an object model can be created which describes level by level the behaviors of activity objects and how they interact with component objects; an extended Petri net is used at the bottom level that specifies more detail how activity objects access component objects. To be practical for its applications, the OOPM model supports sufficient formality such that project managers can easily comprehend and monitor the development process; automatic tools can also be generated to facilitate specifying and monitoring the project.
index765!@#@!1998!@#@!Taylorian Initial Problems!@#@!Proceedings of the 12th European Simulation Multiconference on Simulation - Past, Present and Future!@#@!null
index766!@#@!1999!@#@!Scalability Analysis of Multidimensional Wavefront Algorithms on Large-Scale SMP Clusters!@#@!FRONTIERS!@#@!We develop a model for the parallel perform-ance of algorithms that consist of concurrent, two-dimensional wavefronts implemented in a message pass-ing environment. The model combines the separate con-tributions of computation and communication wavefronts. We validate the model on three supercomputer systems, with up to 500 processors, using data from an ASCI de-terministic particle transport application, although the model is general to any wavefront algorithm implemented on a 2-D processor domain. We also use the model to make estimates of performance and scalability of wave-front algorithms on 100-TFLOPS computer systems ex-pected to be in existence within the next decade. Our model shows that on a 1-billion-cell problem, single-node computation speed (not inter-processor communication performance, as is widely believed) is the bottleneck. Fi-nally, we present preliminary considerations that reveal the additional complexity associated with modeling wavefront algorithms on reduced-connectivity network topologies, such as clusters of SMPs.
index767!@#@!1992!@#@!Dreidimensionale Messung turbulenter Str&ouml;ung mit Bildverarbeitung!@#@!Mustererkennung 1992, 14. DAGM-Symposium!@#@!null
index768!@#@!2002!@#@!Optimal Seed Generation for Delay Fault Detection BIST!@#@!Proceedings of the 11th Asian Test Symposium!@#@!In delay fault detection BIST (Built-In-Self-Test),adjacency test pattern generation scheme can gener-ate robust test patterns effectively. Traditional adja-cency test pattern generation scheme uses LFSR togenerate initial vectors, they can not handle the cir-cuit with more than 30 inputs. In this paper, a de-termined BIST scheme where several seeds are appliedproposed. Based on analysis of independent partialcircuits in the circuit under test, an algorithm is usedgenerate the seeds, the small number of necessaryinitial vectors. Through combining outputs of shift reg-ister, the stage of shift register is reduced. Experimentsshow that the method of this paper has maximum faultcoverage, and short test length that means short testtime. The hardware overhead is in the same level withtraditional methods.
index769!@#@!2003!@#@!Value function and necessary conditions in optimal control problems for differential-difference inclusions!@#@!Nonlinear Analysis: Theory, Methods &amp; Applications!@#@!This paper deals with the optimal control problems for differential-difference inclusions subject to endpoint constraints. We follow a twofold goal. First, we develop a method for estimating the generalized gradients of value function in the problems above. Second, we use these estimates for obtaining necessary optimality conditions. The results obtained are expressed in terms of Clarke constructions for nonsmooth mappings and sets.
index770!@#@!2002!@#@!On the Parameterized Intractability of CLOSEST SUBSTRINGsize and Related Problems!@#@!Proceedings of the 19th Annual Symposium on Theoretical Aspects of Computer Science!@#@!null
index771!@#@!2003!@#@!Electronic access to information and the privacy paradox: rethinking practical obscurity and its impact on electronic freedom of information!@#@!Social Science Computer Review!@#@!This article addresses the U.S. Supreme Court's formulation of "practical obscurity" in Reporters Committee v. Department of Justice, a seminal case interpreting the U.S. Freedom of Information Act (FOIA). By examining lower federal court opinions interpreting Reporters Committee and by analyzing the effects of the Court's opinion on the implementation of the privacy exemptions of the FOIA, this article finds that the Court's opinion has greatly narrowed the scope of the FOIA and limited the power of the FOIA to democratize electronic information. Exemptions from the presumption of disclosure inherent in the FOIA were designed to balance the public's right to know against other competing interests. Historically, courts have balanced the public interest in disclosure against privacy interests when weighing privacy claims made under the FOIA. The Department of Justice argued for a change in this analysis, however, and in Reporters Committee successfully urged the adoption of a narrower definition of disclosable records. This new analysis expands the scope of privacy under the FOIA while it restricts the scope of acceptable public interest argurnents in favor of disclosure. This article demonstrates how the Court's decision in Reporters Committee-specifically, its formulation of practical obscurity as a value worth protecting-holds far-reaching implications for federal access law and for FOI laws around the world.
index772!@#@!2001!@#@!Codes Identifying Sets of Vertices!@#@!Proceedings of the 14th International Symposium on Applied Algebra, Algebraic Algorithms and Error-Correcting Codes!@#@!null
index773!@#@!1993!@#@!A Broader Class of Trees for Recursive Type Definitions for HOL!@#@!Proceedings of the 6th International Workshop on Higher Order Logic Theorem Proving and its Applications!@#@!null
index774!@#@!2002!@#@!On Optimal Hash Tree Traversal for Interval Time-Stamping!@#@!Proceedings of the 5th International Conference on Information Security!@#@!null
index775!@#@!2000!@#@!Program Committee!@#@!Proceedings of the International Symposium on Distributed Objects and Applications!@#@!null
index776!@#@!1995!@#@!Functional test generation for path delay faults!@#@!Proceedings of the 4th Asian Test Symposium!@#@!We present a novel test generation technique for path delay faults, based on the growth (G) and disappearance (D) faults of programmable logic arrays (PLA). The circuit is modeled as a PLA that is prime and irredundant with respect to every output. Certain tests for G faults, generated by using known efficient methods are transformed into tests for path delay faults. Our algorithm generates tests for all robustly detectable path delay faults in the two-level circuit and its multilevel implementation synthesized using algebraic transformations. Experimental results confirm that the generated vectors, beside robustly covering all path delay faults, also cover most stuck faults in the algebraically factored multilevel circuit. We present some of the best known timings and robust path delay fault coverages for the scan/hold versions of several ISCAS89 circuits, for which the PLA description could be obtained.
index777!@#@!2002!@#@!Model-Based Risk Assessment to Improve Enterprise Security!@#@!EDOC!@#@!The main objective of the CORAS project is to provide methods and tools for precise, unambiguous, and efficient risk assessment of security critical systems. To this end, we advocate a model-based approach to risk assessment, and this paper attempts to define the required models for this.Where as traditional risk assessment is performed without any formal description of the target of evaluation or results of the risk assessment, CORAS aims to provide well defined set of models well suited to (1) describe the target of assessment at the right level of abstraction, (2) as a medium for communication between different groups of stakeholders involved in a risk assessment, and (3) to document risk assessment results and the assumptions on which these results depend.We propose here models for each step in a risk assessment process and report results of use.
index778!@#@!1995!@#@!Analyzing and verifying locally clocked circuits with the concurrency workbench!@#@!Great Lakes Symposium on VLSI!@#@!Locally Clocked Modules (LCMs) allow asynchronous communication between synchronous computational elements. The concurrency workbench models concurrent systems in the CCS process algebra. We describe the use of the concurrency workbench to specify, simulate, and verify implementations of LCMs and discuss its application to the specification of asynchronous circuits.
index779!@#@!2002!@#@!Multi-dimensional aggregation of fuzzy numbers through the extension principle!@#@!Data mining, rough sets and granular computing!@#@!In this paper we propose the problem of obtaining a procedure to aggregate fuzzy numbers in such a way that the output is also a fuzzy number. To do this, we use the Zadeh's Extension Principle applied to multi-dimensional numerical functions which satisfy certain conditions, obtaining multi-dimensional aggregation functions on the lattice of fuzzy numbers. Special attention is given to the case of trapezoidal fuzzy numbers.
index780!@#@!1999!@#@!The Performance of a Real-Time I/O Subsystem for QoS-Enabled ORB Middleware!@#@!Proceedings of the International Symposium on Distributed Objects and Applications!@#@!There is increasing demand to extend Object Request Broker (ORB) middleware to support applications with stringent quality of service (QoS) requirements. However, conventional ORBs do not define standard features for specifying or enforcing end-to-end QoS for applications with deterministic real-time requirements. This paper describes the design and performance of a real-time I/O (RIO) subsystem optimized for QoS-enabled ORB endsystems that support high-performance and real-time applications running on off-the-shelf hardware and software. The paper illustrates how integrating a real-time ORB with a real-time I/O subsystem can reduce latency bounds on end-to-end communication between high-priority clients without unduly penalizing low-priority and best-effort clients.
index781!@#@!2003!@#@!The global error of Magnus methods based on the Cayley map for some oscillatory problems!@#@!Future Generation Computer Systems!@#@!This paper deals with numerical methods for the discretization of highly oscillatory systems. We approach the problem by writing the solution in terms of the Magnus expansion based on the Cayley map. The global error, obtained when the method is applied to the linear oscillator, is investigated. Moreover, we provide numerical experiments in order to validate our theoretical results.
index782!@#@!1998!@#@!Gaze Estimation Using Morphable Models!@#@!Proceedings of the 3rd. International Conference on Face & Gesture Recognition!@#@!null
index783!@#@!2000!@#@!On key distribution in secure multicasting!@#@!Proceedings of the 25th Annual IEEE Conference on Local Computer Networks!@#@!Multicasting has been widely utilized for delivering messages from one sender to multiple recipients. Nowadays in some applications such as pay per view or video-conferencing systems, the messages delivered via multicasting should be available to authorized recipients only. Therefore, secure multicasting becomes an important design issue in a distributed environment. To achieve secure multicasting, all authorized recipients form a group and share a group key; messages should be encrypted by the key before they are multicasted. For the sake of security, we need a new group key if someone joins/leaves the group. Consequently, our goal is aimed at finding a way to distribute the new key securely and efficiently. We propose a new solution to the problem; we distribute new keys through a special function called the secure filter. Compared with related work, our solution requires less system resources to change group members.
index784!@#@!2001!@#@!A Frequent Patterns Tree Approach for Rule Generation with Categorical Septic Shock Patient Data!@#@!Proceedings of the Second International Symposium on Medical Data Analysis!@#@!null
index785!@#@!1999!@#@!Landscape Design: Designing for Local Action in Complex Worlds!@#@!Organization Science!@#@!In recent years, the management literature has increasingly emphasized the importance of self-organization and "local action" in contrast to prior traditions of engineering control and design. While processes of self-organization are quite powerful, they do not negate the possibility of design influences. They do, however, suggest that a new set of design tools or concepts may be useful. We address this issue by considering the problem of landscape design-the tuning of fitness landscapes on which actors adapt. We examine how alternative organizational designs influence actors' fitness landscapes and, in turn, the behavior that these alternative designs engender. Reducing interdependencies leads to robust designs that result in relatively stable and predictable behaviors. Designs that highlight interdependencies, such as cross-functional teams, lead to greater exploration of possible configurations of actions, though at the possible cost of coordination difficulties. Actors adapt not only on fixed landscapes, but also on surfaces that are deformed by others' actions. Such couupled landscapes have important implications for the emergence of cooperation in the face of social dilemmas. Finally, actors' perceptions of landscapes are influenced by the manner in which they are framed by devices such as strategy frameworks and managerial accounting systems.
index786!@#@!2001!@#@!Supporting Cooperative Inter-organizational Business Transactions!@#@!Proceedings of the 12th International Conference on Database and Expert Systems Applications!@#@!null
index787!@#@!2003!@#@!Essentials of Constraint Programming!@#@!!@#@!null
index788!@#@!2000!@#@!VHDL Based Simulation of a Sigma-Delta A/D Converter!@#@!Proceedings of the 2000 IEEE/ACM international workshop on Behavioral modeling and simulation!@#@!The VHDL based mixed-signal event-driven (MixED) simulation method is employed to simulate a sigma-delta modulator for A/D conversion. Results are verified by experimental data and comparison to PSpice-AD simulations.
index789!@#@!2001!@#@!Spectral analysis of New York stock market prices!@#@!Essays in econometrics: Spectral analysis, seasonality, nonlinearity, methodology, and forecasting!@#@!New York stock price series are analyzed by a new statistical technique. It is found that short-run movements of the series obey the simple random walk hypothesis proposed by earlier writers, but that the long-run components are of greater importance than suggested by this hypothesis. The seasonal variation and the "business-cycle" components are shown to be of tittle or no importance and a surprisingly small connection was found between the amount of stocks sold and the stock price series.
index790!@#@!2003!@#@!A multistage stochastic programming algorithm suitable for parallel computing!@#@!Parallel Computing!@#@!In [Euro. J. Operat. Res. 143 (2002) 452; Opt. Meth. Software 17 (2002) 383] a Riccati-based primal interior point method for multistage stochastic programmes was developed. This algorithm has several interesting features. It can solve problems with a nonlinear node-separable convex objective, local linear constraints and global linear constraints. This paper demonstrates that the algorithm can be efficiently parallelized. The solution procedure in the algorithm allows for a simple but efficient method to distribute the computations. The parallel algorithm has been implemented on a low-budget parallel computer, where we experience almost perfect linear speedup and very good scalability of the algorithm.
index791!@#@!1999!@#@!Distribution issues in the design and implementation of a virtual market place!@#@!Proceedings of the IFIP WG 6.1 International Working Conference on Distributed Applications and Interoperable Systems II!@#@!null
index792!@#@!2002!@#@!Directions in the Use and Computation of Proximity Queries!@#@!GMP!@#@!Proximity queries include topics such as the computation of the distance between modelled objects, and static and dynamic collision detection. They are useful for object and assembly design, and are proving a vital ingredient of accurate animation and simulation. This paper summarises current directions in the computation and use of proximity queries, and gives a description of our work-in-progress towards making the solution of these queries faster throughthe use of specialised hardware.
index793!@#@!2003!@#@!Foreword!@#@!Journal of Computing Sciences in Colleges!@#@!null
index794!@#@!1998!@#@!CBIR in Medicine: Still a Long Way to Go!@#@!Proceedings of the IEEE Workshop on Content - Based Access of Image and Video Libraries!@#@!null
index795!@#@!1995!@#@!General Perfect Secret Sharing Schemes!@#@!Proceedings of the 15th Annual International Cryptology Conference on Advances in Cryptology!@#@!null
index796!@#@!1999!@#@!Using WAP as the Enabling Technology for CORBA in Mobile and Wireless Environments!@#@!Proceedings of the 7th IEEE Workshop on Future Trends of Distributed Computing Systems!@#@!CORBA is currently the most popular middleware platform. Due to the progress and acceptance of mobile communications, it is inevitable to offer CORBA services for mobile terminals, especially over a wireless link. The Object Management Group, the standardization body for CORBA, already requested proposals for extending CORBA in the wireless environment, leading to several submissions. However, the standardization process is far from being completed. Therefore, we propose the adaptation of an outstanding approach to supply a range of services in the mobile environment, the Wireless Application Protocol (WAP) framework. In the paper, we show how the CORBA standard and the WAP framework can converge, leading to a comprehensive middleware platform for distributed applications in a wireless and mobile environment.
index797!@#@!2003!@#@!Solving combinatorial exchanges: optimality via a few partial bids!@#@!Electronic Commerce!@#@!null
index798!@#@!2003!@#@!On homogeneous sets of positive integers!@#@!Journal of Combinatorial Theory Series A!@#@!The main result of this paper is the proof of the following partition property of the family of all two-element sets of the first n positive integers.There is a real constant C > 0 such that for every partition of the pairs of the set [n] = {1,2, ...,n} into two parts, there exists a homogeneous set H⊆[n] (i.e., all pairs of H are contained in one of the two partition classes) with min H ≥ 2 such that ∑h∈H1\logh ≥ C log log log log n/log log log log log n.This answers positively a conjecture of Erdös (see "On the combinatorial problems which I would most like to see solved", Combinatorica 1 (1981) 25).
index799!@#@!2003!@#@!Colour sorting in the food industry!@#@!Machine vision for the inspection of natural products!@#@!null
index800!@#@!1995!@#@!Stretching quasi delay insensitivity by means of extended isochronic forks!@#@!ASYNC!@#@!Handshake circuits can be mapped onto QDI circuits using generic standard-cells only. Despite several interesting optimizations, the resulting circuits are large. By extending the isochronic-fork assumption, we arrive at a class of asynchronous circuits that particularly allow efficient realizations of double-rail data paths. This paper defines the extended isochronic fork, discusses its implementation, and provides numerous examples. The impact on circuit costs is evaluated for a DCC error decoder. In an appendix a basic arbiter (mutual-exclusion element) is presented that requires simple CMOS gates only. We also propose a 3-way generalization of this arbiter.
index801!@#@!2000!@#@!Parallel Trellis Based Stereo Matching Using Constraints!@#@!Proceedings of the First IEEE International Workshop on Biologically Motivated Computer Vision!@#@!null
index802!@#@!2001!@#@!Estimation of common long-memory components in cointegrated systems!@#@!Essays in econometrics: collected papers of Clive W. J. Granger!@#@!The study of cointegration in large systems requires a reduction of their dimensionality. To achieve this, we propose to obtain the I(1) common factors in every subsystem and then analyze cointegration among them. In this article, a new way of estimating common long-memory components of a cointegrated system is proposed. The identification of these I(1) common factors is achieved by imposing that they be linear combinations of the original variables Xt, and that the error-correction terms do not cause the common factors at low frequencies. Estimation is done from a fully specified error-correction model, which makes it possible to test hypotheses on the common factors using standard chi-squared tests. Several empirical examples illustrate the procedure.
index803!@#@!2002!@#@!Triangulation of NURBS surfaces through adaptive refinement!@#@!Machine Graphics &amp; Vision International Journal!@#@!This paper discusses adaptive approach to the problem of automatic triangulation of NURBS surfaces. The algorithm presented here generates triangulation through the so-called adaptive refinement - a process carried out entirely in a parametric space with a variable triangle size adjusted to the local curvature of the surface, so that the imposed approximation error is not exceeded. The mesh is generated as an adaptive one right from the start, and no further decimation is required. Sample triangulations generated by the algorithm as well as a discussion of its computational complexity are included. Running times of the computer implementation confirm that an average computational cost of the algorithm is ∼ O(N), with N denoting the total number of triangles in the final mesh.
index804!@#@!2002!@#@!Exhibits!@#@!Designing Interactive Systems!@#@!null
index805!@#@!2002!@#@!Spatial web navigation with Perl!@#@!Sys Admin!@#@!null
index806!@#@!2003!@#@!Gang Scheduling in a Distributed System under Processor Failures and Time-Varying Gang Size!@#@!Proceedings of the The Ninth IEEE Workshop on Future Trends of Distributed Computing Systems!@#@!In this paper we study the performance of a distributed system which is subject to hardware failures and subsequent repairs. A special type of scheduling called gang scheduling is considered, under which jobs consist of a number of interacting tasks which are scheduled to run simultaneously on distinct processors. System performance is examined and compared in cases where different distributions for the number of parallel tasks per job (gang size) are employed. We examine cases where gang size is defined by a specific distribution and also a case where gang size distribution varies with time.
index807!@#@!1995!@#@!Representing Medical Context Using Rule-Based Object-Oriented Programming Techniques!@#@!Proceedings of the 5th Conference on Artificial Intelligence in Medicine in Europe: Artificial Intelligence Medicine!@#@!null
index808!@#@!2000!@#@!Integrated services to differentiated services packet forwarding: guaranteed service to expedited forwarding PHB!@#@!Proceedings of the 25th Annual IEEE Conference on Local Computer Networks!@#@!This paper outlines the design and simulation of a packet forwarding algorithm between integrated services and differentiated services network domains. The algorithm forward packets from guaranteed class-of-service flows into the expedited forwarding PHB. The algorithm is assumed to be implemented in a pipelined processor configuration that separate the input and output packet processing functions. The remaining jitter value is used to determine the packet forwarding priority. Measures of throughput and ratio of packet loss are given. From the simulation we learned that this algorithm yields to good packet throughput and tolerable packet loss ratio.
index809!@#@!1997!@#@!Zahnrestauration mittels Bilddeformation!@#@!Mustererkennung 1997, 19. DAGM-Symposium!@#@!null
index810!@#@!1997!@#@!Learning Symbolic Prototypes!@#@!Proceedings of the Fourteenth International Conference on Machine Learning!@#@!null
index811!@#@!2003!@#@!Analyzing usage of location based services!@#@!CHI '03 extended abstracts on Human factors in computing systems!@#@!FriendZone, a suit of mobile location-based community services has been launched. FriendZone's social services include Instant Messenger and Locator (IM&L), Location-based Chat, and Anonymous IM, with supporting Privacy Management. We describe the findings of a 16 months usage survey of 40,000 users, most of them young adults.The results indicate that Anonymous IM is the most popular service, more than IM&L, with lower use of Location-based Chat that was introduced last.
index812!@#@!2001!@#@!System Description: RDL : Rewrite and Decision Procedure Laboratory!@#@!Proceedings of the First International Joint Conference on Automated Reasoning!@#@!null
index813!@#@!1996!@#@!Maximal Length Common Non-intersecting Paths!@#@!Proceedings of the 8th Canadian Conference on Computational Geometry!@#@!null
index814!@#@!1995!@#@!Book review: Software Engineering Standards and Specifications: An Annotated Index and Directory by Stan Magee and Leanard L. Trip!@#@!ACM SIGSOFT Software Engineering Notes!@#@!null
index815!@#@!2003!@#@!A case study of methods of series summation: Kelvin-Helmholtz instability of finite amplitude!@#@!Journal of Computational Physics!@#@!We compute the singularities of the solution of the Birkhoff-Rott equation that governs the evolution of a planar periodic vortex sheet. Our approach uses the Taylor series obtained by Meiron et al. [J. Fluid Mech. 114 (1982) 283] for a flat sheet subject initially to a sinusoidal disturbance of amplitude a. The series is then summed by using various generalisations of the Padé method. We find approximate values for the location and type of the principal singularity as a ranges from zero to infinity. Finally, the results are used as a basis to guide the choice of methods of summing series arising from problems in fluid mechanics.
index816!@#@!2002!@#@!France!@#@!E-commerce law in Europe and the USA!@#@!null
index817!@#@!1998!@#@!System Description: CRIL Platform for SAT!@#@!Proceedings of the 15th International Conference on Automated Deduction: Automated Deduction!@#@!null
index818!@#@!2002!@#@!A Graphically Based Language for Constructing, Executing and Analysing Models of Software Systems!@#@!Proceedings of the 26th International Computer Software and Applications Conference on Prolonging Software Life: Development and Redevelopment!@#@!With computer systems becoming ever larger and more complex, the cost and effort associated with their construction is increasing and the systems are now sufficiently complex that developers need help to analyse and understand them. However, at design time, when this understanding is crucial, the system is unavailable because it has yet to be built. Formal, executable models can help with this problem by providing developers with a platform on which to establish the feasibility of a proposed design. However, commercial developers seemreluctant to employ this type of modelling in their design activity.This paper describes a modelling tool in which the traditional model generation technique of writing "programming language like" code is replaced with a model generation tool which uses a graphical representation of models whilst retaining sufficient formality to permit the models to be executed, or converted into code for analysis by a traditional model checking tool.
index819!@#@!2002!@#@!An Adaptive Admission Control Mechanism for a Cluster-Based Web Server System!@#@!Proceedings of the 16th International Parallel and Distributed Processing Symposium!@#@!null
index820!@#@!2003!@#@!Definitive XSL-FO!@#@!!@#@!:G. KEN HOLMAN is Chief Technology Officer for Crane Softwrights Ltd. and Canadian chair of the ISO SGML standards group. Ken is an invited expert to the W3C®, a member of the W3C Working Group that developed XML, and founder of the OASIS Technical Committees for XML and XSLT conformance. His many books on XML technologies include Definitive XSLT and XPath.About the Series EditorCHARLES F. GOLDFARB is the father of XML technology. He invented SGML, the Standard Generalized Markup Language on which both XML and HTML are based. You can find him on the Web at www.xmlbooks.com.
index821!@#@!1997!@#@!A Bridge for Heterogeneous Communication betwenn CORBA and DCE!@#@!Proceedings of the 4th International COST 237 Workshop on From Multimedia Services to Network Services!@#@!null
index822!@#@!2002!@#@!Using Ontologies in Virtual Brainstorming for Business Process Reengineering!@#@!Proceedings of the IFIP TC5/WG5.5 Third Working Conference on Infrastructures for Virtual Enterprises: Collaborative Business Ecosystems and Virtual Enterprises!@#@!null
index823!@#@!1997!@#@!Fast Table-Driven Algorithms for Interval Elementary Functions!@#@!ARITH!@#@!We present table-driven algorithms for computing interval bounds on several common elementary functions. Our algorithms use directed rounding to obtain sharp bounds---within 1.5 units in the last place of the exact range of the function over the argument interval---without the explicit use of extended precision. Moreover, by performing all floating point operations in the same rounding mode, our algorithms can exploit software pipelining to provide better performance than simply evaluating the corresponding point elementary function at each endpoint of the argument interval and rounding.
index824!@#@!2003!@#@!Force-coupling method for particulate two-phase flow: stokes flow!@#@!Journal of Computational Physics!@#@!In this paper we describe a force-coupling method for particle dynamics in fluid flows. The general principles of the model are described and it is tested on three different Stokes flow problems; a single isolated sphere, a pair of otherwise isolated spheres, and a single sphere in a channel. For sphere to sphere or sphere to wall distances larger than 1/4 of the sphere radius the force-coupling results compared well with analytical and accurate numerical values. For smaller distances the results agree qualitatively, but lubrication effects are not included and this leads to a quantitative discrepancy.
index825!@#@!2003!@#@!Nuts and Bolts!@#@!IEEE Micro!@#@!null
index826!@#@!2003!@#@!Relevance Feedback and Learning in Content-Based Image Search!@#@!World Wide Web!@#@!A major bottleneck in content-based image retrieval (CBIR) systems or search engines is the large gap between low-level image features used to index images and high-level semantic contents of images. One solution to this bottleneck is to apply relevance feedback to refine the query or similarity measures in image search process. In this paper, we first address the key issues involved in relevance feedback of CBIR systems and present a brief overview of a set of commonly used relevance feedback algorithms. Almost all of the previously proposed methods fall well into such framework. We present a framework of relevance feedback and semantic learning in CBIR. In this framework, low-level features and keyword annotations are integrated in image retrieval and in feedback processes to improve the retrieval performance. We have also extended framework to a content-based web image search engine in which hosting web pages are used to collect relevant annotations for images and users' feedback logs are used to refine annotations. A prototype system has developed to evaluate our proposed schemes, and our experimental results indicated that our approach outperforms traditional CBIR system and relevance feedback approaches.
index827!@#@!1997!@#@!Nice Drawings for Planar Bipartite Graphs!@#@!Proceedings of the Third Italian Conference on Algorithms and Complexity!@#@!null
index828!@#@!2000!@#@!Compact Spiking Neural Network Implementation in FPGA!@#@!Proceedings of the The Roadmap to Reconfigurable Computing, 10th International Workshop on Field-Programmable Logic and Applications!@#@!null
index829!@#@!2002!@#@!Graphs and trees!@#@!International Conference on Knowledge Discovery and Data Mining!@#@!null
index830!@#@!1996!@#@!Principle and technique for encapsulation of user control and data information in separate frames!@#@!Proceedings of the 21st Annual IEEE Conference on Local Computer Networks!@#@!Present and future communication services require the integration of data and media applications to provide real-time interactive multimedia services that are reliable and secure. The popularity of the World Wide Web provides a glimpse into the potential of distributed multimedia application services. However, the Internet protocol, TCP/IP, does not have the provisions to adequately handle future real-time interactive multimedia services. Present network protocols are programmed to view and treat all user information packets alike, since application (user) control and data information are bundled within the same packet. The ATM protocol provides more flexible multimedia transmission services for dynamic and static types of information. This paper proposes techniques for enhancing the ATM protocol to enable the support of application communication services as well as network communication services. The paper advocates strict enforcement of the encapsulating of user-control and user-data information in separate and discrete frames at the network-level so that unique application communication services can be specified for the disparate application information traffics. The paper proposes the ability to identify user control and data messages at the network-level. The objective of this paper is to provide an understanding of a new protocol, which provides the capability to optimize services to each of the disparate types of traffic and facilitates the integration of media and data applications. The proposed frame adaptation layer (FAL) protocol enables the various network protocols to be aware of the required application class-of-services and provides the appropriate network services which facilitates traffic shaping and policing.
index831!@#@!2003!@#@!The paradigm is more important than the purchase: educational innovation and hypertext theory!@#@!Digital media revisited: theoretical and conceptual innovation in digital domain!@#@!null
index832!@#@!2000!@#@!Message from the Program Chair!@#@!Proceedings of the 9th Heterogeneous Computing Workshop!@#@!null
index833!@#@!2002!@#@!A Fault-Tolerant FPGA-based Multi-Stage Interconnection Network for Space Applications!@#@!DELTA!@#@!Current space applications are pushing for improved on-board processing abilities, in terms of higher computing power, flexibility and fault-resistance, in order to keep up with the huge amount of collected scientific data. Multiprocessor systems seem a viable solution to match these requisites. In particular, systems employing Multistage Interconnection Networks (MINs) offer the advantage of an effective resource allocation, depending on variable workloads and occurrence of faults. The paper presents a fault-tolerant interconnection mechanism, based on redundant MIN, for multi-sensor systems. The proposed system is implemented by means of Field Programmable Gate Arrays (FPGAs) and allows a flexible re-organization of computing resources in dependence of varying operating conditions. Fault-tolerance is achieved both by exploiting the MIN intrinsic redundancy and by using an efficient FPGA re-configuration technique.
index834!@#@!2003!@#@!A flux-split algorithm applied to conservative models for multicomponent compressible flows!@#@!Journal of Computational Physics!@#@!In this paper we consider a conservative extension of the Euler equations for gas dynamics to describe a two-component compressible flow in Cartesian coordinates. It is well known that classical shock-capturing schemes applied to conservative models are oscillatory near the interface between the two gases. Several authors have addressed this problem proposing either a primitive consistent algorithm [J. Comput. Phys. 112 (1994) 31] or Lagrangian ingredients (Ghost Fluid Method by Fedkiw et al. [J. Comput. Phys. 152 (1999) 452] and [J. Comput. Phys. 169 (2001) 594]). We solve directly this conservative model by a flux-split algorithm, due to the first author (see [J. Comput. Phys. 125 (1996) 42]), together with a high-order (WENO5) flux reconstruction [J. Comput. Phys. 115 (1994) 200; 83 (1989) 32]. This algorithm seems to reduce the oscillations near the interfaces in a way that does not affect the physics of the experiments. We validate our algorithm with the numerical simulation of the interaction of a Mach 1.22 shock wave impinging a helium bubble in air, under the same conditions studied by Haas and Sturtevant [J. Fluid Mech. 181 (1987) 41] and successfully simulated by Quirk and Karni [J. Fluid Mech. 318 (1996) 129].
index835!@#@!2003!@#@!Pivot Vector Space Approach for Audio-Video Mixing!@#@!IEEE MultiMedia!@#@!An audio-mixing artist usually adds the musicalaccompaniment to video. Employing such artists isexpensive and not feasible for a home videopresentation. Our automatic audioývideo mixingtechnique is suited for home videos. It uses a pivotvector space mapping method that matches video shotswith music segments based on aestheticcinematographic heuristics.
index836!@#@!2003!@#@!Synthesis of continuous-time filters and analog to digital converters by integrated constraint transformation, floorplanning and routing!@#@!Great Lakes Symposium on VLSI!@#@!This paper describes a layout-aware analog synthesis methodology. The methodology includes parameter exploration and classification, parameter domain pruning and sampling, and identification of parameter dependencies. The optimization process executes a combined constraint transformation, floorplanning and global routing. The paper presents results for a high frequency continuous-time filter, and two ̿Δ ADCs. Compared to similar work, the methodology is more flexible in handling new designs, and more tolerant in accommodating layout parasitics.
index837!@#@!2003!@#@!Business models and market mechanisms: evaluating efficiencies in consumer electronic markets!@#@!ACM SIGMIS Database!@#@!The paper examines business models utilizing three different market mechanisms on the Internet: direct search, broker, and dealer. Utilizing capital markets and information theory to compare the business models, the research looks at specific market mechanisms instantiated in PriceScan, NetMarket, and Bottom Dollar. The web sites supporting the market structures were also evaluated on trust mechanisms, reputational ratings, information quality, availability, speed, and liquidity. Twenty standard, consumer products offered through these markets were evaluated over a three-month period examining pricing, availability, and speed of response.There were significant differences across the three models. Direct search and broker models had the highest availability and quickest response. Brokers made the greatest use of trust mechanisms. Direct search and dealers offered the greatest liquidity. Information quality was the highest in the dealer, with strong market, price movement, and product information. Lowest overall prices were consistently evident in the direct search. Allocational efficiency was difficult to determine, but an evaluation of the earlier efficiencies suggests that in situations where consistent market availability is not required, overall the direct search model is the most allocationally efficient. In situations requiring immediate market availability, the broker model appears to be the most allocationally efficient with quick response, competitive prices, and good information quality.The paper extends earlier work in business models and market efficiencies by comparing specific instantiations of the models and developing definitions for and a typology of efficiencies based on capital markets theory. In addition, the paper includes technical and qualitative analysis of Web sites supporting the business models.
index838!@#@!2002!@#@!Meteo: A Telephone-Based Portuguese Conversation System in Weather Domain!@#@!Proceedings of the Third International Conference on Advances in Natural Language Processing!@#@!null
index839!@#@!2002!@#@!Representation of digital image by fuzzy neural network!@#@!Fuzzy Sets and Systems!@#@!A multilayer feedforward fuzzy neural network(FNN), by which the predetermined fuzzy system can be realized is constructed to express a given two-dimensional (2-D) digital image. It is shown that such a network is universal approximator. The FNN approach provides us with the representation model of the 2-D discrete image. In noise environment some given fuzzy numbers are employed to describe gray levels of a digital image and the deviation of corrupted image to its noise-free one. A class of fuzzy rules for removing impulse noise in degraded image are presented. The corresponding FNN may work as a filter, which improves the performances of median and rank-conditioned rank selection filters. Especially, such a filter may to a greatest extent maintain the fine structure of the image. Under the minimum mean absolute error criterion the membership functions of fuzzy numbers are adaptively adjusted, and an optimal FNN for image representation is derived in noise environment. Simultaneously some real image examples are systemically analyzed to show that the FNN may result in higher quality global restoration.
index840!@#@!1997!@#@!Foreword!@#@!ARVLSI!@#@!This special issue of Mathematical Structures in Computer Science is devoted to the Proceedings of the International Workshop Logic, Domains, and Programming Languages that took place from May 24 to 27, 1995, in Darmstadt, Germany.
index841!@#@!2000!@#@!Towards the Automatic Assessment of Evolvability for Reusable Class Libraries!@#@!Automated Software Engineering!@#@!Many sources agree that managing the evolution of an OO system constitutes a complex and resource-consuming task. This is particularly true for reusable class libraries, as the user interface must be preserved to allow for version compatibility. Thus, the symptomatic detection of potential instabilities during the design phase of such libraries may serve to avoid later problems. This paper presents a fuzzy logic-based approach for evaluating the interface stability of a reusable class library, by using structural metrics as stability indicators.
index842!@#@!2002!@#@!Retransmission Tree Configuration for Reliable Multicast Protocols!@#@!Revised Papers from the International Conference on Information Networking, Wireless Communications Technologies and Network Applications-Part II!@#@!null
index843!@#@!2001!@#@!Message from the Program Chairs!@#@!Proceedings of the Fifth European Conference on Software Maintenance and Reengineering!@#@!null
index844!@#@!2003!@#@!Foundations of Sequence-Based Software Specification!@#@!IEEE Transactions on Software Engineering!@#@!Rigorous specification early in the software development process can greatly reduce the cost of later development and maintenance, as well as provide an explicit means to manage risk and identify and meet safety requirements. Sequence-based software specification is a collection of techniques for implementing rigorous, practical software specification. The primary result of this research is the sequence enumeration method of specification writing. Straightforward, systematic enumeration of all sequences to produce an arguably complete, consistent, and traceably correct specification is made practical by controlling the growth of the process.
index845!@#@!1996!@#@!Power Optimization of Delay Constrained CMOS Bus Drivers!@#@!Proceedings of the 1996 European conference on Design and Test!@#@!The design automation of minimum power delay-constrained CMOS Bus Drivers for library-based (standard cells) and full-custom design environments is presented in this paper. The effect of the short circuit current consumption is taken into account in the total power evaluation. The proposed methodology is applied to efficiently find the optimum selection of buffers for any given bus load and delay constraint. Analytical predictions and results show good agreements with time costly SPICE simulations and reflect the need of variable taper factors for low power buffers in synchronous CMOS digital circuits.
index846!@#@!2001!@#@!Efficient Feature Mining in Music Objects!@#@!Proceedings of the 12th International Conference on Database and Expert Systems Applications!@#@!null
index847!@#@!2000!@#@!Experiences Reverse Engineering Manually!@#@!Proceedings of the Conference on Software Maintenance and Reengineering!@#@!Better understanding manual reverse engineering can make it and any associated systems reengineering more effective. We reverse engineered a version of a system (referred to as "BOS/X") in support of a broader reengineering effort. System reengineering goals and other circumstances dictated a focused, limited duration, manual reverse engineering exercise. This presented an opportunity to study the BOS/X reverse engineering separately from other reengineering activities. We studied the BOS/X reverse engineering, the results achieved, and some limited reverse engineering metrics. This paper describes the: systems reengineering context; circumstances preventing application of automated techniques and motivating manual reverse engineering; reverse engineering process developed; BOS/X reverse engineering goals; evolution of the reverse engineering products; re-verse engineering results; resources required to produce the results; and an evaluation of the reverse engineering effectiveness. Combined, these results may be used as measures - standards of comparison - that can be studied further - for example to determine potential areas for future automation application.
index848!@#@!2001!@#@!Multiscale Segmentation of Document Images Using M -Band Wavelets!@#@!Proceedings of the 9th International Conference on Computer Analysis of Images and Patterns!@#@!null
index849!@#@!2003!@#@!New tips and tricks for a better usability test!@#@!CHI '03 extended abstracts on Human factors in computing systems!@#@!In this SIG, experienced usability testers will exchange tips and tricks for practical usability testing.
index850!@#@!1996!@#@!Finding an o(n2 log n) Algorithm Is Sometimes Hard!@#@!Proceedings of the 8th Canadian Conference on Computational Geometry!@#@!null
index851!@#@!2003!@#@!Continuity of DEA Efficiency Measures!@#@!Operations Research!@#@!Data envelopment analysis (DEA) is a methodology that allows, in one way or other, the assignment of efficiency scores to members of a group of decision-making units. We call an efficiency measure "continuous" if small perturbations of the input-output data cause only small changes in the score. Continuity is a desirable property of an efficiency measure, in particular in the presence of measurement tolerances. Continuity is also desirable from a numerical point of view because the scores are computed by linear programming software.Focusing on convex production possibility sets, we give examples where radial DEA measures fail to be continuous, i.e., they "jump" under small data perturbations. We present necessary and sufficient conditions for continuity in terms of the data and show that these conditions are satisfied for "almost all" data. We also discuss continuity of nonradial measures and identify possible problems of "multistage approaches" to compute mix efficiencies.
index852!@#@!2000!@#@!A New Multicast Technique for Video Transmission over ABR Services in ATM Networks!@#@!Proceedings of the IFIP TC6 WG6.7 Sixth International Conference on Intelligence in Networks: Telecommunication Network Intelligence!@#@!null
index853!@#@!1997!@#@!Message from the Symposium Chairs!@#@!1997 Workshop on Defect and Fault-Tolerance in VLSI Systems!@#@!null
index854!@#@!1992!@#@!A Type-Coercion Problem in Computer Algebra!@#@!Proceedings of the International Conference on Artificial Intelligence and Symbolic Mathematical Computation!@#@!null
index855!@#@!1998!@#@!System Description: leanK 2.0!@#@!Proceedings of the 15th International Conference on Automated Deduction: Automated Deduction!@#@!null
index856!@#@!2000!@#@!FEC and Pseudo-ARQ for Receiver-Driven Layered Multicast of Audio and Video!@#@!Proceedings of the Conference on Data Compression!@#@!We consider the problem of joint source/channel coding of real-time sources, such as audio and video, for the purpose of multicasting over the Internet. The sender injects into the network multiple source layers and multiple channel (parity) layers, some of which are delayed relative to the source. Each receiver subscribes to the number of source layers and the number of channel layers that optimizes the source-channel rate allocation for that receiver's available bandwidth and packet loss probability.We augment this layered FEC system with layered ARQ. Although feedback is normally problematic in broadcast situations, ARQ is simulated by having the receivers subscribe and unsubscribe to the delayed channel coding layers to receive missing information. This pseudo-ARQ scheme avoids an implosion of repeat requests at the sender, and is scalable to an unlimited number of receivers. We show gains of up to 18 dB on channels with 20% loss over systems without error control, and additional gains of up to 13 dB when FEC is augmented by pseudo-ARQ in a hybrid system. The hybrid system is controlled by an optimal policy for a Markov decision process.
index857!@#@!1990!@#@!Secure User Access Control for Public Networks!@#@!Proceedings of the International Conference on Cryptology: Advances in Cryptology!@#@!null
index858!@#@!1997!@#@!ATREX: Design for Testability System for Mega Gate LSIs!@#@!Proceedings of the 6th Asian Test Symposium!@#@!We propose a Design for Testability System for Mega Gate LSIs. This system meets various demands of designers, because this system has high flexibility. We show the flexibility by introducing some example of circuit insertion which is supported by the system.
index859!@#@!1999!@#@!Automatic Structuring of Written Texts!@#@!Proceedings of the Second International Workshop on Text, Speech and Dialogue!@#@!null
index860!@#@!2002!@#@!Fault Simulation Method for Crosstalk Faults in Clock-Delayed Domino CMOS Circuits!@#@!DELTA!@#@!In recent years, domino logic circuits have received much attention as high-speed circuits by taking place of static CMOS circuits. However, in case of standard domino logic, only non-inverting gates are allowed. Then, clock-delayed (CD) domino logic that provides any logic function is proposed in order to overcome such domino's drawback. In addition, domino circuits are more sensitive to circuit noises compared with static CMOS circuits. In particular, crosstalk can induce critical problems. Therefore, we focus our attention on faulty operations induced by crosstalk in CD domino circuits and propose a new fault simulation method. We realize CD domino logic in VHDL and simulate on a VHDL simulator. We performed experiments for the combinational part of some benchmark circuits of ISCAS'89. And fault coverage for random vectors was obtained from s27 to s1494 under the limitation of simulation time.
index861!@#@!2002!@#@!Distributed multiprocessor environments!@#@!Journal of Computing Sciences in Colleges!@#@!This paper discusses the material included in a seminar for seniors and graduate students on distributed parallel processing offered as an experimental course at Eastern Washington University in the Fall 2000 and Winter 2002 quarters, along with the difficulties discovered as the courses progressed.
index862!@#@!1998!@#@!A Hierarchical Approach for Dependability Analysis of a Commercial Cache-Based RAID Storage Architecture!@#@!Proceedings of the The Twenty-Eighth Annual International Symposium on Fault-Tolerant Computing!@#@!null
index863!@#@!2002!@#@!Networks analysis, complexity, and brain function!@#@!Complexity!@#@!null
index864!@#@!2002!@#@!Cover: this is CNN...breaking into digital asset management!@#@!Storage Management Solutions!@#@!null
index865!@#@!1981!@#@!A few Remarks on Putting Formal Specifications to Productive Use!@#@!Program Specification, Proceedings of a Workshop!@#@!null
index866!@#@!1996!@#@!Group, majority, and strict agreement in timed asynchronous distributed systems!@#@!FTCS!@#@!Atomic broadcast is a group communication service that enables a team of distributed processes to keep replicated data 'consistent', despite concurrency, communication uncertainty, failures and recoveries. We investigate possible meanings for replicated data 'consistency' in timed asynchronous systems, subject to crash/performance process failures and omission/performance communication failures which may partition correct team members into isolated parallel groups. We propose three different replica consistency specifications: group agreement, majority agreement and strict agreement and give examples of atomic broadcast protocols that implement these specifications. The interface issues between the underlying membership services and the broadcast protocols that provide the above semantics are also addressed.
index867!@#@!2003!@#@!A better upper bound on the number of triangulations of a planar point set!@#@!Journal of Combinatorial Theory Series A!@#@!We show that a point set of cardinality n in the plane cannot be the vertex set of more than O(59nn-6) straight-edge triangulations of its convex hull. This improves the previous upper bound of 276.75n+O(log(n)).
index868!@#@!1995!@#@!A Gauss-elimination based PRPG for combinational circuits!@#@!Proceedings of the 1995 European conference on Design and Test!@#@!A new algorithm for the reseeding of multiple polynomial LFSR for pseudorandom test pattern generation (PRPG) is proposed in this paper. It is based on the Gauss-elimination procedure and the deterministic test set generated by an ATPG software system for combinational circuits. In addition to the general LFSR model, we also provide two further improvements, ms1p and 1smp, to minimize the hardware overhead. Experimental results were obtained on ISCAS-85 benchmark circuits to demonstrate the effectiveness of this methodology. Complete fault coverage is achieved in all circuits. Low hardware overhead is also maintained with a reasonable test length.
index869!@#@!1996!@#@!Design of a Real-Time Co-Operating System for Multiprocessor Workstations!@#@!Proceedings of the 29th Hawaii International Conference on System Sciences Volume 1: Software Technology and Architecture!@#@!We have designed a Real-Time Co-Operating System (RTCOS) for simultaneously supporting real-time and non-real-time activities on a workstation with two or more processors. The RTCOS is the software equivalent of a co-processor, with a software architecture analogous to the hardware architecture that has been used in many workstations and personal computers. In this paper, we discuss our first software prototype of the RTCOS, which co-exists with Solaris 2.4 on a four-processor Sun SPARCstation 20. We summarize the feasibility of our approach through an experimental characterization of Solaris 2.4. We address the technical issues involved and present the details of our design. The RTCOS is targeted towards real-time applications in the sensor-based control, process control, signal processing, multimedia, and manufacturing domains.
index870!@#@!1990!@#@!LAPAS: A Performance Evaluation Tool for Large Parallel Systems!@#@!Architektur von Rechensystemen, Tagungsband, 11. ITG/GI-Fachtagung!@#@!null
index871!@#@!1981!@#@!Grammars Without Erasing Rules - The OI Case!@#@!Proceedings of the 6th Colloquium on Trees in Algebra and Programming!@#@!null
index872!@#@!1986!@#@!Wissensgesteuerte Formular interpretation mit Hilfe von Petrinetzen!@#@!Mustererkennung 1986, 8. DAGM-Symposium!@#@!null
index873!@#@!2003!@#@!On the Convergence of Difference Schemes for Hyperbolic Problems with Concentrated Data!@#@!SIAM Journal on Numerical Analysis!@#@!Hyperbolic equations with unbounded coefficients and even generalized functions (in particular, Dirac-delta functions) occur both naturally and artificially and must be treated in numerical schemes. An abstract operator method is proposed for studying these equations. For finite difference schemes approximating several one-dimensional initial-boundary value problems convergence rate estimates in special discrete energetic Sobolev's norms, compatible with the smoothness of the solutions, are obtained.
index874!@#@!2003!@#@!Low tech-high concept: digital media, art, and the state of the arts!@#@!Digital media revisited: theoretical and conceptual innovation in digital domain!@#@!null
index875!@#@!2002!@#@!Modeling for environmental impacts using experimental data!@#@!Development and application of computer techniques to environmental studies!@#@!Existing methods that assess the environmental impact often mandate an in depth understanding of the process or product mechanics. To overcome the complexity, the approach presented in this paper extracts the environmental impacts of a bench-top apparatus using Data Dependent Systems (DDS) methodology. The focus is on experimental evaluation of the environmental impacts of a bench-top heat exchanger system which simulates an industrial drying process. Collected measurements are used to develop DDS models from which an environmental profile is established for the heat exchanger. Results from the heat exchanger study provide insight into how the environmental impact of the industrial drying process may be reduced. Statistical design of experiments determines the significance of design variables. The process is quantified using characteristic roots of the DDS models providing natural frequencies and damping ratios, and these are subsequently associated with the environmental performance. Typical examples of DDS models are presented and their association with the environmental impact is demonstrated.
index876!@#@!2002!@#@!Hardware Architecture for Java in a Hardware/Software Co-Design of the Virtual Machine!@#@!Proceedings of the Euromicro Symposium on Digital Systems Design!@#@!This paper discusses the hardware architecture used in the hw/sw co-design of a Java virtualmachine. The paper briefly outlines the partitioning of instructions and support for the virtual machine. Discussion concerning the hardware architecture follows focusing on the special requirements that must be considered for the target environment. A comparison is performed between this design and that of picoJava, a stand-alone processor for Java. The paper concludes with benchmark results for this architecture compared with software execution.
index877!@#@!2002!@#@!An optimal and programmable control strategy for flexible and standard active filtering under non-sinusoidal line voltages!@#@!Iranian Journal of Science and Technology!@#@!This paper describes the concept of load compensation under distorted voltages conditions. At these conditions, unity power factor achievement requires the compensated loads to have a current set like the voltages and so it will be non-sinusoidal. Conversely, the perfect compensation of current harmonics will result in a power factor lower than unity. Both the harmonics and power factor compensation are of the well known and very important concepts. This paper introduces several new compensation strategies, which can compromise between power factor and current harmonics. Following these strategies a generalized, optimal and flexible control strategy (OFC) for harmonic compensation of utility lines using Active Power Filter (APF) systems is proposed that can realize a wide range of suitable compensation strategies. The major contribution of this paper is developing the required structure and control algorithm of the needed control system. The control strategy is based on the new compensation concept for power quality improvement under non-sinusoidal line voltage situations. It provides a unified compensation framework and has the ability of programming for perfect current harmonics compensation, or Unity Power Factor (UPF) accomplishment, or other newly defined strategies. One of the defined suitable strategies has the ability of maximizing the power-factor subject to some adjustable constraints on the level of current harmoincs and unbalancing via an on-line optimization algorithm to fulfill the IEEE-519 or other desired standards. The strategy guarantees the best achievable power factor and minimum required rating for the compensator. Flexibility of the control strategy has been proved mathematically and verified using extensive simulation results.
index878!@#@!2003!@#@!Reviews and descriptions of tables and books!@#@!Mathematics of Computation!@#@!null
index879!@#@!2002!@#@!Newsline!@#@!Computers in Libraries!@#@!null
index880!@#@!1998!@#@!Learners Interface of a CAL System for Foreign Students to Learn Hiragana/Katakana Characters!@#@!Proceedings of the Third Asian Pacific Computer and  Human Interaction!@#@!null
index881!@#@!1991!@#@!Knowledge-Based Media Coordination in Intelligent User Interfaces!@#@!Proceedings of the 2nd Congress of the Italian Association for Artificial Intelligence on Trends in Artificial Intelligence!@#@!null
index882!@#@!2000!@#@!ISYDES: The Project of a Tool Aimed at Information System Development!@#@!Proceedings of the Academia/Industry Working Conference on Research Challenges!@#@!In this paper, the authors illustrate the main functionalities and development methodologies of the ISYDES (Information System DEsign Support) system, a CASE tool for information system (IS) design and development. Such a tool is mainly composed of two software tools: the former allows the definition of the static structure of data, whereas the latter allows the whole specification of all functions, which constitute the dynamic part of an IS. This second step is very important in the design phase of an IS, as all the IS operations and processes are based on the specification of such functions. The proposed ISYDES tool adopts an object/oriented approach to the IS conceptual design; in particular it provides a way to specify the information processes that can be easily translated in the actual IS coded procedures.
index883!@#@!2000!@#@!Object Recognition Results Using MSTAR Synthetic Aperture Radar Data!@#@!CVBVS!@#@!This paper outlines an approach and experimental results for Synthetic Aperture Radar (SAR) object recognition using the MSTAR data. With SAR scattering center locations and magnitudes as features, the invariance of these features is shown with object articulation (e.g., rotation of a tank turret) and with external configuration variants. This scatter location and magnitude quasi-invariance issued as a basis for development of a SAR recognition system that successfully identifies articulated and non-standard configuration vehicles based on non-articulated, standard recognition models. The forced recognition results and pose accuracy are given. The effect of different confusers on the receiver-operating characteristic (ROC) curves is illustrated along with ROC curves for configuration variants, articulations and small changes in depression angle. Results are given that show that integrating the results of multiple recognizers can lead to significantly improved performance over the single best recognizer.
index884!@#@!2002!@#@!Visual data navigators ("collaboratories"): true interactive visualisation for the web!@#@!Intelligent agents for mobile and virtual media!@#@!The contents in Web documents are normally restricted to static items such as text, imagery and animations. "SmartDoc" has developed "Collaboratories" (Web application components) that incorporate not only text but also the entire interactive data visualisation and navigation process into a Web document, allowing users and project teams to collaborate and share data, visualisation parameters, information and insight while distributed over the standard or mobile Internet, using intuitive visual navigation techniques. In other words, publishing a text document on the Web is only half the story. The other half is enabling others to interact with the published result and gain insight into context that is meaningful."SmartDoc" is a research project jointly funded by the EC Commission and focus on embedded Collaboratories that give the reader full access to any discovery and insight, data navigation tools and underlying data. Visual data navigation is provided through interactive 2D and 3D Web-based visualisation components with a small footprint. The "discovery" is described in one or several snapshots providing the history of the visualisation process.These snapshots are a copy of the component's state at the time when the snapshot was taken and allow the user to further interact from the state when the visualisation was snapped. They can be included as an image for printing the document. The underlying data or spreadsheet is either embedded in the document or accessed through a hyperlink. "What are users looking for?" is the key question guiding a SmartDoc process.The Collaboratories (Application Components) are based an multi-layer visualisation component architecture with a small footprint suitable for Web distribution and therefore scalable and customisable to any level of expertise. A "SmartViewer" client-side plug-in, responsible for interactivity and graphics rendering, has been developed and will be distributed as "freeware"to allow free distribution of a SmartDoc on the network. Integration and assessment of application component-sharing through Web documents and a network infrastructure based on component industry standards, providing real-time data interactivity, reducing the load on the network and with zero administration client deployment.SmartDoc scales to accommodate massive amounts of data presented in a visual format, allows full real-time interaction with on-screen presentations, and gives users an unprecedented level of high-quality visual presentation. Our integration of visualisation and data analysis through an atomic component architecture combined with special data reduction components and fast scene tree rendering by the SmartViewer enables the visual data navigation of large data sets.
index885!@#@!1997!@#@!Automatic synthesis of recursive programs: the proof-planning paradigm!@#@!Automated Software Engineering!@#@!We describe a proof plan that characterises a family of proofs corresponding to the synthesis of recursive functional programs. This plan provides a significant degree of automation in the construction of recursive programs from specifications, together with correctness proofs. This plan makes use of meta-variables to allow successive refinement of the identity of unknowns, and so allows the program and the proof to be developed hand in hand. We illustrate the plan with parts of a substantial example-the synthesis of a unification algorithm.
index886!@#@!1991!@#@!Estimation of Discontinuous Displacement Vector Fields with the Minimum Description Length Criterion!@#@!Mustererkennung 1991, 13. DAGM-Symposium!@#@!null
index887!@#@!2003!@#@!Low-temperature combustion synthesis and characterization of nanosized tetragonal barium titanate powders!@#@!Microelectronic Engineering!@#@!Nanosized tetragonal barium titanate has been directly prepared by low-temperature combustion synthesis process (LCS). According to thermochemical calculations of propellant chemistry theory, the optimum molar ratio of reactants was obtained with the Ba(NO3)2-TiO(NO3)2-citric acid-NH4NO3 system. The influence of the ratio of reactants on the properties of the final products was investigated. The results showed that tetragonal BaTiO3 with high purity was produced at low ignition temperature (∼300 °C). The crystalline size of the powder obtained is less than 50 nm. The crystal structure, crystalline size and morphology were analyzed by XRD, SEM and TEM.
index888!@#@!1996!@#@!A flexible human-computer interface for accessing and interpreting human performance data!@#@!HICS!@#@!A flexible human-computer interface was developed for a multidocument ergonomics database to accommodate a variety of users with different backgrounds and levels of expertise. Multiple access and navigational pathways are provided to address users' varying needs and interests, including browsable outlines that take different perspectives on the data, an engineering-oriented question checklist, full-text searching and extensive hyperlinking within and between documents. Users can customize their interactions with the database by selecting text or graphic presentation formats, attaching notes to database components, creating bookmarks and hypertext links, and saving the current work context. Special tools to help users understand the technical material in the database include multimedia tutorial demonstrations of perceptual concepts and effects as well as a Perception and Performance Prototyper (P3) that lets users interactively explore selected behavioral phenomena and the factors that influence them.
index889!@#@!1995!@#@!Concurrency control for federated multilevel secure database systems!@#@!Proceedings of the 8th IEEE workshop on Computer Security Foundations!@#@!During the past decade, there has been much interest in Multilevel Secure (MLS) database management systems. This has resulted in several commercial MLS database systems and research prototypes available today. We believe that interoperation in MLS database systems is the next logical step. The diversity of solutions among these systems also motivates the study of the interoperability issues. A federated MLS database system is a system implemented on top of a collection of autonomous pre-existing MLS local database systems (LDBSs). Transaction processing in federated MLS database systems is complicated by autonomy and security requirements, since these requirements often conflict with each other. In this paper, we propose a concurrency control protocol for transaction processing in federated MLS database systems. Our protocol ensures global serializability but requires that the security lattice at each local site be totally ordered. However, the union of each local lattice can be partially ordered. In the future work we hope to relax the restriction on local security lattice.
index890!@#@!2003!@#@!Motion Guidance Experiments with Scooter Cobot!@#@!HAPTICS!@#@!Cobots assist humans by mechanically guiding motion along software-defined paths or surfaces. Cobot design has been extensively studied previously. This paper reports the first systematic experimental study of motion guidance with a cobot. We investigated themovements of seven operators with the Scooter cobot in representative environments. Analysis of the force exerted by the operators and the trajectories reveals significant differences between guided movements (GM) and free movements (FM). While FM requires learning for each novel task, GM is optimal from the first trial: Less effort is required to move in GM than in FM; Movements in GM are faster, smoother, and require less back and forth correction than in FM. These advantages demonstrate the strength of the Cobot concept. The results further suggest that operators guided by the Scooter can handle objects in a more "open-loop" way than with a dumb trolley, and so perform faster and concentrate on otheraspects of the manipulation task, potentially resulting in increased productivity and fewer injuries.
index891!@#@!1999!@#@!DOK-Trader: A CORBA Persistent Trader with Query Routing Facilities!@#@!Proceedings of the International Symposium on Distributed Objects and Applications!@#@!Existing traders support the required functions, such as the lookup and register of services. They are limited because they are restricted to a small number of services. This paper proposes solutions to the issues of persistency and query routing in the context of CORBA Trader to improve the performance of the core trader functions. We propose appropriate wrappers that provide database-like interfaces for the traders. This enables transparency and efficient access to persistent services. We propose a design of a full CORBA trader implementation, called DOK - Trader. It has specific functionalities, since it includes a specific routing mechanism for the trader federated queries. We demonstrate that these functionalities have let to better performance for the core CORBA trader functions.
index892!@#@!1999!@#@!Static Analysis of Processes for No and Read-Up nad No Write-Down!@#@!Proceedings of the Second International Conference on Foundations of Software Science and Computation Structure, Held as Part of the European Joint Conferences on the Theory and Practice of Software, ETAPS'99!@#@!null
index893!@#@!2003!@#@!Coefficient-based parametric faults detection in analog circuits!@#@!Great Lakes Symposium on VLSI!@#@!Coefficient-based method is introduced for the parametric faults detection in analog circuits. By use of pseudo Monte-Carlo simulation we can greatly speed up the calculation of bounds of CUT transfer function's coefficients. We can estimate transfer function's actual numeric coefficients with system identification method. There is no need for a apriori knowledge of the symbolic transfer function. Finally we show that it is possible to determine whether any given CUT is faulty.
index894!@#@!2002!@#@!Ripple down rules: a technique for acquiring knowledge!@#@!Decision making support systems: achievements, trends and challenges for!@#@!Knowledge is becoming increasingly recognized as a valuable resource. Given its importance it is surprising that expert systems technology has not become a more common means of utilizing knowledge. In this chapter we review some of the history of expert systems, the shortcomings of first generation expert systems, current approaches and future decisions. In particular we consider a knowledge acquisition and representation technique known as Ripple Down Rules (RDR) that avoids many of the limitations of earlier systems by providing a simple, user-driven knowledge acquisition approach based on the combined use of rules and cases and which support online validation and easy maintenance. RDR has found particular commercial success as a clinical decision support system and we review what features of RDR make it so suited to this domain.
index895!@#@!1999!@#@!Estimating Large Distances in Phylogenetic Reconstruction!@#@!Proceedings of the 3rd International Workshop on Algorithm Engineering!@#@!null
index896!@#@!2003!@#@!Region removal and restoration using a genetic algorithm with isophote constraint!@#@!Pattern Recognition Letters!@#@!In this paper, we propose an efficient method for region removal and restoration based on a genetic algorithm (GA) with isophote constraint. The image restoration problem is modeled as an optimization problem, which in our case, is solved by a cost function with isophote constraint that is minimized using a GA. We consider that an image is decomposed into isophotes based on connected components of constant intensity. Our method creates an optimal connection of all pairs of isophotes in an image plane. In the proposed method, we estimate the value of the smoothness, given by the best chromosome of the GA, and project this value in the isophotes direction. The proposed method restores the inside of the region using a geometric feature of the image from the surrounding area. It can be used to make a natural scene in which a commercial advertisement caption, subtitle or logo in an advertisement scene are removed. Experimental results show a great possibility for automatic removal and restoration of a region in an advertisement scene.
index897!@#@!1997!@#@!Functional verification of the superscalar SH-4 microprocessor!@#@!Proceedings of the 42nd IEEE International Computer Conference!@#@!Functional verification of modern complex processors is a formidable and time consuming task. In spite of substantial manual effort, it is extremely difficult to systematically cover the corner cases of the control logic design, within a short processor design cycle. The SH4 processor is a dual issue superscalar RISC architecture with extensive hardware support for 3D graphics. We present the development of a semi automated methodology for functional verification. In particular, we elaborate a scheme to automatically generate test programs to verify the superscalar issue logic, bypass/multi bypass logic and stall logic, starting from the microarchitectural specification. Finally, we present the Random Test Generation methodology and the specific Random Test Generators.
index898!@#@!2002!@#@!Symbolic heuristic search for factored Markov decision processes!@#@!Eighteenth national conference on Artificial intelligence!@#@!We describe a plnning algorithm that integrates two approaches to solving Markov decision processes with large state spaces. State abstraction is used to avoid evaluating states individually. Forward search from a start state, guided by an admissible heuristic, is used to avoid evaluating all states. We combine these two approaches in a novel way that exploits symbolic model-checking techniques and demonstrates their usefulness for decision-theoretic planning.
index899!@#@!1994!@#@!The CIO Multimedia Communication Platform!@#@!Proceedings of the International COST 237 Workshop on Multimedia Transport and Teleservices!@#@!null
index900!@#@!1995!@#@!Teaching Practical Principles of Software Measurement!@#@!Proceedings of the 8th SEI CSEE Conference on Software Engineering Education!@#@!null
index901!@#@!1999!@#@!Oporto: A Realistic Scenario Generator for Moving Objects!@#@!Proceedings of the 10th International Workshop on Database & Expert Systems Applications!@#@!The spatio-temporal database research community has just started to investigate benchmarking issues. On one hand we would rather have a benchmark that is representative of real world applications, in order to verify the expressiveness of proposed models. On the other hand, we would like a benchmark that offers a sizeable workload of data and query sets, which could obviously stress the strengths and weaknesses of a broad range of data access methods.This paper offers a framework for spatio-temporal data sets generator, a first step towards a full bench-mark for the large real world application field of "smoothly" moving objects with few or no restrictions in motion. The driving application is the modelling of fishing ships where the ships go in the direction of the most attractive shoals of fish while trying to avoid storm areas.Fishes are themselves attracted by plankton areas. Ships are moving points; plankton or storm areas are regions with fixed center but moving shape; and shoals are moving regions. The specification is written in such a way that the users can easily adjust generation model parameters.
index902!@#@!2002!@#@!Some Security Aspects of the M IST Randomized Exponentiation Algorithm!@#@!Revised Papers from the 4th International Workshop on Cryptographic Hardware and Embedded Systems!@#@!null
index903!@#@!2001!@#@!JDIPF - Java Digital Image Processing Framework!@#@!Proceedings of the 14th Brazilian Symposium on Computer Graphics and Image Processing!@#@!A tool created with the aim of contributing to the teaching of image processing techniques is presented. It allows the specification of filters in a simple and intuitive manner. Being a Java application, the system is portable and runs in many different environments.
index904!@#@!1992!@#@!Graph Grammars as Context-Dependent Rewriting Systems: A Partial Ordering Semantics!@#@!Proceedings of the 17th Colloquium on Trees in Algebra and Programming!@#@!null
index905!@#@!1998!@#@!Connected Vibrations: A Modal Analysis Approach for Non-Rigid Motion Tracking!@#@!Proceedings of the IEEE Computer Society Conference on Computer Vision and Pattern Recognition!@#@!null
index906!@#@!1994!@#@!Putting into Practice Advanced Software Engineering Techniques through Students Project!@#@!Proceedings of the 7th SEI CSEE Conference on Software Engineering Education!@#@!null
index907!@#@!2002!@#@!The triangle method for finding the corner of the L-curve!@#@!Applied Numerical Mathematics!@#@!The Conjugate Gradient Method (CG) has an intrinsic regularization property when applied to systems of linear equations with ill-conditioned matrices. This regularization property is specially useful when either the right-hand side or the coefficient matrix, or both are given with errors. The regularization parameter is the iteration number, and in order to find this parameter, the L-curve is used. Here we present a novel method to find the corner of the L-curve, that determines the regularizing iteration number. Numerical results on the collection of test problems [SIAM J. Sci. Comput. 16 (1995) 506-512] are given to illustrate the potentiality of the method.
index908!@#@!1993!@#@!An Action Structure for Synchronous pi-Calculus!@#@!Proceedings of the 9th International Symposium on Fundamentals of Computation Theory!@#@!null
index909!@#@!1989!@#@!Solids Velocity Estimation in Two-Phase Turbulent Flow (as in Circulating Fluidized Bed)!@#@!Mustererkennung 1989, 11. DAGM-Symposium!@#@!null
index910!@#@!2002!@#@!Complexity and Application of Pedigree Analysis Programme GTree!@#@!Proceedings of the IEEE Computer Society Conference on Bioinformatics!@#@!A novel recombinant congenic mouse strain, McRA1-lpr/lpr, which was established by the intercrosses between MRL/Mp-lpr/lpr and C3H/HeJ-lpr/lpr strains throughout more than F50 generations by means of selection based on swelling of ankle joints, manifested severe arthritis, followed by ankylosis, pathologically resembling rheumatoid arthritis in human. To clarify the genetic mechanisms on the development of arthritis in this strain, we newly prepared"GTree" for analyzing the pedigree of pathological phenotypes of arthritis, splenomegaly and lymphadenopathy based on the collected data from over 700 McRA1-lpr/lpr mice collected and arranged by Shiro MORI. The data themselves are now cared in a PostgreSQL Linux server administered by Hideki SAWADA.In this paper we explain the algorithm of the programme and its complexity, and show the pathological peculiarity of spleens and axillary lymph nodes which appear only in the group of RA mice.
index911!@#@!2000!@#@!Pragmatic data modelling and design for end users!@#@!Proceedings of the Seventh Asia-Pacific Software Engineering Conference!@#@!Many people are dependent on desktop end user tools such as spreadsheets and databases to manage their data. While they may have the technical skills to set up data repositories, many end users lack the analysis skills to design data models which reflect their often deceptively complex requirements. We advocate that a comprehensive data model should always be developed, with expert help, so that the end user can feel confident the subtleties of the data are fully understood. We then suggest that some pragmatic decisions can be made to simplify the model so that the end user can retain control over setting up and maintaining the application.
index912!@#@!1996!@#@!Source and Channel Coding for Mobile Multimedia Communications!@#@!Proceedings of the Third International COST 237 Workshop on Multimedia Telecommunications and Applications!@#@!null
index913!@#@!1985!@#@!Is DES a Pure Cipher? (Results of More Cycling Experiments on DES)!@#@!Advances in Cryptology!@#@!null
index914!@#@!2000!@#@!A Proposed Curriculum for an Undergraduate Software Engineering Degree!@#@!Proceedings of the 13th Conference on Software Engineering Education & Training!@#@!We have developed a curriculum for a software engineering undergraduate degree. We used the medical school clinical model to guide our design as it successfully combines both knowledge and practice components. Through rotations, our curriculum will provide graduates with both an advanced knowledge of software engineering concepts and practical skills that have been honed in a realistic setting. In this paper, we present our proposed curriculum and the difficulties we foresee in implementing it.
index915!@#@!1995!@#@!Defect-oriented test methodology for complex mixed-signal circuits!@#@!Proceedings of the 1995 European conference on Design and Test!@#@!Testing of analog blocks in digital circuits is emerging as a critical factor in the success of mixed-signal ICs. The present specification-oriented testing of these blocks results in high test costs and doesn't ensure detection of all defects, causing potential reliability problems. To solve these problems, in this paper a defect-oriented test methodology for mixed analog-digital circuits is proposed. The strength of the method is demonstrated by an implementation for a complex mixed-signal circuit, a flash analog-to-digital converter. It is shown that with simple tests 93% of the defects in this circuit can be detected. Moreover application of DfT guidelines derived from this test methodology may improve the defect coverage to 99%. First impressions lead to the conclusion that the analyzed test obtains a higher defect coverage with lower test costs than functional tests.
index916!@#@!2003!@#@!Networks III!@#@!ACM Symposium on Parallel Algorithms and Architectures!@#@!null
index917!@#@!2003!@#@!Efficiency of compressed code!@#@!Proceedings of the 2003 ACM SIGPLAN conference on Language, compiler, and tool for embedded systems!@#@!null
index918!@#@!2003!@#@!Dynamic data-driven application systems!@#@!International Conference on Supercomputing!@#@!null
index919!@#@!2000!@#@!Proceedings of the 15th Annual IEEE Symposium on Logic in Computer Science!@#@!LICS!@#@!null
index920!@#@!2003!@#@!Homomorphism Closed vs. Existential Positive!@#@!Proceedings of the 18th Annual IEEE Symposium on Logic in Computer Science!@#@!Preservations theorems, which establish connection betweensyntactic and semantic properties of formulas, area major topic of investigation in model theory. In the contextof finite-model theory, most, but not all, preservationtheorems are known to fail. It is not known, however,whether the £os-Tarski-Lyndon Theorem, which assertsthat a 1st-order sentence is preserved under homomorphismsiff it is equivalent to an existential positive sentence,holds with respect to finite structures. Resolvingthis is an important open question in finite-model theory.In this paper we study the relationship between closureunder homomorphism and positive syntax for several non-1st-order existential logics that are of interest in computerscience. We prove that the £os-Tarski-Lyndon Theoremholds for these logics. The logics we consider arevariable-confined existential infinitary logic, Datalog, andvarious fragments of second-order logic.
index921!@#@!2002!@#@!Making Fourier-envelope simulation robust!@#@!Proceedings of the 2002 IEEE/ACM international conference on Computer-aided design!@#@!Fourier-envelope algorithms are an important component of the mixed-signal/RF verification toolbox. In this paper, we address the unpredictability and lack of robustness that has been reported for these algorithms. We show that the problem stems from fast oscillations in envelopes that are expected to be slowly varying. We demonstrate that this is related to the fact that the envelope equations are always stiff, whether or not the underlying system is. We show that careful choice of envelope initial conditions is necessary to obtain useful solutions, and propose two techniques for finding good initial conditions. Applying these, and solving the envelope equations with stiffly-stable numerical methods, we improve the robustness and reliability of Fourier-envelope methods. We illustrate the new methods with a direct-downconversion mixer circuit.
index922!@#@!1998!@#@!Invited Lecture: Interactive Exploration of Distributed 3D Databases over the Internet!@#@!Computer Graphics International!@#@!null
index923!@#@!1996!@#@!Committees!@#@!Proceedings of the 1996 Australian Software Engineering Conference!@#@!null
index924!@#@!2002!@#@!Modelling Networked Enterprises!@#@!EDOC!@#@!The appearance of networked enterprises, in which Internet-enabled organisations work together for mutual benefit, gives rise to a change in the nature of enterprise computing. Enterprise computing today has to deal with application integration across company boundaries and support inter-organisational business processes, collaborations and transactions. It has always been important first to understand the business environment in which enterprise systems are supposed to function before embarking upon their design. Due to the interorganisational nature of networked enterprises and the intimate relation between their business and their systems, this need is even more apparent.In this paper we analyse the requirements that networked enterprise computing places on enterprise modelling techniques, and introduce a new language for modelling networked enterprises. We will also argue that the UML, while highly successful as a software modellingtechnique, lacks some essential ingredients for networked enterprise modelling.
index925!@#@!2001!@#@!Alternative Models of Restructured Electricity Systems, Part 1: No Market Power!@#@!Operations Research!@#@!Different equilibrium concepts have been proposed by various authors (Schweppe et al., Hogan et al., Chao and Peck, Wu et al.) to analyse competitive electricity systems. We establish correspondences between these different models through a single framework and provide additional interpretations of these equilibrium concepts. This unifying conceptual view also provides a computationally feasible approach to simulate the market. It also opens the way to the modeling of some imperfect markets.
index926!@#@!1997!@#@!Minimizing the use of random oracles in authenticated encryption schemes!@#@!Proceedings of the First International Conference on Information and Communication Security!@#@!null
index927!@#@!2003!@#@!Evaluating globally: how to conduct international or intercultural usability research!@#@!CHI '03 extended abstracts on Human factors in computing systems!@#@!This panel will educate the audience on the methods and tools available for conducting international or intercultural usability research. The panel will also address the challenges of conducting international or intercultural usability research and provide tips on how to overcome these challenges.
index928!@#@!2002!@#@!Graph multidimensional scaling with self-organizing maps!@#@!Information Sciences&mdash;Informatics and Computer Science: An International Journal!@#@!Self-organizing maps (SOM) are unsupervised, competitive neural networks used to project high-dimensional data onto a low-dimensional space. In this paper it is shown that SOM can be used to perform multidimensional scaling (MDS) on graphs. The SOM-based approach is applied to two families of random graphs and three real-world networks.
index929!@#@!1993!@#@!Necessary and Sufficient Conditions for a Unique Solution of Plane Motion and Structure!@#@!Proceedings of the 5th International Conference on Computer Analysis of Images and Patterns!@#@!null
index930!@#@!2003!@#@!Surmise relations between tests: mathematical considerations!@#@!Discrete Applied Mathematics!@#@!In 1985, Doignon and Falmagne introduced surmise relations for representing prerequisite relationships between items within a body of information for the assessment of knowledge. Often it is useful to partition such a body of information into sub-collections. As we are primarily interested in psychological applications, we refer to these sub-collections as tests.We extend the concept of surmise relations between items within tests to surmise relations between tests. Three different kinds of surmise relations between tests are investigated with respect to their properties. Furthermore, the corresponding knowledge spaces for tests and their bases are introduced. The relationship of this set theoretical approach to a Boolean matrix representation is discussed.Finally, we give a short overview about the further research regarding this mathematical model. It will be the foundation for a software system that will be used for analyzing test data. Other applications in fields like curriculum development and structuring hyper-texts can easily be imagined.
index931!@#@!2001!@#@!Solving Large Systems of Differential Equations with PaViS!@#@!Proceedings of the th International Conference on Parallel Processing and Applied Mathematics-Revised Papers!@#@!null
index932!@#@!2003!@#@!P2P-RPC: Programming Scientific Applications on Peer-to-Peer Systems with Remote Procedure Call!@#@!Proceedings of the 3st International Symposium on Cluster Computing and the Grid!@#@!This paper presents design and implementation of a remote Procedure call (RPC) API for programming applications on Peer-to-Peer environments. The P2P-RPC API isdesigned to address one of neglected aspect of Peer-to-Peer-the lack of a simple programming interface. In this paper we examine one concrete implementation of the P2P-RPC API derived from OmniRPC (an existing RPC API forthe Grid based on Ninf system). This new API is implemented on top of low-level functionalities of the XtremWebPeer-to-Peer Computing System. The minimal API definedin this paper provides a basic mechanism to make migratea wide variety of applications using RPC mechanism to thePeer-to-Peer systems. We evaluate P2P-RPC for a numerical application (NAS EP Benchmark) and demonstrate itsperformance and fault tolerance properties.
index933!@#@!1997!@#@!A massively parallel implementation of the watershed based on cellular automata!@#@!Proceedings of the IEEE International Conference on Application-Specific Systems, Architectures and Processors!@#@!The watershed transform is a very powerful segmentation tool which comes directly from the idea of watershed line in geohydrology. It has proved its efficiency in many computer vision application fields. This paper presents a new implementation of the watershed which is optimal according to computation time. The flooding algorithm is reminded. Then, a massively parallel cellular automaton is proposed to propagate data using this approach. We discuss the pros and cons of a hardware implementation and give an example of application. A comparison between the results obtained and theoretical limit cases is also presented.
index934!@#@!2003!@#@!Modeling QCA for area minimization in logic synthesis!@#@!Great Lakes Symposium on VLSI!@#@!Concerned by the wall that Moore's Law is expected to hit in the next decade, the integrated circuit community is turning to emerging nanotechnologies for continued device improvements. While significant advancements in nanotechnology devices have been achieved, much work is required to integrate these technologies into the existing design methodologies. Given that the physical design paradigm of each nanotechnology will be significantly different than that of traditional silicon circuits, the underlying cost functions used in optimization algorithms throughout the design abstraction hierarchy must be altered. Because nanotechnologies are not as well developed and understood as silicon devices, abstraction will initially result in less accurate models. However, if models are developed and augmented as nanotechnologies continue to evolve, the transition from CMOS-based design to nano-based design will be relatively seamless.This paper details the logic-level abstraction process for area minimization for one promising nanotechnology - quantum cellular automata (QCA). The model abstracts relative area costs, including interconnect area, for QCA devices, and it is integrated within existing multi-level logic synthesis techniques. Results validate the proposed approach of designing nano-based circuits with the traditional abstraction-based design methodology.
index935!@#@!2000!@#@!A Comparison of the Basic DO Concepts in Standardization!@#@!Proceedings of the International Symposium on Distributed Objects and Applications!@#@!This paper provides a comparison of the basic DO (Distributed Object) concepts, namely ¿object¿, ¿instance¿ and ¿class¿ used in various standards of the DO world. Two families of standards are identified: those related to the modelling aspects (MOF and UML) and those related to the architectural and implementation aspects (CORBA and Java). Moreover, the RM-ODP standard is considered as it includes both aspects. The objective is to help with a common understanding of these concepts. For this, we compare these concepts as defined in these standards according to the four-layer architecture proposed by the MOF standard. An example is provided to illustrate the comparison.
index936!@#@!2003!@#@!What is the difference between information science and computer science?!@#@!Journal of Computing Sciences in Colleges!@#@!null
index937!@#@!2003!@#@!Building Client/Server Applications with VB.NET: An Example Driven Approach!@#@!!@#@!null
index938!@#@!2001!@#@!Neural networks in civil engineering: a review!@#@!Civil and structural engineering computing: 2001!@#@!The Chapter provides an introduction to the diverse range of alternative artificial neural networks (ANNs) currently available and the types of application they have been adopted for in civil and structural engineering. The presentation is made with reference to a classification and decomposition of the main features of ANNs. An introduction is first provided of the essential features of a typical ANN, and its mode of operation. A brief graphical interpretation is presented to illustrate how ANNs model data, and to help gain insight to their scope of application, merits and drawbacks. An identification is then made of the different types of processing that can be performed at the neuron level, the lowest level in an ANN. This is followed by an identification of the different ways in which neurons can be combined into an integral processing device capable of solving non-trivial problems. The range of alternative function types that can be implemented by ANNs are then examined. Finally, a review is provided of the primary methods of developing/training ANNs to solve specific problems. At each stage in the chapter, relevant neural paradigms are referenced and areas of application in civil and structural engineering are identified.
index939!@#@!1998!@#@!Comparison Between Geometry-Based and Gabor-Wavelets-Based Facial Expression Recognition Using Multi-Layer Perceptron!@#@!Proceedings of the 3rd. International Conference on Face & Gesture Recognition!@#@!null
index940!@#@!2000!@#@!Bit Permutation Instructions for Accelerating Software Cryptography!@#@!Proceedings of the IEEE International Conference on Application-Specific Systems, Architectures, and Processors!@#@!Permutation is widely used in cryptographic algorithms. However, it is not well supported in existing instruction sets. In this paper, two instructions, PPERM3R and GRP, are proposed for efficient software implementation of arbitrary permutations. The PPERM3R instruction can be used for dynamically specified permutations; the GRP instruction can be used to do arbitrary n-bit permutations with up to lg(n) instructions. In addition, a systematic method for determining the instruction sequence for performing an arbitrary permutation is described.
index941!@#@!1999!@#@!AOM: An Agent Oriented Middleware Based on Java!@#@!Proceedings of the 5th International Computer Science Conference on Internet Applications!@#@!null
index942!@#@!1999!@#@!A Hierarchical Approach to the Formal Verification of Embedded Systems Using MDGs!@#@!Proceedings of the Ninth Great Lakes Symposium on VLSI!@#@!With the increasing emergence of mixed hardware/software systems, it is important to ensure the correctness of such a system formally, particularly for real-time and safety critical applications. We present a hierarchical approach to modeling and formally verifying an embedded system at higher levels of abstraction, using Multiway Decision Graphs (MDGs). We demonstrate our approach on the embedded software for a mouse controller application on a commercial microcontroller (PIC 16C71), using the MDG verification tools. Inconsistencies in the assembly code with respect to the specification, as published in the application notes of the manufacturer, were uncovered through our experiments.
index943!@#@!1999!@#@!Modeling the Evolution of Markets with Indirect Network Externalities: An Application to Digital Television!@#@!Marketing Science!@#@!The usefulness of a technology product for an end-user often depends on the availability of complementary software products and services. Computers require software, cameras require film, and DVD players require movie programming in order for customers to value the whole product. This phenomenon, where the demand for hardware products is mediated by the supply of complementary software products, is called an indirect network externality. Indirect network externalities create a two-way contingency between the demand for the hardware product and the supply of software products, and result in a strategic interdependence between the actions of hardware manufacturers and the actions of software providers. Indirect network externalities are gaining economic significance in technology markets, because hardware and software are typically provided by independent firms, and both sets of firms have an incentive to free-ride on each others' demand creation efforts. Despite the ubiquity of this phenomenon, it has largely been ignored in the marketing science literature. We present a conceptual and operational model for the evolution of markets with indirect network externalities. The key feature of our framework is to model the market-mediated dependence between the actions of hardware manufacturers and software complementors, created by the direct dependence of consumer demand for the whole product on the actions of manufacturers as well as complementors. In addition, we incorporate marketing-mix effects on consumer response, aswell as heterogeneity in consumer preferences for hardware and software attributes. We model consumer response usinga latent-class choice model. To estimate the complementor response functions, we use a modified Delphi technique that allows us to convert qualitative response data into quantitative response functions. We integrate the consumer and complementor response models to create a simulation modelthat generates forecasts of market shares and sales volumes for competing technologies, as a function of marketing-mix effects and exogenously specified regulatory scenarios. The modeling framework is of interest to new product modelers interested in creating empirical models and decision-support systems for forecasting demand in technology markets characterized by indirect network externalities. The decision-support aspects of the modeling framework should appeal to managers interested in understanding and quantifying the complex interplay between hardware manufacturers and software complementors in the evolution of markets with indirect network externalities. We present an application of the modeling framework to the U.S. digital television industry, and use the framework to characterize the competition among analog and digital TV technologies. Our results suggest that complementor actions play an important role in the acceptance of digital TV technologies in general, and high definition television (HDTV) in particular. We find that forecasts that ignore the influence of indirect network externalities would be seriously biased in favor of HDTV. We illustrate how the modeling framework can be used to identify and profile customer segments in the digital TV market based on their utility for hardware-related features as well as programming-related features. We also illustrate the decision-support capabilities of the modeling framework by evaluating the sensitivity of the forecasts to varying marketing, regulatory, and complementor response scenarios. We derive implications for marketing and public affairs policies of the hardware manufacturers. The developments in the digital TV industry generally support our finding that HDTV will be a niche product, and will diffuse slower than originally expected due in part to the lack of programming. The delays in the introduction of digital TV to the marketplace also suggest that most forecasts for infrastructure-intensive technologies like digital TV may be too optimistic simply because they underestimate the delays in agreeing upon technology standards and resolving regulatory debates.
index944!@#@!2003!@#@!Secure Communication in a Distributed System Using Identity Based Encryption!@#@!Proceedings of the 3st International Symposium on Cluster Computing and the Grid!@#@!Distributed systems require the ability to communicatesecurely with other computers in the network.To accomplish this, most systems use key managementschemes that require prior knowledge of publickeys associated with critical nodes. In large, dynamic,anonymous systems, this key sharing method is not viable.Scribe is a method for efficient key managementinside a distributed system that uses identity based encryption(IBE). Public resources in a network are addressableby unique identifiers. Using this identifier asa public key, other entities are able to securely accessthat resource. We evaluate key distribution schemesinside Scribe and provide recommendations for practicalimplementation to allow for secure, efficient, authenticatedcommunication inside a distributed system.
index945!@#@!1995!@#@!Harvard brain atlas: a teaching and visualization tool!@#@!BIOMEDVIS!@#@!The authors here present initial data from a computerized three-dimensional (3D) human brain atlas project that employs automated segmentation methods 3D slice editing techniques, region of interest definitions based on neuroanatomical knowledge, and 3D surface rendering techniques. For illustrative purposes, the authors show 3D representations of cerebral cortical grey matter (subdivided by lobe), cerebellum, corpus callosum, basal ganglia structures, limbic system structures, eyes and optic chiasm, and the ventricular system. Part of the white matter, including the corticospinal tract is also reconstructed in 3D. This digitized human brain atlas will be expanded and later used to automatically register new MR data sets in order to assess 3D volumes of interest. Currently, it serves as a powerful teaching tool since spatial relationships among neuroanatomical structures can be more readily envisioned when the user is able to view and rotate the structures in 3D space, and where each element of the brain atlas is associated with a name tag that is displayed by a user-controlled pointer.
index946!@#@!2002!@#@!Template Attacks!@#@!Revised Papers from the 4th International Workshop on Cryptographic Hardware and Embedded Systems!@#@!null
index947!@#@!1994!@#@!Simple Termination Revisited!@#@!Proceedings of the 12th International Conference on Automated Deduction!@#@!null
index948!@#@!2003!@#@!Multicoloring trees!@#@!Information and Computation!@#@!Scheduling jobs with pairwise conflicts is modeled by the graph multicoloring problem. It occurs in two versions: in the preemptive case, each vertex may get any set of colors, while in the non-preemptive case, the set of colors assigned to each vertex has to be contiguous. We study these versions of the multicoloring problem on trees, under the sum-of-completion-times objective. In particular, we give a quadratic algorithm for the non-preemptive case, and a faster algorithm in the case that all job lengths are short, while we present a polynomial-time approximation scheme for the preemptive case.
index949!@#@!2003!@#@!Some properties of a new product in J′n!@#@!Journal of Computational and Applied Mathematics!@#@!In this paper, the authors study some basic properties of the new generalized scalar product introduced recently by Carfi in the space of tempered distributions. Such properties are the analogues of some basic properties fulfilled by the scalar product of a finite dimensional pre-Hilbertian space. The interest of this circumstance lies in the fact that the space of tempered distributions has not a pre-Hilbertian natural structure, moreover it is not a finite dimensional vector space.
index950!@#@!2001!@#@!The truth about the digital divide!@#@!The digital divide: facing a crisis or creating a myth?!@#@!null
index951!@#@!2001!@#@!Cryptanalysis of a Public Key Cryptosystem Proposed at ACISP 2000!@#@!Proceedings of the 6th Australasian Conference on Information Security and Privacy!@#@!null
index952!@#@!2002!@#@!HW/SW partitioning and code generation of embedded control applications on a reconfigurable architecture platform!@#@!Proceedings of the tenth international symposium on Hardware/software codesign!@#@!This paper studies the use of a reconfigurable architecture platform for embedded control applications aimed at improving real time performance. The hw/sw codesign methodology from POLIS is used. It starts from high-level specifications, optimizes an intermediate model of computation (Extended Finite State Machines) and derives both hardware and software, based on performance constraints. We study a particular architecture platform, which consists of a general purpose processor core, augmented with a reconfigurable function unit and data-path to improve run time performance. A new mapping flow and algorithms to partition hardware and software are proposed to generate implementations that best utilize this architecture. Encouraging preliminary results are shown for automotive electronic control examples.
index953!@#@!1999!@#@!Program Chairs' Message!@#@!Proceedings of the 1999 IEEE Symposium on Application - Specific Systems and Software Engineering and Technology!@#@!null
index954!@#@!2003!@#@!Non-restrictive computational reflection!@#@!Computer Standards &amp; Interfaces!@#@!Adaptable software systems and architectures give the programmer the ability to create applications that might customize themselves to runtime-emerging requirements. Computational reflection is a programming language technique that is commonly used to achieve the development of this kind of systems. Most runtime reflective systems use Meta-Object Protocols (MOPs). However, MOPs restrict the amount of features an application can customize, and the way they can express its own adaptation. Furthermore, this kind of systems uses a fixed programming language: they develop an interpreter, not a whole language-independent platform.What we present in this paper a non-restrictive reflective platform, called nitrO, that achieves a real computational-environment jump, making every application and language feature adaptable at runtime--without any previously defined restriction. Moreover, the platform has been built using a generic interpreter, in which the reflection mechanism is independent of the language selected by the programmer. Different applications may dynamically adapt each other, regardless of the programming language they use.
index955!@#@!1993!@#@!Spracherkennung mit TANGORA: Medizinische Sprachmodelle und ihre Erweiterung auf Komposita in der deutschen Sprache!@#@!Mustererkennung 1993, Mustererkennung im Dienste der Gesundheit, 15. DAGM-Symposium!@#@!null
index956!@#@!1988!@#@!Checking Natural Language Proofs!@#@!Proceedings of the 9th International Conference on Automated Deduction!@#@!null
index957!@#@!1993!@#@!On the Adequacy of Per Models!@#@!Proceedings of the 18th International Symposium on Mathematical Foundations of Computer Science!@#@!null
index958!@#@!2003!@#@!Using FEM and neural network prediction on hydrodynamic deep drawing of T-piece maximum length!@#@!Finite Elements in Analysis and Design!@#@!The incremental updated Lagrangian elasto-plastic finite element method and abductive network was applied in this study to analyze hydrodynamic deep drawing of 3D T-piece design. A series of 24 sets of different geometry tools were used for a 3D T-piece deep drawing process, with difference variations in the die radius, material radius and matching the different thickness of product.The results of the deep-drawing maximum length from FEM-simulation are then input to a neural network to establish a model for the T-piece deep-drawing variables. The neural network is composed of a number of functional nodes. Once the T-piece control parameters (material thickness, material radius and die radius) are given, the drawing processing performance (deep-drawing maximum length) can be accurately predicted by this developed network. This research achieved a satisfactory result based on demonstration of simulation, proving that it is a new and feasible approach used in control of T-piece drawing process of materials.
index959!@#@!2003!@#@!Network Tomography-Based Unresponsive Flow Detection and Control!@#@!Proceedings of the The Ninth IEEE Workshop on Future Trends of Distributed Computing Systems!@#@!To avoid a congestion collapse, network flows should adjust their sending rates. Adaptive flows adjust the rate, while unresponsive flows do not respond to congestion and keep sending packets. Unresponsive flows waste resources by taking their share of the upstream links of a domain and dropping packets later when the downstream links are congested. We use network tomography ¿ an edge-to-edge mechanism to infer per-link internal characteristics of a domain ¿ to identify unresponsive flows that cause packet drops in other flows. We have designed an algorithm to dynamically regulate unresponsive flows. The congestion control algorithm is evaluated using both adaptive and unresponsive flows, with sending rates as high as four times of the bottleneck bandwidth, and in presence of short andlong-lived background traffic.
index960!@#@!2002!@#@!Upper bounds for restricted splicing!@#@!Formal and natural computing!@#@!We determine or improve upper bounds for non-iterated splicing in length-increasing, length-decreasing, same-length and self splicing mode.
index961!@#@!2002!@#@!New approach to security proactively protects network systems!@#@!Storage Management Solutions!@#@!null
index962!@#@!1998!@#@!Towards the Automated Debugging and Maintenance of Logic-based Requirements Models!@#@!Automated Software Engineering!@#@!In this paper we describe a tools environment which automates the validation and maintenance of a requirements model written in many-sorted first order logic. We focus on: a translator, that produces an executable form of the model; blame assignment functions, which input batches of mis-classified tests (i.e. training examples) and output likely faulty parts of the model; and a theory reviser, which inputs the faulty parts and examples and outputs suggested revisions to the model. In particular, we concentrate on the problems encountered when applying these tools to a real application: a requirements model containing air traffic control separation standards, operating methods and airspace information.
index963!@#@!2003!@#@!Parallel Monte Carlo algorithms for information retrieval!@#@!Mathematics and Computers in Simulation!@#@!In any data mining applications, automated text and text and image retrieval of information is needed. This becomes essential with the growth of the Internet and digital libraries. Our approach is based on the latent semantic indexing (LSI) and the corresponding term-by-document matrix suggested by Berry and his co-authors. Instead of using deterministic methods to find the required number of first "k" singular triplets, we propose a stochastic approach. First, we use Monte Carlo method to sample and to build much smaller size term-by-document matrix (e.g. we build k × k matrix) from where we then find the first "k" triplets using standard deterministic methods. Second, we investigate how we can reduce the problem to finding the "k"-largest eigenvalues using parallel Monte Carlo methods. We apply these methods to the initial matrix and also to the reduced one.The algorithms are running on a cluster of workstations under MPI and results of the experiments arising in textual retrieval of Web documents as well as comparison of the stochastic methods proposed are presented.
index964!@#@!1996!@#@!System-level optimization of architectural performance under varying service demands!@#@!Proceedings of the IEEE Symposium and Workshop on Engineering of Computer Based Systems!@#@!This paper describes the motivation, methods, and application of a regimen for optimizing cost-performance measures for distributed system architectures. Dynamic performance under varying workloads was optimized in terms of system resource parameters in an absolute time base context. The intent was to establish an exacting yet practical means for setting architecture parameters and tolerances near the outset of system-level development. An existing software-implemented prototype for an on-line transaction processing system (OLTPS) was modified and interfaced with a genetic algorithm (GA). An objective function composed of architecture attributes was used as a fitness metric for the GA. Five architecture parameters encoded in a 24-bit chromosome were manipulated by the GA to furnish instantiation values for the OLTPS prototype. After each prototype execution, four dynamic performance measures were fed to the GA for fitness ranking. Despite some hesitancy in GA convergence, the overall optimization scheme worked well. To achieve more rapid resolution of optima, a multiple mutation operator mechanism was improvised and used to advantage. In all, the effort expended for dynamically quantified system-level optimization is seen as well justified and quite beneficial to overall system design.
index965!@#@!1993!@#@!Entschl&uuml;sselung von Proteinfunktionen mit Hilfe des Computers: Erkennung und Interpretation entfernter Sequenz&auml;hnlichkeiten!@#@!Informatik in den Biowissenschaften, 1. Fachtagung der GI-FG 4.0.3 "Informatik in den Biowissenschaften"!@#@!null
index966!@#@!2002!@#@!Data mining tasks and methods: spatial analysis!@#@!Handbook of data mining and knowledge discovery!@#@!The number and the size of spatial databases are rapidly growing in applications such as geomarketing, astrophysics, and molecular biology. This is mainly due to the amazing progress in scientific instruments such as satellites with remote sensors or X-ray crystallography. While a lot of algorithms have been developed for knowledge discovery in relational databases, the field of knowledge discovery in spatial databases has only recently emerged (see Koperski et al., 1996, for an overview). The assumption of independently and identically distributed attributes, which is implicit in classical data mining, may not be applicable for spatial data. Attributes of the neighbors of some object of interest may have an influence on the object itself. For instance, a new industrial plant may pollute its neighborhood depending on the distance and on the major direction of the wind. In Section 1, we introduce spatial database systems and some basic operations for mining in such databases. Then, we discuss the major data mining tasks of spatial clustering (Section 2), spatial classification (Section 3), and spatial characterization (Section 4).
index967!@#@!1999!@#@!CHOROCHRONOS -- Research on Spatiotemporal Database Systems!@#@!Proceedings of the 10th International Workshop on Database & Expert Systems Applications!@#@!Spatiotemporal database management systems can become an enabling technology for important applications such as Geographic Information Systems (GIS), environmental information systems, and multimedia. In this paper we address research issues in spatiotemporal databases, by providing an analysis of the challenges set, the problems encountered, as well as the proposed solutions and the envisioned research areas open to investigation in the EU funded project CHOROCHRONOS.
index968!@#@!2002!@#@!Call Admission Control Using the Moving Pattern of Mobile User for Mobile Multimedia Networks!@#@!Proceedings of the 27th Annual IEEE Conference on Local Computer Networks!@#@!In this paper, a call admission control mechanism isproposed to provide a consistent QoS guarantee formultimedia traffic on a mobile computing environment.Each cell can reserve fractional bandwidth for hand-offcalls to its adjacent cells. It is important to determine theright amount of bandwidth reserved for hand-off callsbecause the blocking probability of new calls mayincrease if the amount of reserved bandwidth is more thannecessary. An adaptive bandwidth reservation based on amobility graph and a 2-tier cell structure is proposed todetermine the amount of bandwidth to be reserved in thecell and to control dynamically its amount according tonetwork conditions. We also propose a call admissioncontrol based on this bandwidth reservation and "next-cellprediction" scheme using an mobility graph. In orderto evaluate the performance of our call admission controlmechanism, we measure metrics such as blockingprobability of new calls, dropping probability of hand-offcalls, and bandwidth utilization. The simulation resultsshow that the performance of our mechanism is superiorto that of existing mechanisms such as NR-CAT2, FR-CAT2,and AR-CAT2.
index969!@#@!2003!@#@!Object Request Brokers in Mobile Computing!@#@!Wireless Personal Communications: An International Journal!@#@!The widespread use of wireless and mobile networks and devices requires special programming techniques and solutions. The object request brokers of mobile environments have to adopt these techniques and offer services dealing with the problems of mobility. Most of the existing object request brokers however were developed for fixed networks assuming reliable transport protocols (mostly TCP), while the mobile networks cannot offer high quality transport. In this paper we give an overview of the challenges and solutions in mobile computing and present our ORB(M) framework implementing services based on the solutions. Extending the framework doesn't require the assistance of its developers, the user can implement application-specific semantic elements and deploy various new methods bound to the process of remote invocation. The user can form arbitrary new invocation semantics based on these elements and customise the invocation semantics used by a given method. Our new mobility-related semantic elements offer solutions to the challenges of mobility allowing the user to concentrate on the essential problems of the application and handling.
index970!@#@!1993!@#@!Crest Lines Detection in Grey Level Images: Studies of Different Approaches and Proposition of a New One!@#@!Proceedings of the 5th International Conference on Computer Analysis of Images and Patterns!@#@!null
index971!@#@!1999!@#@!Joint Source-Channel Coding for Progressive Transmission of Embedded Source Coders!@#@!Proceedings of the Conference on Data Compression!@#@!We present a scheme for joint source-channel coding for transmission of sources com- pressed by embedded source coders over a memoryless noisy channel. We find an exact solution to the problem of optimal channel code allocation. Then we investigate the properties of the solution which allow us to transmit the source progressively while retaining the optimality at intermediate and final transmission rates, using rate-compatible codes.
index972!@#@!2001!@#@!Consequences of Order Crossover Under Order-Up-To Inventory Policies!@#@!Manufacturing &amp; Service Operations Management!@#@!Order crossover occurs whenever replenishment orders do not arrive in the sequence in which they were placed. This paper argues that order crossover is becoming more prevalent and analyzes the dangers of ignoring it. We present an exact iterative algorithm for computing the distribution of the number of orders outstanding, and formulae for the inventory shortfall distribution (the quantity of inventory in replenishment at the start of a period) and the more common lead-time demand distribution, which are different when order crossover is possible. The lead-time demand distribution can have much higher variability than the shortfall distribution. We show that basing inventory policies on the lead-time demand distribution--rather than the shortfall distribution--can lead to significantly higher inventory cost, even if the probability of order crossover is small. We give an alternative proof to that of Zalkind (1976), which shows that the variance of shortfall is less than the variance of the standard lead-time demand.
index973!@#@!2003!@#@!Semantic and syntactic interoperability: in transactional systems!@#@!Electronic Commerce!@#@!This research note describes a middleware-based system that enables semantic and syntactic interoperability of transactional data exchanged in real-time between sending and receiving systems. Our system samples transaction streams, and statistically measures the variances in the semantics and syntax of the underlying data elements exchanged between sending and receiving systems. Automatic transformations of the data elements are applied when a context-specific Data Operability Threshold is crossed. The transaction is then transmitted onward by the sending system (or processed for consumption by the receiving system) in a format that ensures no manual reconciliation would be required to process the transaction. The System is being prototyped for cross-border securities trading and settlement.
index974!@#@!1997!@#@!Automatic generation of performance models using the distributed management framework (DMF)!@#@!Proceedings of the 1997 conference of the Centre for Advanced Studies on Collaborative research!@#@!The purpose of the Distributed Management Framework (DMF) is to provide a layer of abstraction at a level convenient for management application developers. Specifically, it liberates the management application developer from the need to deal with application-dependent format, location, and access methods of management information. It also protects management applications from the need to evolve in response to changes in the managed system. In this paper we describe the DMF, illustrating its usefulness for building cohesive management applications by providing an example of a management application that builds predictive performance models for distributed application systems.
index975!@#@!2003!@#@!A novel ferroelectric based microphone!@#@!Microelectronic Engineering!@#@!A novel ferroelectric based microphone with lead zirconate titanate [Pb(Zr, Ti)O3, PZT] coated silicon cantilever has been proposed in this paper. The cantilever structure is composed of a Pt/PZT/Pt/Ti/SiO2/ Si3N4/SiO2/Si multilayer and is designed using a multimorph model. Optimum fabrication process of the PZT thin films and the cantilever has been developed. The acoustic outputs of the fabricated microphones have been measured with a standard microphone and a high sensitivity of 40 mV/Pa can be obtained. The frequency response of the microphone is very flat in the audio frequency range.
index976!@#@!2002!@#@!Rationalizing key design decisions in the ATM user plane!@#@!ACM SIGCOMM Computer Communication Review!@#@!Any technology requires some number of key design decisions. In the case of the ATM user plane, the choices to use fixed length, 53 byte cells and virtual connections were unorthodox from the perspective of many in the networking research community. This paper attempts a technical justification for those design decisions.
index977!@#@!1973!@#@!Vergleich zweier Warteschlagenmodelle f&uuml;r Realzeit-rechnersysteme mit Interrupt- bzw. Takt-Gesteuerter &Uuml;bernahme von Anforderungen aus der Peripherie!@#@!Gesellschaft f&uuml;r Informatik e.V., 3. Jahrestagung!@#@!null
index978!@#@!2003!@#@!Teaching programming in the OOP era!@#@!ACM SIGCSE Bulletin!@#@!This paper argues in favor of teaching a course in Procedural Programming first before a course in Object Oriented Programming. The basis of the argument is that considered as a paradigm, Object Oriented Programming comes in addition to the Procedural Programming paradigm and not as a replacement for it. In addition, we discuss the mathematics prerequisites required for programming and argue that Information Science departments should insist that students receive a firm foundation in traditional mathematical skills and that the use of instructional technology should reinforce these skills and not detract from them.
index979!@#@!2001!@#@!A Genome Databases Framework!@#@!Proceedings of the 12th International Conference on Database and Expert Systems Applications!@#@!null
index980!@#@!1999!@#@!Solving Equational Problems Efficiently!@#@!Proceedings of the 16th International Conference on Automated Deduction: Automated Deduction!@#@!null
index981!@#@!1999!@#@!A New Approach for Nonlinearity Test of ADCs/DACs and its Application for BIST!@#@!Proceedings of the 1999 IEEE European Test Workshop!@#@!This paper describes an algorithm to derive the non-linearity performances of Analog-to-Digital and Digital-to-Analog Converters (ADCs/DACs) from FFT results. The main advantages of the new approach over conventional ones are that the test stimuli are simpler and the influence of noise on test results decreases. This method is especially useful for the BIST (Built-In Self-Test) of converters. Experiments have shown the feasibility of this approach.
index982!@#@!2003!@#@!New software engineering faculty symposium (NSEFS 03)!@#@!International Conference on Software Engineering!@#@!null
index983!@#@!1998!@#@!A Domain Cluster Inteface for WWW Search!@#@!Proceedings of the 9th International Workshop on Database and Expert Systems Applications!@#@!Because of the recent explosive increase in the number of WWW documents, directory services are indispensable in finding needed documents. In the keyword search function of most directory services, search results are displayed as a URL list ordered by importance calculated by the system, but the order sometimes does not have any meaning to the user since the calculation algorithm is a black box. In addition, it is difficult to find useful documents from a long list. To solve this problem, the authors have developed a new WWW search system that clusters the documents in the search result by the organization name, which is derived from its URL domain name. The system displays the clusters in a hierarchical tree view form.
index984!@#@!2003!@#@!Asymptotically Optimal Worksharing in HNOWs: How Long is "Sufficiently Long?"!@#@!Proceedings of the 36th annual symposium on Simulation!@#@!We proved in [1] that "FIFO" worksharing protocols provide asymptotically optimal solutions to the HNOW-Exploitation Problem.In this problem, one has a bag oftasks, and one seeks to accomplish as much work as possibleon a heterogeneous network of workstations (HNOW)N during a prespecified fixed period.Our study proceededwithin a model that characterizes N via parametersthat measure workstations' computational and communicationalpowers.A worksharing protocol observes a FIFOregimen if it has N's workstations finish their assignedwork, and return their results, in the same order in whichthey are supplied with their work.The asymptotic optimalityof FIFO protocols resides in their accomplishing at leastas much work as any other protocol during sufficiently longworksharing periods.We perfrom a suite of simulation experiments that delimit the length of "sufficiently long."Weshow that, over a range of values of model parameters, thesuperiority of FIFO protocols is usually observed during quiteshort worksharing episodes, often in the range of a few minutes, and seldom more than a few hours.
index985!@#@!2002!@#@!Predicting Software Stability Using Case-Based Reasoning!@#@!Automated Software Engineering!@#@!Predicting stability in object-oriented (OO) software, i.e., the ease with which a software item can evolve while preserving its design, is a key feature for software maintenance. In this paper, we present a novel approach which relies on the case-based reasoning (CBR) paradigm. Thus, to predict the chances of an OO software item to break downward compatibility, our method uses knowledge of past evolution extracted from different software versions. A comparison of our similarity-based approach to a classical inductive method such as decision trees, is presented which included various tests on large datasets from existing software.
index986!@#@!2001!@#@!3D numerical simulation of drop coalescence!@#@!Scientific computing and applications!@#@!The major importance of drop coalescence in a number of natural and industrial processes provides the motivation for fundamental experimental and theoretical studies on its mechanics. One of the main difficulties of such investigations is related with the presence of a thin liquid film, typically of order 10-4 of the drop size. In numerical studies of coalescence this requires very fine spatial diseretization which, combined with the numerical instabilities typical for multiphase flows may lead to enormous CPU time.In the present study, a boundary integral method for numerical simulation of 3D drop-to-drop interactions is considered in the case of Newtonian liquids and negligible inertial forces. The main attention is directed to the application of a multiple time step approach, which can reduce the computational time required with some orders of magnitude without influencing the accuracy of the solution. However, even with this improvement, the computational process is still far from useful in a more intensive investigation, especially for small capillary numbers, which is practically the most interesting case. A modification of the existing numerical methods for 2D film drainage and rupture, taken into account a 3D-based interaction force, proves to be a successful alternative to the simulations of 3D drop coalescence.
index987!@#@!1996!@#@!Exploiting Symmetry in Parallel Computations for Structural Biology!@#@!Proceedings of the Second International Euro-Par Conference on Parallel Processing-Volume II!@#@!null
index988!@#@!1997!@#@!Three-Dimensional Quasi-binary Image Restoration for Confocal Microscopy and Its Application to Dendritic Trees!@#@!Proceedings of the 7th International Conference on Computer Analysis of Images and Patterns!@#@!null
index989!@#@!1997!@#@!Convergent assessment of radiographic diagnostic systems!@#@!CBMS!@#@!Radiological diagnostics serves as a basic monitoring technique for alveroal bone loss which is a severe consequence of periodontal disease. To evaluate efficacy of Conventional Visual Radiography (CVR), and to assess a complete clinical status we had used two more diagnostic systems. These are: Digital Subtraction Radiography (DSR) and Probing Pocket Depth (PPD). Experimental Periodontitis was studied in 20 beagle dogs based on the measurements taken in the beginning (baseline), and before (11th month) and after the medical treatment (12th month). Data analyses pointed out the same clinical trend, i.e. a significant bone loss prior to medical treatment and its recovery to the initial state. Differences in metrics and measurement errors could be identified as causes for discrepancies between the systems, but a relationship between the CVR and PPD is worth further research, as these systems do not appear to be entirely compatible, but rather complementary to each other.
index990!@#@!1997!@#@!Mobile Computing in Military Ambulatory Care!@#@!CBMS!@#@!Although satellite and cellular communication advances have enabled users of mobile computers the ability to access information regardless of location, it introduce new problems for transaction management in distributed database systems. Traditional transaction mechanism and criteria have to be adjusted to accommodate the mobile computing environment. Data replication is an example of a technique that is used in traditional database systems to increase the availability and the fault-tolerance of the data, but at the same time adds the overhead of maintaining replica consistency across multiple sites of the network. Data replication is a useful tool in mobile computing due to the fact that a mobile host may be disconnected from the network for long periods of time. The data replication allows the mobile host to use a local data copy while it is disconnected from the network. Mobile hosts that have the capability to store copies of data items increase the difficulty of maintaining replica consistency, because of the mobile host's volatile storage. Also, the mobile host must be assured that the local copies that it is using are valid, and any changes made locally to a copy is reflected in the rest of the system. In this paper, we introduce a mobile replica management algorithm. A mobile transaction manager (MTM) coordinates the transactions initiated by mobile hosts, which query and update replicated databases stored at both mobile and static hosts in a battlefield environment. This battlefield environment is based upon the U.S. telemedicine (Prime Time III) support in Bosnia. The MTM is responsible for the synchronization of the replicated data items in the network.
index991!@#@!2002!@#@!Editorial: Leveling the Field? The Fourth Interfaces Ranking of Universities' Contribution to the Practice Literature!@#@!Interfaces!@#@!null
index992!@#@!2003!@#@!Component technology: what, where, and how?!@#@!International Conference on Software Engineering!@#@!Software components, if used properly, offer many software engineering benefits. Yet, they also pose many original challenges starting from quality assurance and ranging to architectural embedding and composability. In addition, the recent movement towards services, as well as the established world of objects, causes many to wonder what purpose components might have.This extended abstract summarizes the main points of my Frontiers of Software Practice (FOSP) talk at ICSE 2003. The topics covered aim to offer an end-to-end overview of what role components should play, where they should be used, and how this can be achieved Some key open problems are also pointed out.
index993!@#@!2000!@#@!Localization of 3D Anatomical Point Landmarks in 3D Tomographic Images Using Deformable Models!@#@!Proceedings of the Third International Conference on Medical Image Computing and Computer-Assisted Intervention!@#@!null
index994!@#@!1993!@#@!Klassifikation von Biosignalen am Beispiel visuell evozierter Potentiale mit Hilfe von Wavelet-Netzen!@#@!Mustererkennung 1993, Mustererkennung im Dienste der Gesundheit, 15. DAGM-Symposium!@#@!null
index995!@#@!1997!@#@!Author Index!@#@!Proceedings of the 12th Annual IEEE Symposium on Logic in Computer Science!@#@!Summary form only as given. Studies indicate that a critical point in the pipeline of women into technological careers is the middle school years, when it is common for girls to lose interest in math and science. In order to address this problem within the Central Massachusetts region, WPI initiated in the summer of 1997 a two-week residential outreach program designed specifically for girls entering the seventh grade. The overall goal of "Camp REACH" is to generate or sustain adolescent girls' interest in engineering and technology and to enhance self-confidence and motivation toward education. The camp program is shaped by a philosophical approach that emphasizes the direct benefit engineers can have on society and the development of technological self-efficacy through successful hands-on tasks. Program activities include a "community service design project" for a customer in the Worcester community, hands-on experiential workshops, field trips, speakers, recreational activities, informational sessions for parents, and follow-up programs during the academic year. Girls interact with a spectrum of role models including women high school students, WPI students and faculty, middle school math and science teachers, and practicing engineers. In this talk, the authors discuss successes and lessons learned from the first camp offering, and formative and preliminary summative evaluation results are presented. The ACM Portal is published by the Association for Computing Machinery. Copyright © 2010 ACM, Inc. Terms of Usage Privacy Policy Code of Ethics Contact Us Useful downloads: Adobe Acrobat QuickTime Windows Media Player Real Player
index996!@#@!2003!@#@!Predicate prediction for efficient out-of-order execution!@#@!International Conference on Supercomputing!@#@!Predicated execution is an important optimization even for an out-of-order processor, since it can eliminate hard to predict branches and help to enable software pipelining. Using predication with out-of-order execution creates a naming bottleneck, because there can be multiple definitions reaching a use, and not knowing which use is the correct one can stall the processor.In this paper, we examine using predicate prediction to speculatively allow execution to proceed in the face of multiple definitions. We show that the penalty for mispredicting a predicate is not as severe as mispredicting a branch. Thus, making it advantageous to replace hard to predict branches with predicate predictions. We present a predicate misprediction recovery architecture that replays instructions through the renamer to link up the correct dependencies on a misprediction. This approach allows us to avoid putting the predicted false path instructions in the issue queue reducing the pressure on the dynamic out-of-order scheduler.
index997!@#@!2003!@#@!Customer Lifetime Value Models for Decision Support!@#@!Data Mining and Knowledge Discovery!@#@!We present and discuss the important business problem of estimating the effect of marketing activities on the Lifetime Value of a customer in the Telecommunications industry. We discuss the components of this problem, in particular customer value and length of service (or tenure) modeling, and present a novel segment-based approach, motivated by the segment-level view marketing analysts usually employ. We describe in detail how we build on this approach to estimate the effects of retention campaigns on Lifetime Value, and also discuss its application in other situations. Our solution has been successfully implemented by the Business Insight (BI) Professional Services.
index998!@#@!1998!@#@!Integrated Scientific Computing in Global Networks!@#@!Proceedings of the Thirty-First Annual Hawaii International Conference on System Sciences-Volume 7 - Volume 7!@#@!In network computing, methods (scripts, programs, models, macros, etc.) are executed at remote sites in a transparent way. Distributed Method Management Systems (DMMSs) for network computing allow easy dissemination of new methods over global networks by supporting the publishing of new methods as well as finding and executing existing methods. For consumers, DMMSs replace awkward telnet sessions or debugging cycles for down-loaded public domain software with click'n'go access to methods running in a suitable execution environment. For providers, DMMSs simplify the process of putting methods on the Web to a minimum. In scientific computing, methods are typically scripts for scientific computing packages like Mathematica or Matlab, compiled programs, or stand-alone Internet servers providing computational services. Methods can be applied to data sets available within the DMMS or anywhere on the Internet. The paper presents CoMMM, an object-oriented application framework and runtime environment for DMMSs. CoMMM wraps methods into CORBA objects and provides CORBA Common Facilities for publishing, finding and executing methods.
index999!@#@!2002!@#@!Virtual reality as simulation: the CAVE as 'space of illusion in museum displays!@#@!Virtual space: spatiality in virtual inhabited 3D worlds!@#@!null
index1000!@#@!2000!@#@!Compressed Domain Texture Classification from a Modified EZW Symbol Stream!@#@!Proceedings of the Conference on Data Compression!@#@!The extraction of texture features from compressed images can be cumbersome using traditional decompress-process methods. This paper proposes a method for calculating wavelet energy texture features directly from a wavelet compressed symbol stream. The proposed method requires little decompression (only arithmetic decoding is necessary) and results in a technique that is efficient and requires less memory than traditional approaches. The developed algorithm has been implemented at various compression ratios and in each case, the classification results are nearly identical to those obtained with the traditional method.
index1001!@#@!1993!@#@!Nichtlineare Diffusion zur Integration visueller Daten-Anwendung auf Kernspintomogramme!@#@!Mustererkennung 1993, Mustererkennung im Dienste der Gesundheit, 15. DAGM-Symposium!@#@!null
index1002!@#@!1996!@#@!Implementing and Testing ATM in a Production LAN!@#@!Proceedings of the 29th Hawaii International Conference on System Sciences Volume 1: Software Technology and Architecture!@#@!This work performed at Sandia National Laboratories supported by the U. S. Department of Energy under contract DE-AC04-94AL85000. Asynchronous Transfer Mode (ATM) technology is currently receiving extensive attention in the computer networking arena. Many experts predict that ATM will be the future networking technology for both the Local Area Network (LAN) and the Wide Area Network (WAN). This paper presents the results of a collaboration between Sandia National Laboratories' Advanced Networking Department and Engineering Sciences Center to study the implementation of ATM in one of Sandia's most heavily loaded production networks. The network consists of over 120 Sun Sparc 10s and 20s, two SparcCenter 2000s, a 12 node parallel IBM SP-2, and several other miscellaneous high-end workstations.The existing network was first characterized through extensive traffic measurements to better understand the capabilities and limitations of the existing network technologies and to provide a baseline for comparison to an ATM network. This characterization was used to select a subset of the network elements which would benefit most from conversion to the ATM technology. This subset was then converted to equipment based on the latest ATM standards. With direct OC-3c (155 Mbps) host connections for the workstations and the file and compute servers, we demonstrated as much as 122 Mbps throughput (memory-to-memory TCP/IP transfers) between endpoints. Flow control in the classical many-to-one client server environment was also investigated.Throughout all of our tests, the interaction of the user applications with the network technologies was documented and possible improvements were tested. The performance and reliability of the ATM network was compared to the original network to determine the benefits and liabilities of the ATM technology.
index1003!@#@!1995!@#@!Strictness and Totality Analysis with Conjunction!@#@!Proceedings of the 6th International Joint Conference CAAP/FASE on Theory and Practice of Software Development!@#@!null
index1004!@#@!2003!@#@!Communicating Centrality in Policy Network Drawings!@#@!IEEE Transactions on Visualization and Computer Graphics!@#@!We introduce a network visualization technique that supports an analytical method applied in the social sciences. Policy network analysis is an approach to study policy making structures, processes, and outcomes, thereby concentrating on relations between policy actors. An important operational concept for the analysis of policy networks is the notion of centrality, i.e., the distinction of actors according to their importance in a relational structure. We integrate this measure in a layout model for networks by mapping structural to geometric centrality. Thus, centrality values and network data can be presented simultaneously and explored interactively.
index1005!@#@!2000!@#@!Model Based Contour Searching Method!@#@!Proceedings of the 1st IEEE International Symposium on Bioinformatics and Biomedical Engineering!@#@!A two-step model based approach to a contour extraction problem is developed to provide a solution to more challenging contour extraction problems of biomedical images. A biomedical contour image is initially processed by a deformable contour method to obtain a first order approximation of the contour. The two-step model includes a linked contour model and a posteriori probability model. Initially, the output contour from the deformable contour method is matched against the linked contour model for both model detection and corresponding landmark contour points identification. Segments obtained from these landmarks are matched for errors. Larger error are then passed on to a regionalized a posteriori probability model for further fine tuning to obtain a final result. Experiments on both MR brain images are most encouraging.
index1006!@#@!2001!@#@!Property Preserving Transition Refinement with Concurrent Runs: An Example!@#@!Proceedings of the Second International Conference on Application of Concurrency to System Design!@#@!We suggest a new notion of behavior preserving transition refinement based on partial order semantics. Furthermore, we discuss how to prove the correctness of a transition refinement step. Our results are formalized in the setting of Petri nets. We use Petri nets because they have a canonical partial order semantics, which is defined by concurrent runs.
index1007!@#@!1995!@#@!Rekonstruktion von Schleifpapieroberfl&auml;chen f&uuml;r die Qualit&auml;tskontrolle!@#@!Mustererkennung 1995, 17. DAGM-Symposium!@#@!null
index1008!@#@!1995!@#@!A variant of Cooley-Tuckey algorithm with local memory management!@#@!Proceedings of the 1995 European conference on Design and Test!@#@!We hereby introduce an extension of the Cooley-Tuckey algorithm (CT) aimed at increasing the temporal locality of memory references. It enables one to reduce the stress on external accesses by using a small fast on-chip memory. So it is suitable for large Discrete Fourier Transform (DFT). Configurations of the algorithm parameters according to different optimisation criteria are detailed and a real ASIC application for image processing is described.
index1009!@#@!2000!@#@!An Animation Toolkit Based on Motion Mapping!@#@!Proceedings of the International Conference on Computer Graphics!@#@!In this paper, we present a character animation toolkit for generating animation sequences interactively. It is based on a motion mapping technique that an object's motion can be applied to another object interactively. The toolkit generates the mesh for an object from several feature points on photo images automatically. An object's motion is defined and manipulated independently of modeling data. The motion generated once is applied to any object by the mapping technique according to an animation hierarchical data structure. The animation toolkit is appropriate for generating character animation that needs interactive motion modification and reuse rather than accurate modeling.
index1010!@#@!1995!@#@!Evaluation of a data communication model for switched fibre channel!@#@!Proceedings of the 20th Annual IEEE Conference on Local Computer Networks!@#@!ANSI standard Fibre Channel is emerging as the networking protocol of choice for high bandwidth applications. Fibre Channel is an enabling technology because of the tremendous advantages in speed and latency it provides over existing networking technologies. Applications which weren't feasible before are now possible and more will follow which demand this performance. Fibre Channel is the high performance alternative to existing networking technologies such as FDDI, Fast Ethernet, and ATM. Fibre Channel (FC) provides for 2 different data communication models, connection and connectionless. Although interoperable, some of these implementations may not result in optimal performance. For example, applications for disk attach typically use FC class 2 with large frame sizes for data transfer. Client/server applications in imaging are using large class 1 frames. There is some disagreement in the FC community as to which is more appropriate. Both have their advantages and disadvantages and so its necessary to look at each application individually. This paper addresses some of these issues by simulating these 2 communication models over different switch architectures.
index1011!@#@!1999!@#@!Multiresolution Representation of Shapes Based on Cell Complexes (Invited Paper)!@#@!Proceedings of the 8th International Conference on Discrete Geometry for Computer Imagery!@#@!null
index1012!@#@!2002!@#@!Approximation of random fixed points in normed spaces!@#@!Nonlinear Analysis: Theory, Methods &amp; Applications!@#@!null
index1013!@#@!2003!@#@!A Fast Algorithm for NA Secondary Structure Prediction Including Pseudoknots!@#@!Proceedings of the 3rd IEEE Symposium on BioInformatics and BioEngineering!@#@!Many important RN molecules contain pseudoknots, which are generally excluded by the definition of the secondary structure, mainly for computational reasons. Still, most existing algorithms for secondary structure prediction are not satisfactory in results and complexities, even when pseudoknots are not allowed. We present an algorithm, called P-DCFold, for the prediction of RN secondary structures including all kinds of pseudoknots. It is based on the comparative approach. The helices are searched recursively, from more "likely" to less "likely", using the "Divide and Conquer" approach. This approach, which allows to limit the amount of searching, is possible when only non-interleaved helices are searched for. Thepseudoknots are therefore searched in several steps, each helix of the pseudoknot being selected in a different step.P-DCFold has been applied to tmRN and RnaseP sequences. In less than two seconds, their respective secondary structures, including their pseudoknots, have been recovered very efficiently.
index1014!@#@!2000!@#@!IP route lookups as string matching!@#@!Proceedings of the 25th Annual IEEE Conference on Local Computer Networks!@#@!An IP route lookup can be considered as a string matching problem on the destination address. Finite state automata (FSA) are a flexible and efficient way to match strings. This paper describes how a routing table can be encoded as an FSA and how, through a process of state reduction, we can obtain an optimal representation. This gives insights into the basic properties of the longest-prefix match problem.
index1015!@#@!2002!@#@!External Technology Sourcing Through Alliances or Acquisitions: An Analysis of the Application-Specific Integrated Circuits Industry!@#@!Organization Science!@#@!In today's turbulent business environment innovation is the result of the interplay between two distinct but related factors: endogenous R&D efforts and (quasi) external acquisition of technology and know-how. Given the increasing importance of innovation, it is vital to understand more about the alternative mechanisms--such as alliances and acquisitions--that can be used to enhance the innovative performance of companies. Most of the literature has dealt with these alternatives as isolated issues. Companies, however, are constantly challenged to choose between acquisitions and strategic alliances, given the limited resources that can be spent on research and development. This paper contributes to the literature because it focuses on the choice between innovation-related alliances and acquisitions. We focus on the question of how the trade-off between strategic alliances and acquisitions is influenced by previous direct and indirect ties between firms in an industry network of interfirm alliances. We formulate hypotheses pertaining to the number of direct ties between two companies, their proximity in the overall alliance network, and their centrality in that network. In so doing, we distinguish between ties that connect firms from the same and from different industry segments, and those that connect firms from the same or from different world regions. These hypotheses are tested on a sample of strategic alliances and acquisitions in the application-specific integrated circuits (ASIC) industry. The findings show that a series of strategic alliances between two partners increases the probability that one will ultimately acquire the other. Whereas previous direct contacts tend to lead to an acquisition, this is not true of previous indirect contacts, which increase the probability that a link between the companies, once it is forged, takes the form of a strategic alliance. In the case of acquisitions, firms that are more centrally located in the network of interfirm alliances tend to be acquirers, and firms with a less central position tend to become acquired. These findings underscore the importance of taking previously formed interfirm linkages into account when explaining the choice between strategic alliances and acquisitions, as these existing links influence the transaction costs associated with both alternatives.
index1016!@#@!2000!@#@!About Authors!@#@!Organization Science!@#@!null
index1017!@#@!2002!@#@!Flexible Software Process Enactment Support in the APSEE Model!@#@!HCC!@#@!Software Process Technology recently evolved to automate software process management by providing specialized languages and environments to control the human performance in software development activities. This paper presents APSEE as an executable visuallanguage for software process modeling. The meta-model was specified using graph-grammars, which successfully derived a Java-based implementation. Finally, thisexperience is discussed with respect to the support for dynamic changes in enacting processes.
index1018!@#@!1994!@#@!A comparison of two handwriting recognizers for pen-based computers!@#@!Proceedings of the 1994 conference of the Centre for Advanced Studies on Collaborative research!@#@!An experiment is described that compares two commercial handwriting recognizers with handprinted characters. Each recognizer was tested at two levels of constraint, one using lowercase letters (which were the only symbols included in the input text) and the other using both uppercase and lowercase letters. Two factors - recognizer and constraint - with two levels each, resulted in four test conditions. A total of 16 subjects performed text-entry tasks for each condition. Recognition accuracy differed significantly among conditions. Furthermore, the accuracy observed was far below the walk-up accuracy claimed by the developers of the recognizers. Entry speed was affected not by recognition conditions but by users' adaptation to the idiosyncrasies of the recognizers. User satisfaction results showed that recognition accuracy greatly affects the impression of walk-up users.
index1019!@#@!2002!@#@!An ERP-client benefit-oriented maintenance taxonomy!@#@!Journal of Systems and Software!@#@!The worldwide installed base of enterprise resource planning (ERP) systems has increased rapidly over the past 10 years now comprising tens of thousands of installations in large- and medium-sized organizations and millions of licensed users. Similar to traditional information systems (IS), ERP systems must be maintained and upgraded. It is therefore not surprising that ERP maintenance activities have become the largest budget provision in the IS departments of many ERP-using organizations. Yet, there has been limited study of ERP maintenance activities. Are they simply instances of traditional software maintenance activities to which traditional software maintenance research findings can be generalized? Or are they fundamentally different, such that new research, specific to ERP maintenance, is required to help alleviate the ERP maintenance burden? This paper reports a case study of a large organization that implemented ERP (an SAP system) more than three years ago. From the case study and data collected, we observe the following distinctions of ERP maintenance: (1) the ERP-using organization, in addition to addressing internally originated change-requests, also implements maintenance introduced by the vendor; (2) requests for user-support concerning the ERP system behavior, function and training constitute a main part of ERP maintenance activity; and (3) similar to the in-house software environment, enhancement is the major maintenance activity in the ERP environment, encompassing almost 64% of the total change-request effort. In light of these and other findings, we ultimately: (1) propose a clear and precise definition of ERP maintenance; (2) conclude that ERP maintenance cannot be sufficiently described by existing software maintenance taxonomies; and (3) propose a benefits-oriented taxonomy, that better represents ERP maintenance activities. Three salient dimensions (for characterizing requests) incorporated in the proposed ERP maintenance taxonomy are: (1) who is the maintenance source? (2) why is it important to service the request? and (3) what--whether there is any impact of implementing the request on the installed module(s)?
index1020!@#@!2003!@#@!Mutual Information Agreement in Multicomputer Systems with the Detection and Identification of Byzantine Faults!@#@!Automation and Remote Control!@#@!A method is suggested of the mutual information agreementin multicomputer systems with intercomputer bus-type communication channels and the broadcast way of transfer of intercomputer messages. The method makes it possible to detect and identify symptoms (both by the places of their emergence and by the types of faults, such as malfunctions programmed malfunctions, or failures) of multiple faults of computers and transmitting interfaces (interface devices) with communication channels, which can occur in all cycles of the interchange. In addition, the method enables one to distinguish, first, faults of computers and transmitting interfaces, if it is possible, and, second, the situation of the nondelivery of a message in initial cycles and the situation of the delivery of this message with distortions.
index1021!@#@!2001!@#@!Engineering of distributed control systems!@#@!Engineering of distributed control systems!@#@!null
index1022!@#@!2002!@#@!Ontology Versioning and Change Detection on the Web!@#@!Proceedings of the 13th International Conference on Knowledge Engineering and Knowledge Management. Ontologies and the Semantic Web!@#@!null
index1023!@#@!1999!@#@!Implementing "Object Ownership to Order"!@#@!Proceedings of the Workshop on Object-Oriented Technology!@#@!null
index1024!@#@!2003!@#@!A constraint satisfaction neural network and heuristic combined approach for concurrent activities scheduling!@#@!Journal of Computer Science and Technology!@#@!Scheduling activities in concurrent product development process is of great significance to shorten development lead time and minimize the cost. Moreover, it can eliminate the unnecessary redesign periods and guarantee that serial activities can be executed as concurrently as possible. This paper presents a constraint satisfaction neural network and heuristic combined approach for concurrent activities scheduling. In the combined approach, the neural network is used to obtain a feasible starting time of all the activities based on sequence constraints, the heuristic algorithm is used to obtain a feasible solution of the scheduling problem based on resource constraints. The feasible scheduling solution is obtained by a gradient optimization function. Simulations have shown that the proposed combined approach is efficient and feasible with respect to concurrent activities scheduling.
index1025!@#@!2002!@#@!An agent approach to security in pervasive environments!@#@!Eighteenth national conference on Artificial intelligence!@#@!null
index1026!@#@!1996!@#@!Supporting procedural constructs in existing SQL compilers!@#@!Proceedings of the 1996 conference of the Centre for Advanced Studies on Collaborative research!@#@!The draft of the SQL/PSM standard denes a procedural extension to the existing SQL2 language. An essential part of this extension is the support of procedural constructs such as BEGIN/END blocks, local variables, assignment statements, conditional statements, and various forms of loops.Such an extension introduces new challenges to existing SQL compilers. Most SQL compilers exiting in the marketplace today were built based on the declarativeness of SQL. The question is how these procedural extensions can be best implemented in a relational DBMS without losing the power of existing query optimization mechanisms. So far, most implementations of the SQL procedural extensions rely on the use of a separate interpreter to handle the procedural statements so that the existing SQL compiler can be left untouched. Although this approach is quite easy to implement (as it follows the paradigm currently used between SQL and host languages), it does not provide the best possible performance.In this paper, we propose an integrated approach to extend existing query compilers to support SQL/PSM-like procedural extensions. We show how the existing SQL compiler infrastructure can be generalized to accommodate the new procedural constructs, and we describe how this approach can be implemented as part of an existing DBMS. The work presented in this paper has been prototyped on the code base of IBM DB2 for Common Server Version 2 product.
index1027!@#@!1987!@#@!Navigation of an Airborne Vehicle by Model-Based Image Sequence Processing!@#@!Aachener Symposium f&uuml;r Signaltheorie: Mehrdimensionale Signale und Bildverarbeitung!@#@!null
index1028!@#@!1996!@#@!Compiler-assisted generation of error-detecting parallel programs!@#@!FTCS!@#@!We have developed an automated a compile time approach to generating error-detecting parallel programs. The compiler is used to identify statements implementing affine transformations within the program and to automatically insert code for computing, manipulating, and comparing checksums in order to detect data errors at runtime. Statements which do not implement affine transformations are checked by duplication. Checksums are reused from one loop to the next if this is possible, rather than recomputing checksums for every statement. A global dataflow analysis is performed in order to determine points at which checksums need to be recomputed. We also use a novel method of specifying the data distributions of the check data using data distribution directives so that the computations on the original data, and the corresponding check computations are performed on different processors. Results on the time overhead and error coverage of the error detecting parallel programs over the original programs are presented on an Intel Paragon distributed memory multicomputer.
index1029!@#@!2003!@#@!Error Minimization for Approximate Computation of Range Aggregates!@#@!Proceedings of the Eighth International Conference on Database Systems for Advanced Applications!@#@!Histogram techniques are widely used in commercialdatabase management systems for an estimation of queryresults. Recently, they have been also used in approximately processing database queries, especially aggregationqueries. Existing research results in this area have beenmainly focused on constructing a histogram to approximately represent, as accurate as possible on an intuitivebase, the original data frequencies. In this paper, we willpropose a novel histogram construction method aiming tominimize the average approximate aggregatio errors; andwe have developed an efficient algorithm to construct nearoptimal histograms to achieve this goal. Our experimentresults showed that the new histogram construction techniques lead to more accurate results than those by existing histogram techniques, and also out-perform the existingwavelet techniques.
index1030!@#@!1995!@#@!Efficient spline interpolation!@#@!ASILOMAR!@#@!The problem of interpolating data points using a smooth function has many existing solutions. In particular, the use of piecewise polynomials (splines) has provided solutions with user controlled smoothness. In this paper we introduce a new interpolation procedure which utilizes multiple knot Hermitian splines. The technique renders the interpolating spline function using fixed point shifts and additions. In applications requiring parallel computation the use of these simpler operations implies a significant reduction in hardware complexity.
index1031!@#@!2000!@#@!Stepping into Cooperative Buildings!@#@!Proceedings of the First Australasian User Interface Conference!@#@!If we are stepping out of windows, what are we stepping into? We suggest it is into cooperative buildings. For the foreseeable future, at least, we can identify two major characteristics of the cooperative building. The spaces of the building will be augmented in various ways, providing an ambient environment that bridges spatial discontinuities in work-groups and provides a continuous window into the state of the virtual world. Secondly, the ways in which the spaces themselves are used will evolve to be more congruent with the fluid, dynamic and distributed nature of the work taking place in the building. These two characteristics are deeply interconnected. This evolution need not happen entirely in the physical world; the essence of a cooperative building will be-come the way in which it mixes both physical and virtual affordances to support the workaday activities of its inhabitants.
index1032!@#@!2000!@#@!The Impact of an Integrated Marketing and Manufacturing Innovation!@#@!Manufacturing &amp; Service Operations Management!@#@!Suppose you are a Marketing Manager envisioning a new product, or an Operations Manager contemplating a process improvement, or a CEO who commissioned an integrated new product development team. If our assumptions hold, our model offers you a single numerical measure, called thedegree of product/process innovation, to determine your initiative's impact on potential sales, prices, market segments, and profits. Our simple, single-period model is a variation of the existing vertically differentiated products model: There are two competing substitute products, and customers will buy at most one of them. Our contribution is to allow new relationships between the valuations of the two products by potential customers, and to allow differing unit production costs. We identify equilibrium results when two competing firms each offer one product, and find the profit maximizing result when one (monopolistic) firm offers both products. The new product infringes on the market in one of two ways:High-end encroachment results when the new product attracts the best customers (those with the highest reservation prices), whilelow-end encroachment identifies a situation where the new product attracts fringe (lower-end) customers. Low-end encroachment may help explain why an incumbent sometimes fails to recognize the threat of an entrant's product, as we illustrate with an example from the disk drive industry. In short, we offer insight into the value of both a marketing objective (enhancing the product design attributes) and a manufacturing goal (lowering the production cost) in a product and/or process improvement project.
index1033!@#@!2002!@#@!A New Image Registration Technique with Free Boundary Constraints: Application to Mammography!@#@!Proceedings of the 7th European Conference on Computer Vision-Part IV!@#@!null
index1034!@#@!2002!@#@!Composable Tools For Network Discovery and Security Analysis!@#@!Proceedings of the 18th Annual Computer Security Applications Conference!@#@!Security analysis should take advantage of a reliableknowledge base that contains semantically-rich informationabout a protected network. This knowledge is provided bynetwork mapping tools. These tools rely on models to representthe entities of interest, and they leverage off networkdiscovery techniques to populate the model structure withthe data that is pertinent to a specific target network. Unfortunately,existing tools rely on incomplete data models.Networks are complex systems and most approaches over-simplifytheir target models in an effort to limit the problemspace. In addition, the techniques used to populate the modelsare limited in scope and are difficult to extend.This paper presents NetMap, a security tool for networkmodeling, discovery, and analysis. NetMap relies on a comprehensivenetwork model that is not limited to a specificnetwork level; it integrates network information throughoutthe layers. The model contains information about topology,infrastructure, and deployed services. In addition, therelationships among different entities in different layers ofthe model are made explicit. The modeled information ismanaged by using a suite of composable network tools thatcan determine various aspects of network configurationsthrough scanning techniques and heuristics. Tools in thesuite are responsible for a single, well-defined task. Eachtool has an abstract specification of the input, the output,the type of processing, and the requirements for carryingout a task. Tool descriptions are expressed in a NetworkTool Language. The tool descriptions are then stored in adatabase. By using the network model and the tool descriptions,NetMap is able to automatically determine whichtools are needed to perform a particular complex task andhow the tools should be scheduled to obtain the requestedresults.
index1035!@#@!2002!@#@!Optimizing Military Airlift!@#@!Operations Research!@#@!We describe a large-scale linear programming model for optimizing strategic (intercontinental) airlift capability. The model routes cargo and passengers through a specified transportation network with a given fleet of aircraft subject to many physical and policy constraints. The time-dynamic model captures a significant number of the important aspects of an airlift system in a large-scale military deployment, including aerial refueling, tactical (intracontinental) aircraft shuttles, and constraints based on crew availability. The model is designed to provide insight into issues associated with designing and operating an airlift system. We describe analyses for the U.S. Air Force system concerning fleet modernization and concerning the allocation of resources that affect the processing capacity of airfields.
index1036!@#@!1996!@#@!Properties of Complexity Measures for PRAMs and WRAMs!@#@!Mathematical Foundations of Computer Science 1986!@#@!null
index1037!@#@!1998!@#@!Acknowledgements!@#@!Proceedings of the Great Lakes Symposium on VLSI '98!@#@!null
index1038!@#@!1997!@#@!Matching 3-D arcs!@#@!CVPR!@#@!We present a new algorithm for efficient matching of 3-D polygonal arcs. The algorithm is based on the decomposition of the arcs into sets of corresponding line segments with equal lengths. We derive a closed-form solution for the transformation that gives the best match between two sets of corresponding line segments (best in the sense of an L/sub 2/ norm distance measure), which enables the development of efficient arc matching algorithm. We apply this algorithm to the problem of finding a match between a short are and a piece of a long arc in real and synthetic images, and compare the results with alternative techniques in the literature.
index1039!@#@!2003!@#@!Prelayout interconnect yield prediction!@#@!IEEE Transactions on Very Large Scale Integration (VLSI) Systems!@#@!Functional yield is a term used to describe the percentage of dies on a wafer that are not affected by catastrophic defects. Within the interconnect these defects are usually caused by particle contamination and are divided into bridging defects, which join adjacent wires and cuts, which result in broken wires. Functional yield is therefore determined by the geometry of the routing channels, how these channels are filled with wire and the distribution of defect sizes. Since the wire spacing and width are usually fixed and the distribution of defects within a mature production facility is well known, the problem reduces to estimating individual wire lengths for cuts and to estimating the overlapping distance that two wires share in neighboring sections of the routing grid for bridges. Previous work in this area has analyzed the problem by assuming that all wiring tracks are occupied with wire, leading to overestimates for the probability of failure due to both cuts and bridges. This paper utilizes statistical models of the placement/routing process to provide a more realistic approach for cut and bridge yield estimation. A comparison of the predicted probability of failure within each wiring layer with postlayout data indicate an average error of 20% for cuts and 26% for bridges.
index1040!@#@!1998!@#@!Using Containment Information for View Evolution in Dynamic Distributed Environments!@#@!Proceedings of the 9th International Workshop on Database and Expert Systems Applications!@#@!The maintenance of materialized views in large-scale environments composed of numerous information sources (ISs), such as in the WWW, is complicated by ISs not only continuously modifying their contents but also their capabilities (schemas and query interfaces). With current view technology, views become undefined when ISs change their capabilities. Our Evolvable View Environment (EVE) project addresses this new problem of evolving views under IS capabilities changes, which we coin view synchronization problem. Key principles of EVE include a user-specified preference model for view evolution (Evolvable-SQL (E-SQL)) and a Model for Information Source Descriptions (MISD). In this paper, we first present a formal characterization of correctness of view synchronization using containment constraints defined in MISD. Then, we give a novel view synchronization algorithm for view rewriting exploiting general containment constraints between the to-be-replaced relation and its replacement.
index1041!@#@!1997!@#@!Generic Trading Servivce in Telecommunication Platforms!@#@!Proceedings of the Fifth International Conference on Conceptual Structures: Fulfilling Peirce's Dream!@#@!null
index1042!@#@!1998!@#@!Implementing Fuzzy Querying via the Internet/WWW: Java Applets, ActiveX Controls and Cookies!@#@!Proceedings of the Third International Conference on Flexible Query Answering Systems!@#@!null
index1043!@#@!2003!@#@!Role mining - revealing business roles for security administration using data mining technology!@#@!Symposium on Access Control Models and Technologies!@#@!In this paper we describe the work devising a new technique for role-finding to implement Role-Based Security Administration. Our results stem from industrial projects, where large-scale customers wanted to migrate to Role-Based Access Control (RBAC) based on already existing access rights patterns in their production IT-systems.
index1044!@#@!1995!@#@!Using Mirror Cameras for Estimating Depth!@#@!Proceedings of the 6th International Conference on Computer Analysis of Images and Patterns!@#@!null
index1045!@#@!1995!@#@!Multichannel space-time adaptive processing!@#@!ASILOMAR!@#@!A new recursive processing technique for space-time adaptive processing (STAP) is developed and applied to the airborne MTI radar problem. Unlike the conventional approach, the expanding block structure of the covariance matrix is exploited for updating the covariance matrix inverse as each pulse is received. The resulting block augmented matrix (BAM) inversion algorithm results in significant computational throughput gain. Further, the residual information in the incoming pulse is used to generate an adaptive stopping criterion that addresses the sample data support problem.
index1046!@#@!1979!@#@!A survey of symbolic computation in physics (invited)!@#@!Proceedings of the International Symposiumon on Symbolic and Algebraic Computation!@#@!null
index1047!@#@!1995!@#@!Distributing Search and Knowledge Using a Coordination Language!@#@!Proceedings of the 3rd International Conference on Parallel Computing Technologies!@#@!null
index1048!@#@!1999!@#@!Decentralized Adaptive Flow Control of High-Speed Connectionless Data Networks!@#@!Operations Research!@#@!We introduce a permit-based adaptive control scheme for regulating traffic admission in high-speed connectionless data networks, such as the internet. Permits are awarded to potential customers arriving from outside and travel with them towards their destinations, where the permits are assigned to the local controllers. The controllers randomly distribute the permits among the entry gates at the nodes. Customers from outside are not allowed to enter the network unless there are permits available at the entrance node, thus the model is that of a closed queueing network if we model the dynamics of the permits. The goal is to find the permit distribution strategy that maximizes network performance subject to the restrictions of the network topology. A traffic balance approach is used to establish nonuniqueness of the optimal distribution probabilities for the decentralized operation. We exploit nonuniqueness introducing the concept of the automata actions, focusing on two strategies for the actions. For each strategy, a learning automaton is implemented at the controllers using the Kuhn-Tucker conditions for optimality. Our first learning algorithm converges weakly to a unique limit point, which is optimal, while the limit behaviour of our second learning algorithm may be suboptimal. We illustrate our results using computer simulations in order to compare the two strategies for the same network.
index1049!@#@!2002!@#@!Visual Scripting for Handheld Computers!@#@!HCC!@#@!This paper describes PDAGraph, an event-driven, component-based visual programming language for power users of Handheld Computers or Personal Digital Assistants (PDAs)who are not necessarily professional programmers. PDAGraph is intended to run on a PDA and will give power users the ability to create customized applications, taking advantage ofexisting PDA applications and hardware modules (such as springboard modules available for the Handspring Visor). The language is component-based and ensures that the user cancreate only syntactically correct programs by placing and linking components or component items. There are external, user interface, and script components, all of which are reusable.
index1050!@#@!2002!@#@!Itinerary-Based Airline Fleet Assignment!@#@!Transportation Science!@#@!We consider the airline fleet assignment problem involving the profit maximizing assignment of aircraft types to flight legs. Although several basic formulations have been proposed, important network considerations are insufficiently treated in these formulations and the resulting solutions are often suboptimal. We propose a new formulation and solution approach that captures network effects and generates superior solutions. We quantify the benefits of our proposed approach in a case study using data from a major United States airline.
index1051!@#@!1995!@#@!Modularization, re-use and testing for parallel message-passing programs!@#@!Proceedings of the 28th Hawaii International Conference on System Sciences!@#@!The advantages of modularization which are well-known in sequential programming should also be exploited when designing and developing parallel programs. We investigate the requirements for such a concept in the context of an explicit, imperative message-passing programming language for the distributed memory paradigm. The language is a hybrid one in the sense that all parallel aspects are specified by means of graphical constructs whereas sequential parts are formulated in a slightly restricted ANSI-C.
index1052!@#@!2002!@#@!Types, or: Where's the Difference Between CCS and pi?!@#@!Proceedings of the 13th International Conference on Concurrency Theory!@#@!null
index1053!@#@!1998!@#@!Recursive Types in Games: Axiomatics and Process Representation!@#@!Proceedings of the 13th Annual IEEE Symposium on Logic in Computer Science!@#@!null
index1054!@#@!2002!@#@!Model-based Animation of Coverbal Gesture!@#@!Proceedings of the Computer Animation!@#@!Virtual conversational agents are supposed to combine speech with nonverbal modalities for intelligible and believeable utterances. However, the automatic synthesi of coverbal gestures still struggles with several problems like naturalness in procedurally generated animations, flexibility in pre-defined movements, and synchronization with speech. In thi paper, we focus on generating complex multimodal utterances including gesture and speech from XML-based descriptions of their overt form. We describe a coordination model that reproduces co-arcticulation and transition effects in both modalities. In particular, an efficient kinematic approach to creating gesture animations from shape specifications is presented, which provides fine adaptation to temporal constraint that are imposed by cross-modal synchrony.
index1055!@#@!2001!@#@!Proceedings of the 3rd ACM SIGPLAN international conference on Principles and practice of declarative programming!@#@!International Conference on Principles and Practice of Declarative Programming!@#@!This volume contains the papers and abstracts presented at PPDP'01, the Third International ACM SIGPLAN Conference on Principles and Practice of Declarative Programming, held in Florence, Italy, September 5-7, 2001.Together with the Sixth International ACM SIGPLAN Conference on Functional Programming (ICFP) and a number of associated workshops, PPDP'01 has formed a federation of conferences known as Colloquium on Principles, Logics, and Implementations of high-level programming languages (PLI 2001). Previous PLI colloquia were held in Paris, in September 1999, and in Montr&eacute;al, in September 2000. These events are organised by SIGPLAN, ACM's Special Interest Group on Programming Languages.PPDP 2001 aims to stimulate research on the use of declarative methods in programming and on the design, implementation and application of programming languages that support such methods. Topics of interest include any aspect related to understanding, integrating and extending programming paradigms such as those for functional, logic, constraint and object-oriented programming; concurrent extensions and mobile computing; type theory; support for modularity; use of logical methods in the design of program development tools; program analysis and verification; abstract interpretation; development ofimplementation methods; and application of the relevant paradigms and associated methods in industry and education.A total of 40 submissions were received in response to the call for papers. The START conference management system was used for the handling of electronic submissions, for allocation of reviewing duties, and for filing of reviews. The program committee meeting was conducted electronically. Each paper was reviewed by at least three referees and 19 papers were selected for publication. In addition to the regular paper presentations, the scientific program included three invited talks, by Javier Esparza (University of Edinburgh), Andrew Gordon (Microsoft Research Cambridge), and Dave Schmidt (Kansas State University).
index1056!@#@!2002!@#@!Adopting a Plurality Vote Perspective!@#@!Mathematics of Operations Research!@#@!For three-alternative positional voting and decision methods, it is shown how to decompose the profiles and data sets in a manner which identifies all possible conflict relative to a specified procedure. This approach is illustrated with the plurality vote by characterizing all possible profiles which cause all possible conflicts between the plurality and other pairwise and/or positional procedures. The approach then is used to cast doubt on an often-cited plurality vote property.
index1057!@#@!1982!@#@!Simulation 3-dimensionaler physikalischer Prozesse?!@#@!Simulationstechnik, 1. Symposium Simulationstechnik!@#@!null
index1058!@#@!2003!@#@!Performance of intelligent systems governed by internally generated goals!@#@!Computational models for neuroscience: human cortical information processing!@#@!Intelligent behavior is characterized by flexible and creative pursuit of endogenously defined goals. It has emerged in humans through the stages of evolution that are manifested in the brains and behaviors of other vertebrates. Perception is a key concept by which to link brain dynamics to goal-directed behavior. This archetypal form of intentional behavior is an act of observation into time and space, by which information is sought to guide future action, and by which the perceiver modifies itself through learning from the sensory consequences of its own actions. Chaotic brain dynamics creates the goals, expresses them by means of behavioral actions, and defines the meaning of the requested information. These acts include the making of representations (e.g. numbers, words, graphs, sounds, gestures) for communication to other brains in validation and coordination of experience. The failure of artificial intelligence to achieve its stated aims can be attributed to taking too literally these man-made descriptive representations as the tokens of brain action, whereas in brains there is no information, only dynamic flows and operators.
index1059!@#@!1998!@#@!Index of Authors!@#@!Proceedings of the International Conference on Configurable Distributed Systems!@#@!null
index1060!@#@!1992!@#@!ProPre A Programming Language with Proofs!@#@!Proceedings of the International Conference on Logic Programming and Automated Reasoning!@#@!null
index1061!@#@!2002!@#@!A fuzzy logic controller for traffic junction signals!@#@!Information Sciences&mdash;Informatics and Computer Science: An International Journal!@#@!In this paper a fuzzy logic based traffic junction signal controller (FTJSC) is presented. In order to design a more practical controller, we simulated an environment that meets the traffic situations more than ever. This environment is generalized by considering the number of consecutive junctions, the number of lanes, the lengths of vehicles, and the lengths of streets. Compared with existing studies, the proposed fuzzy controller has the following characteristics: different input variables, lower inference frequency, fewer control rules (9 rules), and correlating each junction with others. It is applicable to multiple junctions and multiple lanes without any modification. The experimental results with low, medium and high traffic loads confirm the performance of the proposed FTJSC.
index1062!@#@!2000!@#@!Fast Progressive Image Coding without Wavelets!@#@!Proceedings of the Conference on Data Compression!@#@!We introduce a new image compression algorithm that allows progressive image reconstruction - both in resolution and in fidelity, with a fully embedded bitstream. The algorithm is based on bit-plane entropy coding of reordered transform coefficients, similar to the progressive wavelet codec (PWC) previously introduced.Unlike PWC, however, our new progressive transform coder (PTC) does not use wavelets; it performs the space-frequency decomposition step via a new lapped biorthogonal transform (LBT). PTC achieves a rate vs. distortion performance that is comparable (within 2%) to that of the state-of-the-art SPIHT (set partitioning in hierarchical trees) codec.However, thanks to the use of the LBT, the space-frequency decomposition step in PTC reduces the number of multiplications per pixel by a factor of 2.7, and the number of additions by about 15%, when compared to the fastest possible implementation of the ¿9/7¿ wavelet transform via lifting. Furthermore, since most of the computation in the LBT is in fact performed by a DCT, our PTC codec can make full use of fast software and hardware modules for 1-D and 2-D DCTs.
index1063!@#@!1996!@#@!Evolutionary Learning Algorithm for Projection Neural Networks!@#@!Selected papers from the First Asia-Pacific Conference on Simulated Evolution and Learning!@#@!null
index1064!@#@!1996!@#@!Data flow transformations to detect results which are corrupted by hardware faults!@#@!Proceedings of the 1996 High-Assurance Systems Engineering Workshop!@#@!Design diversity, which is generally used to detect software faults, can be used to detect hardware faults without any additional measures. Since design of diverse programs may use hardware parts in the same way, the hardware fault coverage obtained is insufficient. To improve hardware fault coverage, a method is presented that systematically transforms every instruction of a given program into a modified instruction (sequence), keeping the algorithm fixed. This transformation is based on a diverse data representation and accompanying modified instruction sequences, that calculate the original results in the diverse data representation. If original and systematically modified variants of a program are executed sequentially, the results can be compared online to detect hardware faults. For this method, different diverse data representation have been examined. For the most suitable representation, the accompanying modified instruction sequences have been generated at assembler level and at high language level. The theoretically estimated improvement of the fault coverage of design diversity by additionally using systematically generated diversity have been confirmed by practical examinations.
index1065!@#@!1997!@#@!A Practical Integration of First-Order Reasoning and Decision Procedures!@#@!Proceedings of the 14th International Conference on Automated Deduction!@#@!null
index1066!@#@!2000!@#@!Group Updates for Red-Black Trees!@#@!Proceedings of the 4th Italian Conference on Algorithms and Complexity!@#@!null
index1067!@#@!1993!@#@!The Application of Digital Image Processing in the Evaluation of Agricultural Experiments!@#@!Proceedings of the 5th International Conference on Computer Analysis of Images and Patterns!@#@!null
index1068!@#@!1999!@#@!Hybrid Data/Configuration Caching for Striped FPGAs!@#@!Proceedings of the Seventh Annual IEEE Symposium on Field-Programmable Custom Computing Machines!@#@!In recent years, interest in the area of custom computing machines (CCMs) has been on a steady increase. Much of the activity surrounding CCMs has centered around Field-Programmable Gate Array (FPGA) technology and rapid prototyping applications. For supporting applications, FPGAs are reconfigured to allow pieces of the application to be mapped on it temporally. The performance of the FPGA when used as virtual hardware engine depends on its reconfiguration granularity. We study the striped FPGA, and propose a hybrid mechanism to process a large amount of data using a combination of data and configuration caching. We also present our analysis, quantifying total execution time and I/O overhead presented by the scheme to determine its applicability domain.
index1069!@#@!1999!@#@!Security Architecture Development and Results for a Distributed Modeling and Simulation System!@#@!Proceedings of the 15th Annual Computer Security Applications Conference!@#@!This paper reports on an ongoing effort to define the security architecture for the Joint Simulation System (JSIMS), a joint military modeling and simulation system. It also describes the use of the security architecture to support the accreditation of the system.The JSIMS security architecture must coordinate not only enclaves at different classifications, but also the independent configurations of the multiple stakeholders. These include the various military branches and their separate designated approving authorities.It has therefore been necessary to develop the security architecture with sufficient breadth and flexibility to describe a variety of JSIMS instantiations, allowing an integrated accreditation by the multiple authorities without necessitating entirely independent accreditations. We have addressed the objective of flexibility by establishing a base, logical architecture along with customized versions of the architecture to meet the joint security objectives.
index1070!@#@!1996!@#@!Model-integrated toolset for fault detection, isolation and recovery (FDIR)!@#@!Proceedings of the IEEE Symposium and Workshop on Engineering of Computer Based Systems!@#@!Fault detection, isolation and recovery (FDIR) functions are essential components of complex engineering systems. The design, validation, implementation, deployment and maintenance of FDIR systems are extremely information intensive tests requiring in-depth knowledge of the engineering system. The paper gives an overview of a model-integrated toolset supporting FDIR from design, into post deployment. The toolset is used for development of large, complex spacecraft systems during the engineering design phase.
index1071!@#@!1982!@#@!Modeling X.25 Using the Graph Model of Behavior!@#@!Proceedings of the IFIP WG6.1 Second International Workshop on Protocol Specification, Testing and Verification!@#@!null
index1072!@#@!2001!@#@!Designing Fast Asynchronous Circuits!@#@!ASYNC!@#@!A five-step design process for asynchronous circuits helps simplify their logic and speed their operation. First, assume that all logic gates in the control will have nearly uniform delay. Second, use the uniform delay assumption to simplify control logic. Third, lay out the chip to get wire length data. Fourth, choose a specific delay and calculate transistor widths to apply that specific delay uniformly to all logic gates in the control; this paper shows how. Fifth, verify correct operation with standard methods. The specific gate delay trades off speed, area, and power consumption; postponing its choice takes advantage of asynchrony to accommodate the limitations imposed by layout. The theoretical lower bound for specific delay depends on the logical effort of the most complex loop in the design and remarkably, is independent of wire capacitance, given wide enough transistors, but wire capacitance puts practical bounds on speed. The effect of wire resistance remains unexplored.
index1073!@#@!2000!@#@!Decision Support under Imperfections in Electronic Commerce!@#@!Proceedings of the 11th International Workshop on Database and Expert Systems Applications!@#@!The selection of products and services is a central issue in electronic commerce. Available data is often not sufficient to allow a precise evaluation and user preferences are usually vague. In this paper, a model for deciding under imperfect information is presented. The decision model handles two types of imperfections: imprecisions on the side of the alternatives and vagueness in the preferences of the users. Incomplete description of the alternatives may result in imprecisions in the evaluation of their features. The decision model provides a framework to reduce these imprecisions by completing information from external sources. Besides, fuzzy query conditions allow users to express vague preferences. A scenario illustrates the use of the decision model where the goal is to select a rental apartment from classified advertisements with respect to its availability by public transport.
index1074!@#@!2003!@#@!Hot on the trail of an e-learning career!@#@!eLearn!@#@!null
index1075!@#@!2003!@#@!All things UML!@#@!Software Visualization!@#@!null
index1076!@#@!1998!@#@!An Algorithm for Three-Dimensional Orthogonal Graph Drawing!@#@!Proceedings of the 6th International Symposium on Graph Drawing!@#@!null
index1077!@#@!1995!@#@!Automatic test vector generation for mixed-signal circuits!@#@!Proceedings of the 1995 European conference on Design and Test!@#@!Mixed circuit testing is known to be a very difficult task. This is due to the difficulty of: testing the analog part of the circuit, controlling the digital signal from the analog outputs, observing the analog outputs in the digital circuit, controlling the analog circuit from the digital outputs and observing the digital signals in the analog circuit. As a solution to these problems, we propose an automatic test vector generation for mixed circuits to perform functional testing. In this paper, a case of an analog block followed by a digital block is considered. The experimental results (simulation and discrete realization) show the efficiency of the automatic test generation technique.
index1078!@#@!2003!@#@!Guest Editors' Introduction: On-Chip Power Distribution Networks!@#@!IEEE Design &amp; Test!@#@!null
index1079!@#@!1998!@#@!Calculus in Coinductive Form!@#@!Proceedings of the 13th Annual IEEE Symposium on Logic in Computer Science!@#@!null
index1080!@#@!1996!@#@!Application of Artificial Neural Networks in Particle Physics!@#@!Proceedings of the 1996 International Conference on Artificial Neural Networks!@#@!null
index1081!@#@!2003!@#@!Foreword!@#@!Theoretical Computer Science!@#@!null
index1082!@#@!1999!@#@!An Effective Methodology for Mixed Scan and Reset Design Based on Test Generation and Structure of Sequential Circuits!@#@!Proceedings of the 8th Asian Test Symposium!@#@!In this paper, a flip-flop selection methodology, which utilizes reachable states of flip-flops, required states for hard-to-detect faults, which are obtained from test generation, and the structural connection relationship of flip-flops, to achieve a nearly optimal mixed partial-scan/reset design, is proposed. The methodology first generates and simulates test patterns for the circuit-under-test to obtain information of reachable states and states needed for excitation and propagation of hard-to-detect faults. It then searches the connection relationship among flip-flops and arranges flip-flops in an appropriate order for mixed partial scan and reset selection. Experimental results show that the method achieves higher testability than reported methods with less number of scan/reset flip-flops.
index1083!@#@!2002!@#@!Determinantal formula for the chow form of a toric surface!@#@!Proceedings of the 2002 international symposium on Symbolic and algebraic computation!@#@!This paper gives an explicit method for computing the resultant of any sparse unmixed bivariate system with given support. We construct square matrices whose determinant is exactly the resultant. The matrices constructed are of hybrid Sylvester and B&eacute;zout type. Previous work by D'Andrea [6] gave pure Sylvester type matrices (in any dimension). In the bivariate case, D'Andrea and Emiris [8] constructed hybrid matrices with one B&eacute;zout row. These matrices are only guaranteed to have determinant some multiple of the resultant. The main contribution of this paper is the addition of new B&eacute;zout terms allowing us to achieve exact formulas. We make use of the exterior algebra techniques of Eisenbud, Fl&oslash;ystad, and Schreyer [10, 9].
index1084!@#@!1993!@#@!Robot Mapping: Foot-Prints versus Tokens!@#@!Proceedings of the 4th International Symposium on Algorithms and Computation!@#@!null
index1085!@#@!2003!@#@!Editorial: internet-mediated simulation and gamming; SAGSAGA; thanks!@#@!Simulation and Gaming!@#@!null
index1086!@#@!2003!@#@!vGPRS: a mechanism for voice over GPRS!@#@!Wireless Networks!@#@!This paper proposes vGPRS, a voice over IP (VoIP) mechanism for general packet radio service (GPRS) network. In this approach, a new network element called VoIP mobile switching center (VMSC) is introduced to replace standard GSM MSC. Both standard GSM and GPRS mobile stations can be used to receive real-time VoIP service, which need not be equipped with the VoIP (i.e., H.323) terminal capabilities. The vGPRS approach is implemented using standard H.323, GPRS, and GSM protocols. Thus, existing GPRS and H.323 network elements are not modified. Furthermore, the message flows for vGPRS registration, call origination, call release and call termination procedures are described to show the feasibility of our vGPRS system.
index1087!@#@!2002!@#@!System Description: The MathWeb Software Bus for Distributed Mathematical Reasoning!@#@!Proceedings of the 18th International Conference on Automated Deduction!@#@!null
index1088!@#@!2002!@#@!Coup De Fouet Based VRLA Battery Capacity Estimation!@#@!DELTA!@#@!The most important battery state of health (SOH) parameter is capacity. Capacity, the energy storage capability of a battery, is difficult to measure for the valve regulated lead acid (VRLA) battery. One of the most reliable approaches involves fully discharging the battery. However, this leaves the telecommunication system vulnerable to mains failure, is expensive and time consuming. Recently the authors have discovered a correlation between battery capacity and parameters found within the voltage profile during the initial stages of discharge. This region is known as the coup de fouet. This paper presents the issues relating to the construction of a model for extracting battery capacity knowledge from the coup de fouet. Results obtained so far indicate that this approach will form the basis of an intelligent battery management system.
index1089!@#@!1998!@#@!Dynamic Models of Human Motion!@#@!Proceedings of the 3rd. International Conference on Face & Gesture Recognition!@#@!null
index1090!@#@!1998!@#@!Pattern Matching for Spatial Point Sets!@#@!Proceedings of the 39th Annual Symposium on Foundations of Computer Science!@#@!Two sets of points in $d$-dimensional space are given: a {\it data set\/} $D$ consisting of $N$ points, and a {\it pattern set\/} or {\it probe\/} $P$ consisting of $k$ points. We address the problem of determining whether there is a transformation, among a specified group of transformations of the space, carrying $P$ into or near (meaning at a small directed Hausdorff distance of) $D$. The groups we consider are translations and rigid motions. Runtimes of approximately $O(n \log n)$ and $O(n^d \log n)$ respectively are obtained (letting $n=\max\{N,k\}$ and omitting the effects of several secondary parameters). For translations, a runtime of approximately $O(n(ak+1)\log^2 n)$ is obtained for the case that a constant fraction $a
index1091!@#@!2003!@#@!An Introduction of Compression Algorithms into SSL/TLS and Proposal of Compression Algorithms Specialized for Application!@#@!Proceedings of the 17th International Conference on Advanced Information Networking and Applications!@#@!The specification of SSL/TLS defines that data from the upper layer can be compressed in the record layer before they are encrypted. Since only the no-compression is provided for the compression algorithm in the specification, nobody can compress transmission data at the SSL/TLS protocols unless communication peers have a special agreement to use a compression algorithm. However, the compression mechanism should be useful for the users of narrower bandwidth communication lines such as the ordinary analog telephone lines and N-ISDN.In order to solve this problem, this paper first introduces general-purpose compression algorithms into SSL/TLS, and shows that the average transfer times for several Japanesetext files via HTTP are much improved especially for narrow bandwidth communication lines. We also compare with the compression mechanism on HTTP, and result the difference between the results of the SSL/TLS compression and HTTP compression is rather little.For improving the compression ratio, we next propose compression algorithms specialized for application protocols. As examples, we focus to HTTP and HTML, and construct the tree structures of the field names and field values. From the tree, the static dictionaries for the compression algorithms are defined. Finally, we implement the compression algorithms and show the compression ratios when the several HTML files are transfered.
index1092!@#@!2003!@#@!Utilizing a computing lab to improve retention and recruiting of computer science and computer information science students!@#@!Journal of Computing Sciences in Colleges!@#@!A computer lab specific for Computer Science/Computer Information Science (CS/CIS) majors has many benefits in recruiting and retaining students for these disciplines and provides additional educational benefits both in the class and for extra curricular activities for both students and faculty. The lab may be used for recruiting new students by providing an impressive facility for prospective students and by utilizing it for workshops offered to high school students in computer related subjects that are not typically offered on local high school campuses. For college students, the lab would promote student interaction and enhance learning by providing an environment conducive for research and experimentation in computer science. Placing this lab under the supervision of the CS/CIS department provides benefits for faculty, including faster response to new software installation and problems, and opportunities for faculty to take advantage of the lab for special course requirements such as loading a special operating system in the Operating Systems course. Hiring student workers for system administration also aids in teaching students the responsibility of interacting with customers (faculty in this case) and the need for responsiveness to customer requests.
index1093!@#@!2000!@#@!Human Motion Planning Based on Recursive Dynamics and Optimal Control Techniques!@#@!Proceedings of the International Conference on Computer Graphics!@#@!The 3D simulation of human activity based on physics, kinematics, and dynamics in terrestrial and space environments, is becoming increasingly important in robotics, computer graphics, biomechanics, and virtual reality. Virtual humans may be used to design tasks in terrestrial environments and analyze their physical workload to maximize success and safety without expensive physical mockups (e.g. partially realistic neutral-buoyancy tanks for space activity analyzing). In our previous paper {Lo3}, we presented an efficient optimal control and recursive dynamics based animation system for simulating and controlling the motion of articulated figures, and implemented the approach to several experiments where the simplified articulated models which has a serial/closed-loop chain structures with only small degree-of-freedom (less than seven) each. The computation time is from a few minutes up to 4 hours based on the complexity of the model and how close is the initial guess of the motion trajectory to the optimal solution. This paper presents an improved method, which can deal with more complicated kinematic chains --tree-structures -- as well as larger degree-of-freedom serial/closed-loop chain structures. Motion planning is done by first solving the inverse kinematic problem to generate possible trajectories, which gives us a better initial guess of the motion trajectory than the previous one, and then by solving the resulting nonlinear optimal control problem. For example, minimization of the torques during a simulation under certain constraints is often applied and has its origin in the biomechanics literature. Examples of activities shown are chinup and dipdown in different terrestrial environments as well as zero gravity self-orientation and ladder traversal.
index1094!@#@!1999!@#@!A Hierarchical Neural Object Classifier for Subsymbolic-Symbolic Coupling!@#@!Mustererkennung 1999, 21. DAGM-Symposium!@#@!null
index1095!@#@!2000!@#@!Hand Gesture Animation from Static Postures Using an Anatomy-Based Model!@#@!Proceedings of the International Conference on Computer Graphics!@#@!Automatic interpretation and animation of human motion has become an important research topic among researchers in virtual reality and computer animation. One major problem encountered during hand motion analysis is the huge amount of data that need to be captured and analyzed. Even for human hand, though a small part of our body involved about 30 motion parameters for each hand posture. In this paper, we present our approach for hand motion animation using only the static images of the set of target gestures. We achieve naturalistic hand motion animation by the use of an anatomy-based hand model and a hand gesture coding system, which we called Hand Action Coding System (HACS). This allows complex sequence of hand gestures to be animated based only on the static image of the hand gestures to be animated. This approach greatly simplifies the motion data acquisition and the process of motion analysis and synthesis.
index1096!@#@!2002!@#@!One Small Step for a Diagram, One Giant Leap for Meaning!@#@!Proceedings of the Second International Conference on Diagrammatic Representation and Inference!@#@!null
index1097!@#@!1997!@#@!The Hierarchical Multi-Bank DRAM: A High-Performance Architecture for Memory Integrated with Processors!@#@!ARVLSI!@#@!A microprocessor integrated with DRAM on the same die has the potential to improve system performance by reducing the memory latency and improving the memory bandwidth. However, a high performance microprocessor will typically send more accesses than the DRAM can handle due to the long cycle time of the embedded DRAM, especially in applications with significant memory requirements. A multi-bank DRAM can hide the long cycle time by allowing the DRAM to process multiple accesses in parallel, but it will incur a significant area penalty and will therefore restrict the density of the embedded DRAM main memory. In this paper, we propose a hierarchical multi-bank DRAM architecture to achieve high system performance with a minimal area penalty. In this architecture, the independent memory banks are each divided into many semi-independent subbanks that share I/O and decoder resources. A hierarchical multi-bank DRAM with 4 main banks each composed of 32 subbanks occupies approximately the same area as a conventional 4 bank DRAM while performing like a 32 bank one - up to 65% better than a conventional 4 bank DRAM when integrated with a single-chip multiprocessor.
index1098!@#@!2002!@#@!On the Tail of the Waiting Time in a Markov-Modulated M/G/1 Queue!@#@!Operations Research!@#@!We show that the "exponential decay parameter" of the waiting time in a Markov-modulatedM/G/1 queue is no larger than that of the correspondingM/G/1 queue with "averaged" parameters, and we give a necessary and sufficient condition for equality. We also explore the effect of speeding up the modulation process. A key tool is a Markov-modulated fluid model.
index1099!@#@!2003!@#@!Patterns, frameworks, and middleware: their synergistic relationships!@#@!International Conference on Software Engineering!@#@!The knowledge required to develop complex software has historically existed in programming folklore, the heads of experienced developers, or buried deep in the code. These locations are not ideal since the effort required to capture and evolve this knowledge is expensive, time-consuming, and error-prone. Many popular software modeling methods and tools address certain aspects of these problems by documenting how a system is designed. However, they only support limited portions of software development and do not articulate why a system is designed in a particular way, which complicates subsequent software reuse and evolution.Patterns, frameworks, and middleware are increasingly popular techniques for addressing key aspects of the challenges outlined above. Patterns codify reusable design expertise that provides time-proven solutions to commonly occurring software problems that arise in particular contexts and domains. Frameworks provide both a reusable product-line architecture [1] guided by patterns -- for a family of related applications and an integrated set of collaborating components that implement concrete realizations of the architecture. Middleware is reusable software that leverages patterns and frameworks to bridge the gap between the functional requirements of applications and the underlying operating systems, network protocol stacks, and databases. This paper presents an overview of patterns, frameworks, and middleware, describes how these technologies complement each other to enhance reuse and productivity, and then illustrates how they have been applied successfully in practice to improve the reusability and quality of complex software systems.
index1100!@#@!2003!@#@!Preface: a framework for the study of mobile commerce!@#@!Mobile commerce: technology, theory, and applications!@#@!null
index1101!@#@!2003!@#@!Analysis methods of CT-scan images for the characterization of the bone texture: first results!@#@!Pattern Recognition Letters!@#@!The ultimate objective of the planned work is to propose a way to the characterization of the bone texture from the analysis of CT-scan images. This would assist the discrimination of healthy from pathological subjects. This paper emphasizes a preliminary study concerning the selection of tools for the characterization of the bone texture. The selectivity is lead by the analysis of respective sensitivities of the considered methods. We study here two methods of texture analysis. The first one is based on the fractal geometry whose application to the analysis of texture is well established in literature. The second method is an original one. It is called the "method of the three dimensional relief".
index1102!@#@!1997!@#@!Symposium Organization and Organizing Committee!@#@!Proceedings of the 1997 IEEE International Symposium on Computational Intelligence in Robotics and Automation!@#@!null
index1103!@#@!2003!@#@!Worst case mobility in ad hoc networks!@#@!ACM Symposium on Parallel Algorithms and Architectures!@#@!We investigate distributed algorithms for mobile ad hoc networks for moving radio stations with adjustable transmission power in a worst case scenario. We consider two models to find a reasonable restriction on the worst-case mobility. In the pedestrian model we assume a maximum speed vmax of the radio stations, while in the vehicular model we assume a maximum acceleration amax of the points.Our goal is to maintain persistent routes with nice communication network properties like hop distance, energy-consumption, congestion and number of interferences. A route is persistent, if we can guarantee that all edges of this route can be uphold for a given time span Δ, which is a parameter denoting the minimum time the mobile network needs to adopt changes, i.e. update routing tables, change directory entries, etc. This Δ can be used as the length of an update interval for a proactive routing scheme.We extend some known notions such as transmission range, interferences, spanner, power spanner and congestion to both mobility models and introduce a new parameter called crowdedness that states a lower bound on the number of radio interferences. Then we prove that a mobile spanner hosts a path system that polylogarithmically approximates the optimal congestion.We present distributed algorithms based on a grid clustering technique and a high-dimensional representation of the dynamical start situation which construct mobile spanners with low congestion, low interference number, low energy-consumption, and low degree. We measure the optimality of the output of our algorithm by comparing it with the optimal choice of persistent routes under the same circumstances with respect to pedestrian or vehicular worst-case movements. Finally, we present solutions for dynamic position information management under our mobility models.
index1104!@#@!1998!@#@!Monadic Logic and Automata: Recent Developments!@#@!Proceedings of the 13th Annual IEEE Symposium on Logic in Computer Science!@#@!null
index1105!@#@!2002!@#@!Dynamic agent population in agent-based distance vector routing!@#@!Second international workshop on Intelligent systems design and application!@#@!The Intelligent Mobile Agent paradigm can be applied to a wide variety of intrinsically parallel and distributed applications. Network routing is one such application that can be mapped to an agent-based approach. The performance of any agent-based system will depend on its agent population. Although a significant amount of research has been conducted on mobile agent-based systems, little consideration has been given to the importance of agent population in dynamic networks. A large number of constituent agents can consume considerable amounts of network resources, thereby impeding the overall performance of the network. Hence, it is imperative to have a control mechanism whereby the agent population can be adjusted in a distributed manner to balance the resource overhead in the network. This paper briefly discusses an agent-based approach to Distance Vector Routing, referred as Agent-based Distance Vector Routing. It also describes a framework for an adaptive approach to control the number of agents in the network using pheromones and discusses its limitations.
index1106!@#@!1997!@#@!A New Approach to Realizing Fault-Tolerant Multiprocessor Scheduling by Exploiting Implicit Redundancy!@#@!FTCS!@#@!In this paper we propose a new approach to fault-tolerant multiprocessor scheduling by exploiting implicit redundancy, which is originally introduced by task duplication. In the new scheduling algorithm, we adopt two strategies: (1)Some processing elements (PEs) are reserved only for realizing fault-tolerance, and thus are not used for original task scheduling (reserved-scheduling). (2)A set of tasks is partitioned into several disjoint small subsets, and to each subset the algorithm is applied incrementally(phased-scheduling). By this unique device, we can ensure that the finish times of schedules are small even in the case of a single PE failure. Then we apply the new scheduling algorithm to practical task graphs (LU-decomposition and Laplace equation solver). The experimental results show that the obtained schedules can tolerate a single PE failure at the cost of small degree of time redundancy.
index1107!@#@!1998!@#@!Heterogeneous Parallel Computing With Java: Jabber Or Justified?!@#@!Proceedings of the Seventh Heterogeneous Computing Workshop!@#@!Is Java a good language for programming heterogeneous parallel computing systems? It is a well-designed modern language that, combined with the Java Virtual Machine (JVM), offers a myriad of modern programming features and excellent portability. However, in speedup-oriented heterogeneous computing, our primary concern is obtaining the best possible execution speed from the heterogeneous system. This paper briefly discusses what heterogeneous parallel computing is really about, lists some of the key features of Java, and finally summarizes how well Java matches the task of programming for heterogeneous parallel computing.
index1108!@#@!2002!@#@!An Intelligent Medical System for Mocrobiological Data Validation and Nosocomial Infection Surveillance!@#@!CBMS!@#@!We describe a knowledge based system for microbiological laboratory data validation and bacteria infections monitoring. The knowledge base has been obtained from international standard guidelines for microbiological laboratory practice, from experts' suggestions and from data mining. In this work, we evaluate the system in terms of accuracy on a test dataset.
index1109!@#@!2001!@#@!Causal Simulation and Diagnosis of Dynamic Systems!@#@!Proceedings of the 7th Congress of the Italian Association for Artificial Intelligence on Advances in Artificial Intelligence!@#@!null
index1110!@#@!1996!@#@!Proof Search with Set Variable Instantiation in the Calculus of Constructions!@#@!Proceedings of the 13th International Conference on Automated Deduction: Automated Deduction!@#@!null
index1111!@#@!2002!@#@!Letter to the editor: libraries flooded in the Czech Republic: please help!!@#@!Information Services and Use!@#@!null
index1112!@#@!1996!@#@!Highly available directory services in DCE!@#@!FTCS!@#@!The DCE standard includes specifications for the Directory Service, a component that performs typical naming services in distributed computing environments. We list some deficiencies in these specifications that affect the naming service availability and correctness, and suggest possible solutions. We then describe an enhancement of an implementation of the Directory Service that adds support for partial replication of the name space, continuous operation of the service, and automatic fallover. Our extensions ensure the consistency of the name space data, and are transparent to application developers and end users, all without a significant performance penalty.
index1113!@#@!1979!@#@!Zur Detektion von Relativbewegungen in bewegten nat&uuml;rlichen Szenen!@#@!Angewandte Szenenanalyse, DAGM Symposium!@#@!null
index1114!@#@!2002!@#@!MDM/KDD2002: multimedia data mining between promises and problems!@#@!ACM SIGKDD Explorations Newsletter!@#@!This report presents a brief overview of multimedia data mining and the corresponding workshop series at ACM SIGKDD conference series on data mining and knowledge discovery. It summarizes the presentations, conclusions and directions for future work that were discussed during the 3rd edition of the International Workshop on Multimedia Data Mining, conducted in conjunction with KDD-2002 in Edmonton, Alberta, Canada.
index1115!@#@!2002!@#@!Statistical tools to assess the reliability of self-organizing maps!@#@!Neural Networks!@#@!Results of neural network learning are always subject to some variability, due to the sensitivity to initial conditions, to convergence to local minima, and, sometimes more dramatically, to sampling variability. This paper presents a set of tools designed to assess the reliability of the results of self-organizing maps (SOM), i.e. to test on a statistical basis the confidence we can have on the result of a specific SOM. The tools concern the quantization error in a SOM, and the neighborhood relations (both at the level of a specific pair of observations and globally on the map). As a by-product, these measures also allow to assess the adequacy of the number of units chosen in a map. The tools may also be used to measure objectively how the SOM are less sensitive to non-linear optimization problems (local minima, convergence, etc.) than other neural network models.
index1116!@#@!1998!@#@!A Stability Theorem in Rewriting Theory!@#@!Proceedings of the 13th Annual IEEE Symposium on Logic in Computer Science!@#@!null
index1117!@#@!1997!@#@!Committees!@#@!ARITH!@#@!null
index1118!@#@!2003!@#@!Security in mobile computing environments!@#@!Mobile Networks and Applications!@#@!null
index1119!@#@!1999!@#@!New models for the management of public key infrastructure and root certification authorities!@#@!Proceedings of the IFIP TC11 WG11.1/WG11.2 Seventh Annual Working Conference on Information Security Management &amp; Small Systems Security!@#@!null
index1120!@#@!1997!@#@!Discrete-Time Rigidity-Constrained Optical Flow!@#@!Proceedings of the 7th International Conference on Computer Analysis of Images and Patterns!@#@!null
index1121!@#@!1986!@#@!Verstehen von Landkarten!@#@!Mustererkennung 1986, 8. DAGM-Symposium!@#@!null
index1122!@#@!1996!@#@!Process Partitioning for Distributed Embedded Systems!@#@!Proceedings of the 4th International Workshop on Hardware/Software Co-Design!@#@!We present a new technique for partitioning processes in distributed embedded systems. Our heuristic algorithm minimizes both context switch and communication overhead under real-time deadline and process size constraints; it also tries to allocate functions to processors which are well-suited to that function. The algorithm analyzes the sensitivity of the latency of the task graph to changes in vertices hierarchical clustering, splitting and border adjusting. This algorithm can be used for initial partitioning during co-synthesis of distributed embedded systems. Synthesis of examples partitioned by our algorithm with implementations synthesized directly from the original example shows that our partitioning algorithm significantly improves the results obtainable by practical co-synthesis algorithms.
index1123!@#@!2002!@#@!Value webs: cases, features, and success factors!@#@!Managing virtual web organizations in the 21st century: issues and challenges!@#@!The new information infrastructure redefines the roles and relationships between buyer, seller, and middleman, allowing new ways of accessing and tapping information and price arrangements. Most importantly information about a product or service may be separated from the product or service itself. The chapter scrutinizes how companies are using these opportunities to establish networked retail businesses and generate customer value in innovative ways. We have tried to reconstruct a widespread interorganizational arrangement for product and service retailing on the Web, its antecedents, its challenges and its economic logic.
index1124!@#@!1994!@#@!An object oriented testing and maintenance environment!@#@!Proceedings of the 1994 conference of the Centre for Advanced Studies on Collaborative research!@#@!The object-oriented (OO) paradigm enjoys increasing acceptance in the software industry. Although the OO paradigm has visible benefits in the development cycle, testing and maintenance of OO programs have been considered challenging tasks by the research community. In this paper, we describe an OO testing and maintenance model and present a supporting CASE environment. The model consists of three types of diagrams: the Object Relation Diagram (ORD), Block Branch Diagram (BBD), and Object State Diagram (OSD). An ORD depicts the inheritance, aggregation, and association relationships between the classes of an OO program, a BBD presents the control flow graph of a function/method and its interfaces to other parts of the OO program, and an OSD displays the state-dependent behavior of a class in terms of a hierarchy of state transition diagrams. These diagrams are extracted from code using a reverse engineering approach and facilitate the understanding, test preparation, and maintenance of OO programs. Based on the model, a CASE environment, called OOTME, has been developed to support object-oriented testing and maintenance in aspects of test strategy generation, test case/data generation, code change, and impact identification. In addition, the application of OOTME to the InterViews library is presented.A software demonstration will be provided at the conference site.
index1125!@#@!2002!@#@!Augmented Lagrangians with Adaptive Precision Control for Quadratic Programming with Simple Bounds and Equality Constraints!@#@!SIAM Journal on Optimization!@#@!In this paper we discuss a specialization of the augmented Lagrangian-type algorithm of Conn, Gould, and Toint to the solution of strictly convex quadratic programming problems with simple bounds and equality constraints. The new feature of the presented algorithm is the adaptive precision control of the solution of auxiliary problems in the inner loop of the basic algorithm which yields a rate of convergence that does not have any term that accounts for inexact solution of auxiliary problems. Moreover, boundedness of the penalty parameter is achieved for the precision control used. Numerical experiments illustrate the efficiency of the presented algorithm and encourage its usage.
index1126!@#@!2002!@#@!Using reinforcement learning to introduce artificial intelligence in the CS curriculum!@#@!Journal of Computing Sciences in Colleges!@#@!There are many interesting topics in artificial intelligence that would be useful to stimulate student interest at various levels of the computer science curriculum. They can also be used to illustrate some basic concepts of computer science, such as arrays. One such topic is reinforcement learning - teaching a computer program how to play a game or traverse an environment using a system of rewards and punishments. There are reinforcement learning projects that can be used at all levels of the computer science curriculum. This paper describes a few examples of reinforcement learning and how they might be used.
index1127!@#@!1981!@#@!Abstract Data Types and Rewriting Systems: Application to the Programming of Algebraic Abstract Data Types in Prolog!@#@!Proceedings of the 6th Colloquium on Trees in Algebra and Programming!@#@!null
index1128!@#@!1996!@#@!BIST Testability Enhancement of System Level Circuits: Experience with An Industrial Design!@#@!Proceedings of the 5th Asian Test Symposium!@#@!A systematic methodology for testability analysis and enhancement of sequential circuit designs using Built-In Self-Test (BIST) is described. Inter-modular test insertions is applied to improve controllability as well as observability in a system level circuit. Circuit partitioning based on functionality has been applied to reduce the computation complexity. The technique is demonstrated on several industrial design circuits for the fax applications. Results show how inter-modular test insertion to enhance testability, guided by testability analysis technique, produce significantly better fault coverage than its original test plan with functional test alone for these industrial circuits. In order to obtain a high fault coverage, functional test, random test and sequential ATPG test have been utilized. We also do test pattern compaction to obtain the minimum size of test pattern. Moreover, very low hardware overhead has been achieved. This methodology has been successfully applied to test system level circuits consisting of sequential circuit modules to do post-design re-synthesis improving overall testability. This methodology has achieved 98% and 99% fault coverage level for several different types of system level circuits from industry.
index1129!@#@!1988!@#@!Web-Based Virtual Classrooms Supported by Dynamic Group Building Mechanisms!@#@!Interaktion im Web - Innovative Kommunikationsformen, Fachtagung und Kongre&szlig; des German Chapter of the ACM, der Gesellschaft f&uuml;r Informatik (GI) sowie Fachbereich Mathematik und Informatik der Philipps-Universit&auml;t Marburg/Lahn am!@#@!null
index1130!@#@!1979!@#@!Automatisierte Verarbeitung holografischer Interferenzmuster!@#@!Angewandte Szenenanalyse, DAGM Symposium!@#@!null
index1131!@#@!2002!@#@!GeoWorlds: integrating GIS and digital libraries for situation understanding and management!@#@!The New Review of Hypermedia and Multimedia!@#@!Helping organizations to marshal, analyze, discuss, and act on all of the available information about a situation playing out over space and time is a critical problem. GeoWorlds (http://www.isi.edu/geoworlds) is a component-based information management system that addresses this issue. It brings together information analysis, retrieval and collaboration tools and integrates digital library, geographic information systems (GIS), and remote sensor data management technologies. It provides three key services: 1) rapidly assembling a custom repository of geographic information about a region, 2) bi-directionally linking it to collections of document-based information from the World-Wide Web, and 3) monitoring real-time sensor data for information that might change conclusions or decisions formed on the basis of this rich information set. GeoWorlds framework enables synchronous and asynchronous collaboration over finding, filtering, organizing and visualizing the needed information.
index1132!@#@!1995!@#@!Reliability analysis of CSP specifications using Petri nets and Markov processes!@#@!Proceedings of the 28th Hawaii International Conference on System Sciences!@#@!In our research we are developing methodologies and tools to permit stochastic analyses of CSP-based system specifications. In this regard, we have been developing morphisms between CSP-based models and Petri net-based stochastic models. This process has given us insight for further refinements to the original CSP specifications (i.e., identify potential failure processes and recovery actions). In order to create systems that meet user needs in terms of cost, functionality, performance and reliability, it is essential to relate the parameters needed for reliability analysis to the user level specification.
index1133!@#@!1996!@#@!Inference of segmented, volumetric shape from three intensity images!@#@!CVPR!@#@!We present a method to infer segmented and full volumetric descriptions of objects from intensity images. We use three weakly calibrated images from closely spaced viewpoints as input. Deriving full volumetric descriptions requires the development of robust inference rules. The inference rules are based on local properties of generalized cylinders (GCs). We first detect groups in each image based on proximity, parallelism and symmetry. The groups in the three images are matched and their contours are labelled as "true" and "limb" edges. We use the information about groups and the label associated with their contours to recover visible surfaces and their surface axes. To extract the complete volume in terms of a GC, we need to infer the GC axis, its cross section and the scaling function. The properties of straight and curved axis generalized cylinders are used locally on the visible surfaces to obtain the GC axis. The cross section is recovered if seen in the images, else it is inferred using the visible surfaces and GC properties. We consider groups with true edges, limb edges or a combination of both. The final descriptions are volumetric and in terms of parts. Sometimes, when not enough information is present to make volumetric inferences, the descriptions remain at the surface level. We demonstrate results on real images of moderately complex objects with texture and shadows.
index1134!@#@!1998!@#@!Implementing Process Enactment within a Process-Centred Software Development Environment!@#@!Proceedings of the Australian Software Engineering Conference!@#@!null
index1135!@#@!2001!@#@!An Evaluation of Test Generation Algorithms for Combinational Circuits!@#@!Proceedings of the 10th Anniversary Compendium of Papers from Asian Test Symposium 1992-2001!@#@!Within this era of VLSI circuits, testability is truly a verycrucid issue.To generate a test set for a given circuit,choice of an algorithm within a number of existing testgeneration algorithms to apply is bound to vary from circuitto circuit.Some objective quantitative measures are used inmaking such choice.Such measures are so important to theanalysis of algorithms that become the subject of this work.
index1136!@#@!2002!@#@!Comparing the Effectiveness of Various Bayesian X Control Charts!@#@!Operations Research!@#@!In an attempt to improve the procedures for statistical process control many researchers have developed and proposed a variety of adaptive control charts in the last decade. The common characteristic of those charts is that one or more of the chart parameters (sampling interval, sample size,control limits) is allowed to change during operation, taking into account current sample information. Due to their flexibility, adaptive charts are more effective than their static counterparts but they are also more complex in terms of implementation. The purpose of this paper is to evaluate the economic performance of various adaptive control schemes to derive conclusions about their relative effectiveness. The analysis concentrates on Bayesian control charts used for monitoring the process mean in finite production runs. We present dynamic programming formulations and properties of the optimal solutions, which we then use to solve a number of numerical examples. The results from our comparative numerical study indicate that the chart parameter having the most positive impact on the economic performance by being adaptive is the sampling interval. It is therefore sufficient in most cases to use control charts with adaptive sampling intervals rather than other types of partially adaptive charts or the more complicated fully adaptive control charts.
index1137!@#@!1998!@#@!Specification and Integration of Theorem Provers and Computer Algebra Systems!@#@!Proceedings of the International Conference on Artificial Intelligence and Symbolic Computation!@#@!null
index1138!@#@!2002!@#@!Development of a stand-alone lighting system for 70 W HPS lamps!@#@!Iranian Journal of Science and Technology!@#@!A stand-alone photovoltaic lighting system is reported in this paper. The system uses a 70 W HPS lamp with a DC bus voltage of 12 V. An efficient electronic ballast, which makes possible the use of 70 W HPS lamp in photovoltaic applications is reported. Design of the ballast is discussed. The ballast has an efficiency of more than 87 percent for the operating load range. The performance of the HPS lamp with the electronic ballast is reported and compared with passive ballast.
index1139!@#@!2001!@#@!Introduction!@#@!Revised Papers from the Second Workshop of the Cross-Language Evaluation Forum on Evaluation of Cross-Language Information Retrieval Systems!@#@!null
index1140!@#@!1992!@#@!Arithmetic + Logic + Geometry = Concurrency!@#@!Proceedings of the 1st Latin American Symposium on Theoretical Informatics!@#@!null
index1141!@#@!1998!@#@!Fast Monte-Carlo Algorithms for finding low-rank approximations!@#@!Proceedings of the 39th Annual Symposium on Foundations of Computer Science!@#@!In several applications, the data consists of an m X n matrix A and it is of interest to find an approximation $\DD$ of a specified rank k to A where, k is much smaller than m and n. Traditional methods like the Singular Value Decomposition (SVD) help us find the ``best'' such approximation. However, these methods take time polynomial in m and n which is often too prohibitive.In this paper, we develop an algorithm which is qualitatively faster, provided we may sample the entries of the matrix according to a natural probability distribution. Indeed, in the applications such sampling is possible.
index1142!@#@!1989!@#@!PICASYS - Ein Bildanalysesystem zur Identifikation von Leiterplatinen!@#@!Mustererkennung 1989, 11. DAGM-Symposium!@#@!null
index1143!@#@!2003!@#@!Introducing the 2.6 kernel!@#@!Linux Journal!@#@!From the scheduler to the device drivers, there's a lot to like and learn about the upcoming Linux 2.6.
index1144!@#@!2003!@#@!Software telegram!@#@!Computational Statistics &amp; Data Analysis!@#@!null
index1145!@#@!2003!@#@!Computational aspects of maximum likelihood estimation of autoregressive fractionally integrated moving average models!@#@!Computational Statistics &amp; Data Analysis!@#@!Computational aspects of likelihood-based estimation of univariate ARFIMA(p,d,q) models are addressed. Particular issues are the numerically stable evaluation of the autocovariances and efficient handling of the variance matrix which has dimension equal to the sample size. It is shown how efficient computation and simulation are feasible, even for large samples. Implementation of analytical bias corrections in ARFIMA regression models is also discussed.
index1146!@#@!2003!@#@!Optimal integer delay budgeting on directed acyclic graphs!@#@!Proceedings of the 40th annual Design Automation Conference!@#@!Delay budget is an excess delay each component of a design can tolerate under a given timing constraint. Delay budgeting has been widely exploited to improve the design quality. We present an optimal integer delay budgeting algorithm. Due to numerical instability and discreteness of libraries of components during library mapping in design optimization flow, integer solution for delay budgeting is essential. We prove that integer budgeting problem - a 20-year old open problem in design optimization [7]- can be solved optimally in polynomial time. We applied optimal delay budgeting in mapping applications on FPGA platform using pre-optimized cores of FPGA libraries. For each application we go through synthesis and place and route stages in order to obtain accurate results. Our optimal algorithm outperforms ZSA algorithm [3] in terms of area by 10% on average for all applications. In some applications, optimal delay budgeting can speedup runtime of place_and_route up to 2 times.
index1147!@#@!2002!@#@!Profile: Carolina Cruz-neira!@#@!Computer graphics companion!@#@!null
index1148!@#@!1995!@#@!Using a layered paradigm to model multimedia!@#@!Proceedings of the 28th Hawaii International Conference on System Sciences!@#@!This paper examines multimedia from a perspective of both data modeling and application development. It outlines a layered paradigm as a preferred approach to modeling, proposes a new layered multimedia data model (LMDM), and then demonstrates how the LMDM can be used together with a database of multimedia data to describe and support a large number of present and future multimedia applications. In addition, evaluation criteria are proposed by which the effectiveness of any new multimedia modeling approach should be assessed. The paper concludes with an attempt to evaluate the utility of the LMDM in the light of these criteria.
index1149!@#@!2003!@#@!Formal verification - prove it or pitch it!@#@!Proceedings of the 40th annual Design Automation Conference!@#@!Despite a number of solid advances in simulation and verification techniques over the last twenty years, semiconductor chip designs continue to see large increases in the cost of verification - both in terms of human resources and time. Most of these increases are due to the growing size and complexity of the chip designs. Many of these designs are complete systems in their own right thus enlarging the scope of the verification problem. Formal verification has held out the most promise for reducing the magnitude of the verification task. Indeed, most major microprocessor teams - at IBM, Intel and Motorola - have routinely hosted formal verification experts since the early '90s. ASIC vendors and their tool providers have been closely following these developments into a number of initiatives and new startup companies driven by that very promise of formal verification. Despite these developments, simulation continues to be the final source of signoff - if not confidence - in chip tapeouts. Why is this so? Formal verification is an important technology to be left at the margins of the validation task. Will formal verification eliminate or limit unit level verification and provide the necessary glue for a realistic validation flow? Will the testbenches be replaced by constraints and assertions? Can validation effort be reused? This panel will explore the issues related to building practical validation flows, and the technologies that the designer community can realistically look forward to materializing in their lifetimes.
index1150!@#@!2000!@#@!Control of Nondeterminism in Testing Distributed Multithreaded Programs!@#@!APAQS!@#@!Distributed and multithreaded systems are usually much more complex to analyze statically or test dynamically due to the nondeterminism involved. Forcing the system to take a particular execution path manually may be difficult sometimes. In this paper, we present our work in test control methods for distributed concurrent systems, and introduce the framework of our automated test control toolkit that can help users to realize some particular execution paths desired. The testing is specification-based: a test scenario is given as a pair of a test case and a control constraint expressing the partial order among certain events we are interested in. The test control is however based on a derived constraint only on shared objects. This allows us to develop more efficient test tools based on some unique code extension for different test scenarios. In our experiment, systems under testing consist of a set of processes, each in Java possibly with multiple threads, and communications among the processes are through CORBA.
index1151!@#@!2003!@#@!Tight degree bounds for pseudo-triangulations of points!@#@!Computational Geometry: Theory and Applications!@#@!We show that every set of n points in general position has a minimum pseudo-triangulation whose maximum vertex degree is five. In addition, we demonstrate that every point set in general position has a minimum pseudotriangulation whose maximum face degree is four (i.e., each interior face of this pseudo-triangulation has at most four vertices). Both degree bounds are tight. Minimum pseudo-triangulations realizing these bounds (individually but not jointly) can be constructed in O(n logn) time.
index1152!@#@!2003!@#@!Short talks-Specialized section: Fitt's law & text input!@#@!CHI '03 extended abstracts on Human factors in computing systems!@#@!null
index1153!@#@!1999!@#@!Manufacturing & Service Operations Management: An Introduction!@#@!Manufacturing &amp; Service Operations Management!@#@!null
index1154!@#@!1991!@#@!Lexical Discrimination within a Multilevel Semantics Approach!@#@!Proceedings of the 2nd Congress of the Italian Association for Artificial Intelligence on Trends in Artificial Intelligence!@#@!null
index1155!@#@!1993!@#@!Real Time - Mach Timers: Exporting Time to the User!@#@!USENIX MACH III Symposium!@#@!null
index1156!@#@!2003!@#@!Analyzing security costs!@#@!Communications of the ACM!@#@!Quantification tools, if applied prudently, can assist in the anticipation, budgeting, and control of direct and indirect computer security costs.
index1157!@#@!1995!@#@!167 MHz Radix-4 Floating Point Multiplier!@#@!ARITH!@#@!null
index1158!@#@!2001!@#@!A dynamic equilibrium approach: the application in long-term energy planning!@#@!Scientific computing and applications!@#@!In this paper, I present the multi-period market equilibrium model with the geometric distributed lag (GDL) demand, called the GDL equilibrium model, as well as its solution technique, called the decoupling algorithm. The dynamic equilibrium approach, including the GDL equilibrium model and the decoupling algorithm, can be valuable aids in long-run energy planning and energy-related CO2 emission control decision-making, in order to represent the time-lagged effect. In the energy GDL equilibrium model, the demand is represented by a function of the prices not only in the current time period but also in previous time periods through the GDL structure, and the supply is a cost-minimizing linear energy process submodel. The solution technique employs sequential nonlinear programming to calculate the intertemporal equilibrium of energy supplies and demands, along with the corresponding CO2 emission control submodel. The methods of analysis for the economic impact of CO2 emission control are carefully explored.
index1159!@#@!2002!@#@!Sustaining learning in critical domains of robotic systems!@#@!Journal of Computing Sciences in Colleges!@#@!Previous research in the field of Artificial Intelligence has focused on systems that are based on basic ideas of human long-term learning. These systems are not easily applicable to critical situations for robotic systems. In risky situations robotic systems use hierarchical/instinctual memory to address these perilous situations. However, this instinctual memory is often modified over long periods of time resulting in a sustained long-term memory system that interacts with the hierarchical system. In this paper a new method to modify and create learning in hierarchical/instinctualmemory is introduced in order to create a robotic system that is more capable of surviving in critical states. This new procedure draws on Learning Theory from the field of Cognitive Psychology in order to create and maintain this learning system for robotic structures. The new system that was created was first developed by re-analyzing the basic structure of memory and learning systems previously used in robotic systems. It is composed of six basic structures-Instinctual learning, Short-term learning, Long-term learning, motor memory, short-term memory, and long-term memory/knowledge base. Motor memory closely interacts exclusively with Instinctual Learning in a bi-directional relationship. Instinctual Learning also interacts with itself. The short term learning system interacts with both short-term memory as well as short-term learning itself. Finally, the long term learning system interacts with both long-term memory/knowledge base and long term learning. Both long-term learning and long-term memory can modify instinctuallearning; instinctuallearning can also modify long-term learning. The short and long- term learning structures interact and can modify one another. All modifications take place due to the repetitiveness and/or distinctiveness of the actions specified. For example, instinctual learning is self-modifiable through repetition in certain states, and this will also modify long-term learning and the long-term knowledge base. This system creates structures to deal with particular situations, but these distinct structures are also highly interactive. This provides a means to create sustained learning in risky domains. This system will allow practical robotic systems in critical domains to learn faster. This scheme has breakthrough potential for practical robotic systems such as military defense, police and rescue situations, medical diagnostic systems and other critical domain applications.
index1160!@#@!1998!@#@!Talking Eye: Autonomous Creature as Accomplice for Human!@#@!Proceedings of the Third Asian Pacific Computer and  Human Interaction!@#@!null
index1161!@#@!2003!@#@!Data and presentation techniques for fast, simple, and automatic plotting!@#@!Computer Standards &amp; Interfaces!@#@!We present a set of data-plotting techniques that help users, especially those with time constraints, in inferring conclusions flom measurement data quickly and with minimal efforts. The developed methods deal with speeding up the data file reading process, simplifying the user interface, and more importantly, enabling users to obtain automatically designed and customized plots whose attributes match those of previously designed ones. Together with a suite of presentation and analysis tools, the techniques are employed to build an application, which we use to test their performance. Finally, we analyze the application in terms of the standard reference model (SRM).
index1162!@#@!1993!@#@!Neural Networks for Constraint Satisfaction!@#@!Proceedings of the Third Congress of the Italian Association for Artificial Intelligence on Advances in Artificial Intelligence!@#@!null
index1163!@#@!2002!@#@!Optimal binary search trees meet object-oriented programming!@#@!Journal of Computing Sciences in Colleges!@#@!This paper presents an object-oriented approach to the problem of finding optimal binary search trees. We show that object-oriented techniques produce a solution that is an improvement over those created procedurally and that is well within the reach of our undergraduate students. Combining the study of optimality with that of object-oriented design helps the students gain a deeper appreciation of both.
index1164!@#@!2002!@#@!A Biologically Inspired Assurance Definition and Specification in Heterogeneous Autonomous Decentralized Systems!@#@!Proceedings of the 7th IEEE International Symposium on High Assurance Systems Engineering!@#@!In near future, billions of computers and intelligent sensors will connected through networks, each computer/application have its own autonomy, heterogeneity, and always in changing environments. We call these systems as a Heterogeneous Autonomous Decentralized Systems (HADS). Assurance is a hot research topic in HADS. In this paper, the conventional viewpoint towards assurance and the biological viewpoint for assurance are reviewed. Based on the biologically inspired matters, we view the assurance problem of HADS from systemperspective, data perspective, communication perspective, and application perspective. An assurance definition in HADS is defined and its technical vision is figured out. It will help researchers for their research on assurance in HADS.
index1165!@#@!1997!@#@!Using Extended Event Traces to Describe Communication in Software Architectures!@#@!Proceedings of the Fourth Asia-Pacific Software Engineering and International Computer Science Conference!@#@!A crucial aspect of the architecture of a software system is its decomposition into components and the specification of component interactions. In this report we use a variant of Extended Event Traces as a graphical technique for the description of such component interactions. It allows us to define interaction patterns that occur frequently within an architecture, in the form of diagrams. The diagrams may be instantiated in various contexts, thus allowing reuse of interaction patterns. Our notation contains operators yielding not only exemplary but complete behavior specifications. Extended Event Traces have a clear semantics that is based on sets of traces. We present several application examples that demonstrate the practical use of our notation.
index1166!@#@!2003!@#@!Marketing the virtual library!@#@!Building a virtual library!@#@!During the last decade, there have been significant changes in higher education, particularly in the emergence of distance education and the 24/7- access mantra (24 hours a day, seven days a week). This, in turn, has had a continuing impact upon efforts to reconceptualize what an academic library is and what it does. Not surprisingly, academic libraries face a number of critical issues, including increased costs of resources, expansion of traditional services, increased competition from other information vendors, and the impact of new technologies. Although these issues appear as threats, they are opportunities for libraries to design their own future (Denham, 1995).In the near future, academic libraries will remain a vital resource for faculty, students, and staff. While it is easy for academic libraries to become complacent about their status within a university since there is no competition on campus, successful marketing programs can enhance visibility, create understanding about the value of the library, and shape public perception of the scope of its resources and services (Gómez, 2001). This chapter will briefly look at marketing issues in academic libraries, how those issues were dealt with in marketing the Virtual Library, and where marketing for academic libraries may be going in the future as the physical and virtual worlds shift, meld, and merge.
index1167!@#@!1987!@#@!Data modeling as a Tool for Data System Planning: Can Data Modeling Accurately Reflect the Enterprise ? (Panel)!@#@!Proceedings of the Sixth International Conference on Entity-Relationship Approach!@#@!null
index1168!@#@!2003!@#@!Almost-certain eventualities and abstract probabilities in the quantitative temporal logic qTL!@#@!Theoretical Computer Science!@#@!'Almost-certain eventualities' are liveness properties that hold with probability 1. 'Abstract probabilities' in transition systems are those known only to be bounded away from zero and one.Vardi (Proceedings of the 26th IEEE Symposium on Foundations of Computer Science, Portland, 1985, p. 327) showed that almost-certain properties in linear temporal logic depend only on abstract probabilities rather than on the probabilities' precise values. We discuss the extent to which a similar result holds in the quantitative temporal logic qTL derived from the quantitative modal µ,calculus qMµ (Proceedings the Formal Methods Pacific '97, Springer, Singapore, 1997, also available http://web.comlab.ox.ac.uk/oucl/research/areas/probs/bibliography.html; logic J, IGPL 7(6) (1999) 779, http://www3.oup.co.uk/igpl/Volume_07/Issue_06, http://web.comlab. ox.ac.uk/oucl/research/areas/probs/bibliography.html), and we show how to specialise the logic to these cases. The aim is to provide a simpler calculus than the full logic, one that is in a certain sense complete for proving almost-certain eventualities from abstract-probabilistic assumptions.We concinde by considering the complexity of the specialised logic.
index1169!@#@!2002!@#@!...And now for something completely similar!@#@!Sys Admin!@#@!null
index1170!@#@!2003!@#@!Proof Nets for Unit-free Multiplicative-Additive Linear Logic (Extended abstract)!@#@!Proceedings of the 18th Annual IEEE Symposium on Logic in Computer Science!@#@!A cornerstone of the theory of proof nets for unit-freemultiplicative linear logic (MLL) is the abstract representation of cut-freeproofs modulo inessential commutations of rules. The only knownextension to additives, based on monomial weights, fails topreserve this key feature: a host of cut-free monomial proof nets cancorrespond to the same cut-free proof. Thus the problem offinding a satisfactory notion of proof net for unit-freemultiplicative-additive linear logic (MALL) has remained open since theincep-tion of linear logic in 1986. We present a new definition of MALLproof net which remains faithful to the cornerstone of the MLLtheory.
index1171!@#@!2003!@#@!The Robot host competition at the AAAI-2002 mobile Robot competition!@#@!AI Magazine!@#@!Robots in the Robot Host competition, part of the Eighteenth National Conference on Artificial Intelligence (AAAI-2002) Mobile Robot Competition faced two challenges: (1) a serving task that was similar to the Hors d'Oeuvres, Anyone? event of previous years and (2) a new information kiosk task. Both tasks required moving carefully among people, politely offering them information or hors d'oeuvres, recognizing when the people are making a request, and answering the request.
index1172!@#@!2002!@#@!Wireless LAN architecture for mobile operators!@#@!Wireless local area networks: the new wireless revolution!@#@!The evolution of Internet- or IP-based office applications has created a strong demand for public broadband wireless access offering capacity beyond current cellular systems. A wireless LAN is able to support broadband data rates in indoor environments but does not include support for operator-driven public access. In addition, most commercial public wireless LAN solutions only provide modest authentication and roaming capability compared with traditional cellular networks. This chapter describes a new wireless LAN system architecture that combines the wireless LAN radio access technology with the mobile operators' SIM-based subscriber management functions and roaming infrastructure. In the defined system, wireless LAN access is authenticated and charged with the GSM SIM, which is a widely deployed mobility platform. This solution supports roaming between cellular and wireless LAN access networks and is one step toward an all-IP network architecture. The first release of the system has been implemented and verified in an actual mobile operator network.
index1173!@#@!2003!@#@!Necessary and sufficient condition that the limit of Stieltjes transforms is a Stieltjes transform!@#@!Journal of Approximation Theory!@#@!The pointwise limit S of a sequence of Stieltjes transforms (Sn) of real Borel probability measures (Pn) is itself the Stieltjes transform of a Borel p.m. P if and only if iyS(iy) → -1 as y → ∞, in which case Pn converges to P in distribution. Applications are given to several problems in mathematical physics.
index1174!@#@!1999!@#@!Decomposing Digital 3D Shapes Using a Multiresolution Structure!@#@!Proceedings of the 8th International Conference on Discrete Geometry for Computer Imagery!@#@!null
index1175!@#@!1994!@#@!A Public-Key Cryptosystem and a Digital Signature System BAsed on the Lucas Function Analogue to Discrete Logarithms!@#@!Proceedings of the 4th International Conference on the Theory and Applications of Cryptology: Advances in Cryptology!@#@!null
index1176!@#@!1996!@#@!MENTOR: An Environment Supporting the Construction of Methods!@#@!Proceedings of the Third Asia-Pacific Software Engineering Conference!@#@!The method engineering discipline acknowledges the need for the construction of methods tuned to specific situations of development projects. One proposal for solving such a problem is to consider a method as a set of method fragment where a fragment can represent either process or product knowledge. Methods can be stored in a method base. We have implemented such a method base which constitutes the kernel of a tool environment called MENTOR, supporting the construction the evolution of methods and their enactment. In this paper we present and exemplify the Computer Aided Method Engineering (CAME) functionalities of MENTOR supporting the method construction process. The goal of this CAME environment is to improve the productivity of method engineers by facilitating the construction of methods which are project specific.
index1177!@#@!1999!@#@!Information Theory and the Finite-Time Behavior of the Simulated Annealing Algorithm: Experimental Results!@#@!INFORMS Journal on Computing!@#@!This article presents an empirical approach that demonstrates a theoretical connection between (information theoretic) entropy measures and the finite-time performance of the simulated annealing algorithm. The methodology developed leads to several computational approaches for creating problem instances useful in testing and demonstrating the entropy/performance connection: use of generic configuration spaces, polynomial transformations between NP-hard problems, and modification of penalty parameters. In particular, the computational results show that higher entropy measures are associated with superior finite-time performance of the simulated annealing algorithm.
index1178!@#@!1998!@#@!A Web-Based Database for Conducting Outcomes Research via the Internet: the National Comprehensive Cancer Network System!@#@!Proceedings of the 10th International Conference on Scientific and Statistical Database Management!@#@!null
index1179!@#@!2002!@#@!First-order logic with two variables and unary temporal logic!@#@!Information and Computation!@#@!We investigate the power of first-order logic with only two valiables over ω-words and finite words, a logic denoted by FO2. We prove that FO2 can express precisely the same properties as linear temporal logic with only the unary temporal operators: "next," "previously," "sometime in the future," and "sometime in the past," a logic we denote by unary-TL Moreover, our translation from FO2> to unary-TL converts every FO2 formula to an equivalent unary-TL formula that is at most exponentially larger and whose operator depth is at most twice the quantifier depth of the first-order formula, We show that this translation is essentially optimal. While satisfiability for full linear temporal logic, as well as for unary-TL, is known to be PSPACE-complete, we prove that satisfiability for FO2 is NEXP-complete. in sharp contrast to the fact that satisfiability for FO3 has nonelementary computational complexity. Our NEXP upper bound for FO2 satisfiability has the advantage of being in terms of the quantifier depth of the input formula. It is obtained using a small model property for FO2 of independent interest, namely, a satisfiable FO2 formula has a model whose size is at most exponential in the quantifier depth of the formula. Using our translation from FO2 to unary-TL we derive this small model property from a corresponding small model property for unary-TL. Our proof of the small model property for unary-TL is based on an analysis of unary-TL types.
index1180!@#@!2002!@#@!Proceedings of the 15th IEEE workshop on Computer Security Foundations!@#@!CSFW!@#@!null
index1181!@#@!1989!@#@!Der IBM Spracherkennungsprototyp TANGORA - Anpassung an die deutsche Sprache!@#@!Mustererkennung 1989, 11. DAGM-Symposium!@#@!null
index1182!@#@!1999!@#@!Exact Solution of the Quadratic Knapsack Problem!@#@!INFORMS Journal on Computing!@#@!The Quadratic Knapsack Problem (QKP) calls for maximizing a quadratic objective function subject to a knapsack constraint, where all coefficients are assumed to be nonnegative and all variables are binary. The problem has applications in location and hydrology, and generalizes the problem of checking whether a graph contains a clique of a given size. We propose an exact branch-and-bound algorithm for QKP, where upper bounds are computed by considering a Lagrangian relaxation that is solvable through a number of (continuous) knapsack problems. Suboptimal Lagrangian multipliers are derived by using subgradient optimization and provide a convenient reformulation of the problem. We also discuss the relationship between our relaxation and other relaxations presented in the literature. Heuristics, reductions, and branching schemes are finally described. In particular, the processing of each node of the branching tree is quite fast: We do not update the Lagrangian multipliers, and use suitable data structures to compute an upper bound in linear expected time in the number of variables. We report exact solution of instances with up to 400 binary variables, i.e., significantly larger than those solvable by the previous approaches. The key point of this improvement is that the upper bounds we obtain are typically within 1% of the optimum, but can still be derived effectively. We also show that our algorithm is capable of solving reasonable-size Max Clique instances from the literature.
index1183!@#@!2001!@#@!Utaclir @ CLEF 2001 - Effects of Compound Splitting and N-Gram Techniques!@#@!Revised Papers from the Second Workshop of the Cross-Language Evaluation Forum on Evaluation of Cross-Language Information Retrieval Systems!@#@!null
index1184!@#@!2002!@#@!Sciences: environmental sciences!@#@!Handbook of data mining and knowledge discovery!@#@!Environmental sciences are concerned with the physical, chemical, and biological aspects of the environment. They cover an extremely broad range of topics, such as biodiversity, climate change, forestry, and freshwater ecology, and are relevant to practical issues of environmental management. In this article, we attempt to give an overview of knowledge discovery in databases (KDD) applications in environmental sciences, complemented with a sample of case studies. The latter are described in slightly more detail and used to illustrate KDD-related issues that arise in environmental applications. The application domains addressed range from ecological modeling to remote sensing.
index1185!@#@!1997!@#@!A Lifetime-Sensitive Scheduling Method!@#@!APDC!@#@!This paper presents a lifetime-sensitive scheduling method. By shortening lifetimes of variables in scheduling phase, it can lighten register pressure in register allocation phase, lessen spill codes and result in more efficient object codes. The preliminary experimental results show that this method is an effective scheduling method.
index1186!@#@!1998!@#@!Microsystems Testing: A Challenge!@#@!Proceedings of the 7th Asian Test Symposium!@#@!null
index1187!@#@!2003!@#@!Norm Gibbs - Department Chair, Facilitator, Motivator and Visionary!@#@!Proceedings of the 16th Conference on Software Engineering Education and Training!@#@!null
index1188!@#@!2000!@#@!Committees/Reviewers!@#@!CVPR!@#@!null
index1189!@#@!2002!@#@!A Test Point Insertion Method to Reduce the Number of Test Patterns!@#@!Proceedings of the 11th Asian Test Symposium!@#@!The recent advances in semiconductor integration technology have resulted in an increasing number of the test length of full scan designed LSI's.This paper presents a test point insertion method for reducing test patterns of full scan designed LSI's.In our method, test points are inserted base on improved fault detection probability and value assignment probability such that test patterns are efficiently compacted.Experimental results for some practical designs show that the rate of test pattern compaction ranges from 31% to 65%.Those results also prove that our method is very effective for reducing the number of test patterns.
index1190!@#@!1981!@#@!Discriminability of Infinite Sets of Terms in the Dinfinity-Models of the lambda-calculus!@#@!Proceedings of the 6th Colloquium on Trees in Algebra and Programming!@#@!null
index1191!@#@!2002!@#@!Algorithms for a temporal decoupling problem in multi-agent planning!@#@!Eighteenth national conference on Artificial intelligence!@#@!The Temporal Decoupling Problem (TDP) arises when a group of agents collaborating on a set of temporally-dependent tasks seek to coordinate their execution of those tasks by applying additional temporal constraints sufficient to ensure that agents working on different tasks may operate independently. This paper: (1)formally defines the TDP, (2) presents theorems that give necessary and sufficient conditions for solutions to the TDP, (3)presents a family of sound and complete algorithms for solving the TDP, and (4) compares the performance of several variations of the basic algorithm. Although this work was motivated by a problem in collaborative multi-agent planning, it represents a contribution to the theory of Simple Temporal Networks that is independent of the motivating application.
index1192!@#@!1996!@#@!An Algebra for a Temporal Object Data Model!@#@!Proceedings of the 7th International Conference on Database and Expert Systems Applications!@#@!null
index1193!@#@!2001!@#@!The future of technology in higher education!@#@!Journal of Computing Sciences in Colleges!@#@!null
index1194!@#@!2002!@#@!Proceedings of the tenth international symposium on Hardware/software codesign!@#@!International Conference on Hardware Software Codesign!@#@!Welcome to CODES'O2.This meeting marks the tenth anniversary of the forum that traces its roots to the first Hardware/Software Codesign Workshop held in Estes Park in fall 1992. A retrospective over a decade of the meeting reveals a strong and vibrant community of researchers that took the very first bold steps into uncharted territory. With researchers coming together from such diverse backgrounds as logic design, artificial intelligence and software engineering, the convergence was also as much marked by technical challenges as by the cultural understanding of what goes on the other side. The yin-and-yang of hardware and software gyrated around technical issues such as system modeling, system partitioning and synthesis. Through discussions the community cross pollination was especially remarkable, with software community coming to appreciate that "software synthesis" has little to do with erstwhile automatic program generation but optimization of software from formal models and specifications much the same way logic synthesis results in optimized logic netlists. That software can be optimized (against multiple competing criteria) much as hardware is routinely optimized by EDA tools was as much a revelation as the understanding that hardware/software codesign is really about systems engineering rather than application of a chain of automatic computer-aided design tools. Indeed, the discussions brought up similarities and lessons learnt in complex system designs from submarines to the Space Shuttle. This community was still shy of using the term "Embedded Systems," for in those days embedded systems often referred to microcontroller-based systems marked by low criticality, low performance and cost sensitive designs. Over a decade, however, as mainstream computing has increasingly become a part of our daily lives -- and indeed often incorporates components and technologies that are on the cutting edge of performance and functionality achievable today -- that reticence has been abandoned. Embedded systems, particularly those for microelectronic on-chip implementations, have come to characterize a major component of the meeting. CODES sessions in recent years have addressed issues such as architectural design, design space exploration and validation of such systems. Energy efficiency and performance modeling (including real-time performance) have become major research themes.We are happy to report that after ten active years of discussions, presentations and follow-ups, the CODES forum remains an active and vibrant community. We received a total of 76 papers out of which 25 papers were selected for full presentations and 11 papers for short presentations after a thorough review process that included, on an average, 4 to 5 reviews per paper. As always, the technical program at CODES is actively put together through discussions within the entire technical program committee of the symposium. It is a tribute to you -- the audience, authors and participants -- that the CODES keeps going strong. As we complete ten years of an active community participation, given the momentum and relevance of the technical challenges that we face in putting together complete systems (particularly for on-chip implementations) we are confident that CODES can look forward to many more years of technical contributions.
index1195!@#@!2002!@#@!Bridging the digital divide by co-creating a collaborative computer science classroom!@#@!Journal of Computing Sciences in Colleges!@#@!Although the so-called "digital divide" is a popular topic of discussion among computer scientists and women's studies scholars, these two discourses rarely intersect, either theoretically or practically--creating a disciplinary divide. Women's studies scholars have thoroughly documented the historical barriers to science and computing for women and have outlined successful strategies for retaining women in computer science classrooms. However, few computer science educators are familiar with women's studies scholarship. This paper, which combines the perspectives of a women's studies scholar and a computer scientist, attempts to bridge the disciplinary divide between computer science and women's studies. In Section 1, we explain how the historical legacies of two fundamental themes implicit in the philosophy of science contribute to the exclusive environment in computer science classrooms today: 1) science=male, nature=female, and 2) exclusive epistemologies and pedagogies that privilege "maleness" over "femaleness." In Section 2, we offer a few practical pedagogical strategies for bridging the digital divide in computer science classrooms by co-creating collaborative rather than competitive learning environments. In Section 3, we explain what is required of computer science faculty if we are to halt the exit of talented women from our programs.
index1196!@#@!2003!@#@!State Constrained Feedback Stabilization!@#@!SIAM Journal on Control and Optimization!@#@!A standard finite dimensional nonlinear control system is considered, along with a state constraint set S and a target set $\Sigma$. It is proven that open loop S-constrained controllability to $\Sigma$ implies closed loop S-constrained controllability to the closed $\delta$-neighborhood of $\Sigma$, for any specified $\delta > 0$. When the S-constrained minimum time function to $\Sigma$ satisfies a local continuity condition, conclusions on closed loop S-constrained stabilizability ensue. The (necessarily discontinuous) feedback laws in question are implemented in the sample-and-hold sense and possess a robustness property with respect to state measurement errors. The feedback constructions involve the quadratic infimal convolution of a control Lyapunov function with respect to a certain modification of the original dynamics. The modified dynamics in effect provide for constraint removal, while the convolution operation provides a useful semiconcavity property.
index1197!@#@!2003!@#@!Code Compression Using Variable-to-fixed Coding Based on Arithmetic Coding!@#@!Proceedings of the Conference on Data Compression!@#@!Embedded computing systems are space and cost sensitive; memory is one of the mostrestricted resources, posing serious constraints on program size. Code compression,which is a special case of data compression where the input source is machineinstructions, has been proposed as a solution to this problem. Previous work in codecompression has focused on either fixed-to-variable coding or dictionary-basedalgorithms. We propose code compression schemes that use variable-to-fixed (V2F)length coding, based on arithmetic coding. Experiments show that the compression ratiousing memoryless V2F coding for the TMS320C6x processor is on average 82.5%(defined as the ratio of the compressed over the uncompressed program) anddecompression can be parallelized. A Markov-based V2F coding based on arithmeticcoding, can achieve an average compression ratio 72% for TMS320C6x, whiledecompression cannot be parallelized. Furthermore, our experiments have shown thatarithmetic coding based V2F coding has similar compression performance with Tunstallcoding. Finally, we present a power reduction scheme for the instruction bus using ourV2F coding scheme.
index1198!@#@!1994!@#@!Improved Performance of Mobile Data Networks Using Stack Algorithms and Receiver Capture!@#@!Proceedings of the 1994 International Zurich Seminar on Digital Communications: Mobile Communications: Advanced Systems and Components!@#@!null
index1199!@#@!2000!@#@!DFT closure!@#@!Proceedings of the 9th Asian Test Symposium!@#@!It is becoming evident that testability must be addressed throughout the entire design process. To successfully meet all the design goals of today's and tomorrow's enormously complex devices, swift convergence of function, timing, area and power requirements must be simultaneously accompanied by new test tools that enable rapid, predictable and repeatable DFT closure. Achieving successful DFT closure requires that RTL designers and DFT engineers work in concert on a unified view of the design, using integrated tools and flows. It also requires that DFT tools have zero impact on critically important timing closure flows.
index1200!@#@!1974!@#@!Monadic Program Schemes Under Restricted Classes of Free Interpretations!@#@!Proceedings of the 2nd Colloquium on Automata, Languages and Programming!@#@!null
index1201!@#@!1989!@#@!Teaching Object-Oriented Programming Using the Macintosh MPW/MacApp Environment!@#@!Proceedings of the SEI Conference on Software Engineering Education!@#@!null
index1202!@#@!2001!@#@!Fast PNN Using Partial Distortion Search!@#@!Proceedings of the 9th International Conference on Computer Analysis of Images and Patterns!@#@!null
index1203!@#@!1997!@#@!Index of Authors!@#@!Proceedings of the Australian Software Engineering Conference!@#@!null
index1204!@#@!1997!@#@!Adaptive Vector Quantization Using Generalized Threshold Replenishment!@#@!Proceedings of the  Conference on Data Compression!@#@!In this paper, we describe a new adaptive vector quantization (AVQ) algorithm designed for the coding of nonstationary sources. This new algorithm, generalized threshold replenishment (GTR), differs from prior AVQ algorithms in that it features an explicit, online consideration of both rate and distortion. Rate-distortion cost criteria are used in both the determination of nearest-neighbor codewords and the decision to update the codebook. Results presented indicate that, for the coding of an image sequence, (1) most AVQ algorithms achieve distortion much lower than that of nonadaptive VQ for the same rate (about 1.5 bits/pixel), and (2) the GTR algorithm achieves rate-distortion performance substantially superior to that of the prior AVQ algorithms for low-rate coding, being the only algorithm to achieve a rate below 1.0 bits/pixel.
index1205!@#@!2000!@#@!From Object-Oriented to Aspect-Oriented Databases!@#@!Proceedings of the 11th International Conference on Database and Expert Systems Applications!@#@!null
